<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="An Introduction to Machine Learning" />
<meta property="og:type" content="book" />
<meta property="og:url" content="https://m-clark.github.io/docs/" />
<meta property="og:image" content="https://m-clark.github.io/docs/img/nineteeneightyR.png" />
<meta property="og:description" content="An introduction to machine learning for applied researchers." />
<meta name="github-repo" content="m-clark/introduction-to-machine-learning/" />


<meta name="date" content="2017-04-21" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="An introduction to machine learning for applied researchers.">

<title>An Introduction to Machine Learning</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<script src="libs/htmlwidgets-0.8/htmlwidgets.js"></script>
<script src="libs/jquery-1.12.4/jquery.min.js"></script>
<script src="libs/datatables-binding-0.2/datatables.js"></script>
<link href="libs/dt-core-1.10.12/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.12/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.12/js/jquery.dataTables.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>


<link rel="stylesheet" href="standard_html.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
<link rel="stylesheet" href="mytufte.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#section"></a></li>
<li><a href="00_preface.html#preface">Preface</a></li>
<li class="has-sub"><a href="01_intro.html#introduction">Introduction</a><ul>
<li><a href="01_intro.html#explanation-prediction">Explanation &amp; Prediction</a></li>
<li><a href="01_intro.html#some-terminology">Some Terminology</a></li>
</ul></li>
<li class="has-sub"><a href="02_tools.html#tools">Tools</a><ul>
<li><a href="02_tools.html#the-standard-linear-model">The Standard Linear Model</a></li>
<li><a href="02_tools.html#logistic-regression">Logistic Regression</a></li>
<li class="has-sub"><a href="02_tools.html#expansions-of-those-tools">Expansions of Those Tools</a><ul>
<li><a href="02_tools.html#generalized-linear-models">Generalized Linear Models</a></li>
<li><a href="02_tools.html#generalized-additive-models">Generalized Additive Models</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="03_loss.html#the-loss-function">The Loss Function</a><ul>
<li class="has-sub"><a href="03_loss.html#continuous-outcomes">Continuous Outcomes</a><ul>
<li><a href="03_loss.html#squared-error">Squared Error</a></li>
<li><a href="03_loss.html#absolute-error">Absolute Error</a></li>
<li><a href="03_loss.html#negative-log-likelihood">Negative Log-likelihood</a></li>
<li><a href="03_loss.html#r-example">R Example</a></li>
</ul></li>
<li class="has-sub"><a href="03_loss.html#categorical-outcomes">Categorical Outcomes</a><ul>
<li><a href="03_loss.html#misclassification">Misclassification</a></li>
<li><a href="03_loss.html#binomial-log-likelihood">Binomial log-likelihood</a></li>
<li><a href="03_loss.html#exponential">Exponential</a></li>
<li><a href="03_loss.html#hinge-loss">Hinge Loss</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="04_regularization.html#regularization">Regularization</a><ul>
<li><a href="04_regularization.html#r-example-1">R Example</a></li>
</ul></li>
<li class="has-sub"><a href="05_biasvar.html#bias-variance-tradeoff">Bias-Variance Tradeoff</a><ul>
<li><a href="05_biasvar.html#bias-variance">Bias <em>&amp;</em> Variance</a></li>
<li><a href="05_biasvar.html#the-tradeoff">The Tradeoff</a></li>
<li class="has-sub"><a href="05_biasvar.html#diagnosing-bias-variance-issues-possible-solutions">Diagnosing Bias-Variance Issues <em>&amp;</em> Possible Solutions</a><ul>
<li><a href="05_biasvar.html#worst-case-scenario">Worst Case Scenario</a></li>
<li><a href="05_biasvar.html#high-variance">High Variance</a></li>
<li><a href="05_biasvar.html#high-bias">High Bias</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="06_crossval.html#cross-validation">Cross-Validation</a><ul>
<li><a href="06_crossval.html#adding-another-validation-set">Adding Another Validation Set</a></li>
<li class="has-sub"><a href="06_crossval.html#k-fold-cross-validation">K-fold Cross-Validation</a><ul>
<li><a href="06_crossval.html#leave-one-out-cross-validation">Leave-one-out Cross-Validation</a></li>
</ul></li>
<li><a href="06_crossval.html#bootstrap">Bootstrap</a></li>
<li><a href="06_crossval.html#other-stuff">Other Stuff</a></li>
</ul></li>
<li class="has-sub"><a href="07_models.html#model-assessment-selection">Model Assessment &amp; Selection</a><ul>
<li><a href="07_models.html#beyond-classification-accuracy-other-measures-of-performance">Beyond Classification Accuracy: Other Measures of Performance</a></li>
</ul></li>
<li class="has-sub"><a href="08_overview.html#process-overview">Process Overview</a><ul>
<li class="has-sub"><a href="08_overview.html#data-preparation">Data Preparation</a><ul>
<li><a href="08_overview.html#define-data-and-data-partitions">Define Data and Data Partitions</a></li>
<li><a href="08_overview.html#feature-scaling">Feature Scaling</a></li>
<li><a href="08_overview.html#feature-engineering">Feature Engineering</a></li>
<li><a href="08_overview.html#discretization">Discretization</a></li>
</ul></li>
<li><a href="08_overview.html#model-selection">Model Selection</a></li>
<li><a href="08_overview.html#model-assessment">Model Assessment</a></li>
</ul></li>
<li class="has-sub"><a href="1000_appendix.html#appendix">Appendix</a><ul>
<li><a href="1000_appendix.html#bias-variance-demo">Bias Variance Demo</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="model-assessment-selection" class="section level1">
<h1>Model Assessment &amp; Selection</h1>
<p><span class="newthought">In typical model comparison</span> within the standard linear model framework, there are a number of ways in which we might assess performance across competing models. For standard OLS regression we might examine adjusted-<span class="math inline">\(R^2\)</span>, or with the generalized linear models we might pick a model with the lowest AIC<label for="tufte-sn-20" class="margin-toggle sidenote-number">20</label><input type="checkbox" id="tufte-sn-20" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">20</span> In situations where it is appropriate to calculate in the first place, AIC can often compare to the bootstrap and k-fold cross-validation approaches.</span>. As we have already discussed, in the machine learning context we are interested in models that reduce e.g. squared error loss (regression) or misclassification error (classification). However in dealing with many models some differences in performance may be arbitrary.</p>
<div id="beyond-classification-accuracy-other-measures-of-performance" class="section level2">
<h2>Beyond Classification Accuracy: Other Measures of Performance</h2>
<p>In typical classification situations we are interested in overall accuracy. However there are situations, not uncommon, in which simple accuracy isn’t a good measure of performance. As an example, consider the prediction of the occurrence of a rare disease. Guessing a non-event every time might result in 99.9% accuracy, but that isn’t how we would prefer to go about assessing some classifier’s performance. To demonstrate other sources of classification information, we will use the following 2x2 table that shows values of some binary outcome (0 = non-event, 1 = event occurs) to the predictions made by some model for that response (arbitrary model). Both a table of actual values, often called a <span class="emph">confusion matrix</span><label for="tufte-sn-21" class="margin-toggle sidenote-number">21</label><input type="checkbox" id="tufte-sn-21" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">21</span> This term has always struck me as highly sub-optimal.</span>, and an abstract version are provided.</p>
<!-- between the combined failure of pander datatable and div in tufte (ignores width) this hack gets clean tables side by side via a ghosted third column-->
<div class="col3" width="50%">
<p><div id="htmlwidget-ac187e7660fd2dd01166" style="width:35%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-ac187e7660fd2dd01166">{"x":{"filter":"none","data":[["","","Predicted",""],["","","1","0"],["","1","41","16"],["Actual","0","21","13"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th><\/th>\n      <th><\/th>\n      <th><\/th>\n      <th><\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"t","ordering":false,"columnDefs":[{"className":"dt-right","targets":[1,2,3]}],"order":[],"autoWidth":false,"orderClasses":false,"rowCallback":"function(row, data) {\nvar value=data[0]; if (value!==null) $(this.api().cell(row, 0).node()).css({'background-color':'#fffff8'});\nvar value=data[1]; if (value!==null) $(this.api().cell(row, 1).node()).css({'background-color':'#fffff8'});\nvar value=data[2]; if (value!==null) $(this.api().cell(row, 2).node()).css({'background-color':'#fffff8'});\nvar value=data[3]; if (value!==null) $(this.api().cell(row, 3).node()).css({'background-color':'#fffff8'});\n}"}},"evals":["options.rowCallback"],"jsHooks":[]}</script><br/><div id="htmlwidget-2431d7b8447e155af89f" style="width:35%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-2431d7b8447e155af89f">{"x":{"filter":"none","data":[["","","Predicted",""],["","","1","0"],["","1","A","C"],["Actual","0","B","D"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th><\/th>\n      <th><\/th>\n      <th><\/th>\n      <th><\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"t","ordering":false,"columnDefs":[{"className":"dt-right","targets":[1,2,3]}],"order":[],"autoWidth":false,"orderClasses":false,"rowCallback":"function(row, data) {\nvar value=data[0]; if (value!==null) $(this.api().cell(row, 0).node()).css({'background-color':'#fffff8'});\nvar value=data[1]; if (value!==null) $(this.api().cell(row, 1).node()).css({'background-color':'#fffff8'});\nvar value=data[2]; if (value!==null) $(this.api().cell(row, 2).node()).css({'background-color':'#fffff8'});\nvar value=data[3]; if (value!==null) $(this.api().cell(row, 3).node()).css({'background-color':'#fffff8'});\n}"}},"evals":["options.rowCallback"],"jsHooks":[]}</script><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/></p>
</div>
<p><span class="emph">True Positive</span>, <span class="emph">False Positive</span>, <span class="emph">True Negative</span>, <span class="emph">False Negative</span>: Above, these are A, B, D, and C respectively.</p>
<p><span class="emph">Accuracy</span>: Number of correct classifications out of all predictions ((A+D)/Total). In the above example this would be (41+13)/91, about 59%.</p>
<p><span class="emph">Error Rate</span>: 1 - Accuracy.</p>
<p><span class="emph">Sensitivity</span>: is the proportion of correctly predicted positives to all true positive events: A/(A+C). In the above example this would be 41/57, about 72%. High sensitivity would suggest a low type II error rate (see below), or high statistical power. Also known as <em>true positive rate</em>.</p>
<p><span class="emph">Specificity</span>: is the proportion of correctly predicted negatives to all true negative events: D/(B+D). In the above example this would be 13/34, about 38%. High specificity would suggest a low type I error rate (see below). Also known as <em>true negative rate</em>.</p>
<p><span class="emph">Postive Predictive Value</span> (PPV): proportion of true positives of those that are predicted positives: A/A+B. In the above example this would be 41/62, about 66%.</p>
<p><span class="emph">Negative Predictive Value</span> (NPV): proportion of true negatives of those that are predicted negative: D/C+D. In the above example this would be 13/29, about 45%.</p>
<p><span class="emph">Precision</span>: See PPV.</p>
<p><span class="emph">Recall</span>: See sensitivity.</p>
<p><span class="emph">Lift</span>: Ratio of positive predictions given actual positives to the proportion of positive predictions out of the total: (A/(A+C))/((A+B)/Total). In the above example this would be (41/(41+16))/((41+21)/(91)), or 1.06.</p>
<p><span class="emph">F Score</span> (F1 score): Harmonic mean of precision and recall: 2*(Precision*Recall)/(Precision+Recall). In the above example this would be 2*(.66*.72)/(.66+.72), about 0.69.</p>
<p><span class="emph">Type I Error Rate</span> (false positive rate): proportion of true negatives that are incorrectly predicted positive: B/B+D. In the above example this would be 21/34, about 62%. Also known as <em>alpha</em>.</p>
<p><span class="emph">Type II Error Rate</span> (false negative rate): proportion of true positives that are incorrectly predicted negative: C/C+A. In the above example this would be 16/57, about 28%. Also known as <em>beta</em>.</p>
<p><span class="emph">False Discovery Rate</span>: proportion of false positives among all positive predictions: B/A+B. In the above example this would be 21/62, about 34%. Often used in multiple comparison testing in the context of ANOVA.</p>
<p><span class="emph">Phi coefficient</span>: A measure of association: (A*D - B*C)/(sqrt((A+C)*(D+B)*(A+B)*(D+C))). In the above example this would be 0.11.</p>
<p>Note the following summary of several measures where <span class="math inline">\(N_+\)</span> and <span class="math inline">\(N_-\)</span> are the total true positive values and total true negative values respectively, and <span class="math inline">\(T_+\)</span>, <span class="math inline">\(F_+\)</span>, <span class="math inline">\(T_-\)</span> and <span class="math inline">\(F_-\)</span> are true positive, false positive, etc.:</p>
<div id="htmlwidget-aa4f67fedaf4cfc844c3" style="width:35%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-aa4f67fedaf4cfc844c3">{"x":{"filter":"none","data":[["","","Predicted",""],["","","1","0"],["","1","T&lt;U+208A&gt;/N&lt;U+208A&gt; = TPR = sensitivity = recall","F&lt;U+208B&gt;/N&lt;U+208A&gt; = FNR = Type II"],["Actual","0","F&lt;U+208A&gt;/N&lt;U+208B&gt; = FPR = Type I","T&lt;U+208B&gt;/N&lt;U+208B&gt; = TNR = specificity"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th><\/th>\n      <th><\/th>\n      <th><\/th>\n      <th><\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"t","ordering":false,"columnDefs":[{"className":"dt-right","targets":[1,2,3]}],"order":[],"autoWidth":false,"orderClasses":false,"rowCallback":"function(row, data) {\nvar value=data[0]; if (value!==null) $(this.api().cell(row, 0).node()).css({'background-color':'#fffff8'});\nvar value=data[1]; if (value!==null) $(this.api().cell(row, 1).node()).css({'background-color':'#fffff8'});\nvar value=data[2]; if (value!==null) $(this.api().cell(row, 2).node()).css({'background-color':'#fffff8'});\nvar value=data[3]; if (value!==null) $(this.api().cell(row, 3).node()).css({'background-color':'#fffff8'});\n}"}},"evals":["options.rowCallback"],"jsHooks":[]}</script>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">testdf &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">locationName=</span> <span class="kw">c</span>(<span class="st">&quot;台北&quot;</span>,<span class="st">&quot;新北市&quot;</span>,<span class="st">&quot;台南市&quot;</span>), <span class="dt">TEMP=</span><span class="kw">c</span>(<span class="dv">30</span>,<span class="dv">29</span>,<span class="dv">28</span>))
testdf</code></pre></div>
<pre><code>              locationName TEMP
1         &lt;U+53F0&gt;&lt;U+5317&gt;   30
2 &lt;U+65B0&gt;&lt;U+5317&gt;&lt;U+5E02&gt;   29
3 &lt;U+53F0&gt;&lt;U+5357&gt;&lt;U+5E02&gt;   28</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(DT)
<span class="kw">datatable</span>(testdf)</code></pre></div>
<div id="htmlwidget-fc4b66cf135d712895f8" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-fc4b66cf135d712895f8">{"x":{"filter":"none","data":[["1","2","3"],["&lt;U+53F0&gt;&lt;U+5317&gt;","&lt;U+65B0&gt;&lt;U+5317&gt;&lt;U+5E02&gt;","&lt;U+53F0&gt;&lt;U+5357&gt;&lt;U+5E02&gt;"],[30,29,28]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>locationName<\/th>\n      <th>TEMP<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":2},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p>There are many other measures such as area under a Receiver Operating Curve (<span class="emph">ROC</span>), <span class="emph">odds ratio</span>, and even more names for some of the above. The gist is that given any particular situation you might be interested in one or several of them, and it would generally be a good idea to look at a few.</p>

</div>
</div>
<p style="text-align: center;">
<a href="06_crossval.html"><button class="btn btn-default">Previous</button></a>
<a href="08_overview.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
