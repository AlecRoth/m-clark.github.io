---
title: "Exploring the Pandemic"
description: |
  Processing and Visualizing Covid-19 Data
author:
  - name: Michael Clark
    url: https://m-clark.github.io
date: '`r Sys.Date()`'
preview: ../../img/covid_preview.gif   # apparently no way to change the size displayed via css (ignored) or file (stretched)
output:
  distill::distill_article:
    self_contained: false
    toc: true
    css: [../../styles.css, ../../css/misc.css]
    code_folding: hide
draft: false
tags: [covid19, daily, total, world, u.s., michigan, washtenaw, wayne, detroit, sars, mers, h1n1]
categories:
  - visualization
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  comment = NA,
  R.options = list(width = 120),
  cache.rebuild = FALSE,
  cache = FALSE,
  fig.align = 'center',
  fig.asp = .7,
  dev = 'svglite',
  dev.args = list(bg = 'transparent')
)

library(tidyverse)
library(kableExtra)

kable_df <- function(..., digits=3) {
  kable(..., digits=digits) %>% 
    kable_styling(full_width = F)
}

rnd = tidyext::rnd
```

<aside>First posted 2020-03-23.</aside>


## Introduction

This is some code to get processed data and visualizations regarding the COVID-19 outbreak.   The goal here is just to present some code that I'm playing with that may also make it easier for others to get their hands dirty. In other words, this is for enabling others to play with the data as well, while presenting some clean code and data. There are actually already some R packages doing some of this, but they are currently (in my opinion) problematic, slow to update, and or don't really offer much than what you could just do yourself, as demonstrated below.  I'll likely be updating this daily for the time being.

I actually started scraping Wikipedia's WHO incidence report tables, but any cursory glance showed numerous issues and lots of cleaning, coupled with a format that changed almost daily.  I then started playing with the data behind the [Johns Hopkins dashboard](https://coronavirus.jhu.edu/map.html), which was notably better, but didn't have some info and there are issues there as well. I settled on Open Covid, but may revisit JH after their changes take place, as they will also have U.S. county level counts.

I use some custom functions in the following, and I don't show every bit of code, but most of these cases are inconsequential.  The bulk of this code should be usable by anyone pretty easily if they are familiar with the <span class="pack" style = "">tidyverse</span>.

Resources:

For the country level plots:
- Open COVID-19: https://github.com/open-covid-19/data
- Open COVID categorical data: https://open-covid-19.github.io/data/data_categories.csv

For U.S. county level plots:
- Johns Hopkins: https://github.com/CSSEGISandData/COVID-19
- NY Times finally put their data up on March 27: https://github.com/nytimes/covid-19-data

Check out CSCAR chum Alex Cao's more local efforts here: https://observablehq.com/@caocscar/covid-19-michigan-data

## Getting Started

The following is a fairly simple function for reading data from the GitHub repo. It has arguments for filtering to a specific country, whether or not you only wan the current numbers, 

```{r read_covid_data}
read_covid_data <- function(
  country = NULL,     # Filter to specific country
  current = FALSE,    # Only the current data
  totals  = FALSE     # Only totals (no regional)
) {
  if (current) {
    data = readr::read_csv('https://open-covid-19.github.io/data/data_latest.csv',
                           col_types = 'Dccccciiddi')
  }
  else {
    data = read_csv('https://open-covid-19.github.io/data/data.csv',
                    col_types = 'Dccccciiddi')
  }
  
  if (!is.null(country)) {
     data = filter(data, CountryCode == country | CountryName == country)
  }
  
  # other cleanup and additions
  data = data %>% 
    rename(
      country_code = CountryCode,
      country_name = CountryName,
      region_code = RegionCode,
      region_name = RegionName,
      total_confirmed = Confirmed,
      total_deaths = Deaths
    ) %>% 
    rename_all(tolower) %>% 
    group_by(country_code, region_code) %>% 
    mutate(
      total_deaths = ifelse(is.na(total_deaths), 0, total_deaths),
      daily_confirmed = total_confirmed - lag(total_confirmed),
      daily_deaths = total_deaths - lag(total_deaths),
      region_name  = if_else(region_name == 'South Caroline', 'South Carolina', region_name),
      death_rate   = total_deaths/total_confirmed
    ) %>% 
    mutate_at(vars(contains('daily')), function(x) ifelse(is.na(x), 0, x)) %>% 
    select(date:region_name, contains('daily'), contains('total'), death_rate, everything()) %>% 
    ungroup()
  
  if (totals) data = filter(data, is.na(region_code))
  
  ungroup(data)
}
```


```{r read_data, cache.rebuild=TRUE}
library(tidyverse)  # required for function

main = read_covid_data()  # all of the data

world_totals = read_covid_data(current = TRUE, totals = TRUE)  # only country current totals

countries = main %>% filter(is.na(region_code))   # country-level for all dates

us = read_covid_data(country = 'US')  # all US data

us_current = read_covid_data(country = 'US', current = TRUE) # only current US state totals
```


```{r death-rates, echo=FALSE, cache.rebuild=TRUE}
# current days data may not be complete, and Spain is always given an update before everyone. I do an initial check to see if there has been an update for the U.S. current date, otherwise Spain (and probably Italy) are a day ahead.

world_death_rates = world_totals %>%
  group_by(country_code) %>% 
  filter(date == max(date)) %>% 
  ungroup() %>% 
  summarise(
    `Total Confirmed` = sum(total_confirmed),
    `Total Deaths`    = sum(total_deaths),
    `Death Rate`      = `Total Deaths` / `Total Confirmed`,
    `Death Rate (minus Italy)` = 
      sum(total_deaths[country_name != 'Italy']) / 
      sum(total_confirmed[country_name != 'Italy'])
  )


us_death_rates = us_current %>% 
  filter(is.na(region_name)) %>% 
  select(matches('total|rate'))

mi_death_rates = us_current %>% 
  filter(region_code == 'MI') %>% 
  select(matches('total|rate'))
```


#### World

Now that we have the data, we can see what's going on.

```{r table-of-world-current-counts, echo=FALSE, cache=FALSE}
world_death_rates %>% 
  mutate_at(vars(-contains('rate')), scales::comma) %>% 
  mutate_at(vars(contains('rate')), scales::percent, accuracy = .1) %>% 
  mutate_all(function(x) cell_spec(x, "html", color = '#ff5500', font_size = 36)) %>% 
  kable_df(
    escape = FALSE,
    align = 'c', 
    table.attr='class="covid-table"'
  ) 
```

#### United States

```{r table-of-us-current-counts, echo=FALSE, cache=FALSE}
us_death_rates %>% 
  rename_all(function(x) str_to_title(str_replace_all(x, '_', ' ' ))) %>% 
  mutate_at(vars(-contains('rate')), scales::comma) %>% 
  mutate_at(vars(contains('rate')), scales::percent, accuracy = .1) %>% 
  mutate_all(function(x) cell_spec(x, "html", color = '#ff5500', font_size = 36)) %>% 
  kable_df(
    escape = FALSE,
    align = 'c', 
    table.attr='class="covid-table"'
  )
```

#### Michigan

```{r table-of-michigan-current-counts, echo=FALSE, cache=FALSE}
mi_death_rates %>% 
  rename_all(function(x) str_to_title(str_replace_all(x, '_', ' ' ))) %>% 
  mutate_at(vars(-contains('rate')), scales::comma) %>% 
  mutate_at(vars(contains('rate')), scales::percent, accuracy = .1) %>% 
  mutate_all(function(x) cell_spec(x, "html", color = '#ff5500', font_size = 36)) %>% 
  kable_df(
    escape = FALSE,
    align = 'c', 
    table.attr='class="covid-table"'
  )
```

#### Washtenaw County

The following uses <span class="pack" style = "">rvest</span> to grab the current tally for this county from the county website. It is updated daily at noon.

```{r washtenaw}
URL = 'https://www.washtenaw.org/3108/Cases'

library(rvest)

init = read_html(URL) %>% 
  html_table()

washtenaw_cases = as_tibble(init[[1]])
```

```{r washtenaw-show, echo=FALSE}
washtenaw_cases %>% 
  rename(
    `Total Confirmed` = 1,
    `Total Deaths` =  3
  ) %>% 
  select(-`TotalÂ Hospitalizations`, -TotalRecovered) %>% 
  mutate(`Death Rate` = `Total Deaths`/`Total Confirmed`) %>%   
  mutate_at(vars(-contains('rate')), scales::comma) %>% 
  mutate_at(vars(contains('rate')), scales::percent, accuracy = .1) %>% 
  mutate_all(function(x) cell_spec(x, "html", color = '#ff5500', font_size = 36)) %>% 
  kable_df(
    escape = FALSE,
    align = 'c', 
    table.attr='class="covid-table"'
  )
```



## The Data

The following is adapted from the ReadMe file at the open covid repo.

The columns of the main dataset are:

| Name | Description | Example |
| ---- | ----------- | ------- |
| **date** | ISO 8601 date (YYYY-MM-DD) of the datapoint | 2020-03-21 |
| **country_code** | ISO 3166-1 code of the country | CN |
| **country_name** | American English name of the country | China |
| **region_code** | (Optional) ISO 3166-2 code of the region | HB |
| **region_name** | (Optional) American English name of the region | Hubei |
| **total_confirmed** | Total number of cases confirmed after positive test | 67800 |
| **total_deaths** | Total number of deaths from a positive COVID-19 case | 3139 |
| **death_rate** | Rate of deaths from a positive COVID-19 case | 0.04629794 |
| **daily_confirmed** | Daily number of cases confirmed after positive test | 0 |
| **daily_deaths** | Daily number of deaths from a positive COVID-19 case | 6 |
| **latitude** | Floating point representing the geographic coordinate | 30.9756 |
| **longitude** | Floating point representing the geographic coordinate | 112.2707 |
| **population** | Total count of humans living in the region | TODO |

<br>

For countries where both country-level and region-level data is available, the
entry which has a null value for the `region_code` and `region_name` columns
indicates country-level aggregation. Please note that, sometimes, the
country-level data and the region-level data come from different sources so
adding up all region-level values may not equal exactly to the reported
country-level value.


### U.S. State Totals

Here is a data table for easy look-up of current U.S. 

```{r us-current-state-lookup, echo=FALSE}
us_current %>% 
  mutate(
    region_code = if_else(is.na(region_code), 'Total', region_code),
    region_name = if_else(is.na(region_name), 'Total', region_name),
  ) %>% 
  select(-(latitude:population), -country_name, -country_code) %>% 
  DT::datatable(
    width = 800,
    rownames = FALSE,
    options = list(
      scrollX = TRUE
    )
  )
```


## Country Level Trends

The following does some additional processing before going to a plot of the trends. I pick some countries to highlight (not necessarily the ones with the most cases), and I treat the world total as a separate addition to the plot.  

```{r country-trend-static-proc}
highlight = c(
  'United States of America',
  'China',
  'Japan',
  'South Korea',
  'Italy',
  'Iran',
  'United Kingdom',
  'France',
  'Germany',
  'Spain'
)

world = countries %>%
  filter(date < Sys.Date() + 1) %>%
  group_by(date) %>% 
  summarise(total_confirmed = sum(total_confirmed))
```

Now we can just do a basic plot.  I use <span class="pack" style = "">ggrepel</span> to see more clearly where the highest cases are currently.

```{r country-trend-static}
library(ggrepel)

p = countries %>% 
  ggplot(aes(x = date, y = total_confirmed)) +
  geom_path(aes(group = country_code), alpha = .005) +
  geom_point(
    aes(),
    size  = 5,
    alpha = .1,
    data  = world
  ) +
  geom_point(
    aes(color = country_code),
    size  = 1.5,
    alpha = .5,
    data  = filter(countries, country_name %in% highlight, date < Sys.Date() + 1)
  ) +
  geom_text_repel(
    aes(label = country_code, color = country_code),
    size  = 2,
    alpha = .85,
    data  = filter(countries, country_name %in% highlight, date == max(date)-1),
    show.legend = FALSE
  ) +
  scico::scale_color_scico_d(begin = .1, end = .9) +
  scale_x_date(
    date_breaks = '2 weeks',
    labels = function(x) format(x, format = "%m/%d")
  ) +
  scale_y_continuous(
    position = "right",
    trans    = 'log',
    breaks   = c(50, unlist(map(c(1,5), function(x) x*10^(2:6)))), 
    labels   = scales::comma
  ) +
  visibly::theme_clean() + 
  labs(
    x = '', 
    y = '',
    subtitle =  'Total Confirmed Cases',
    caption  = 'Dark large dot is world total'
    ) +
  theme(
    axis.text.x  = element_text(size = 6),
    axis.text.y  = element_text(size = 6),
    axis.title.y = element_text(size = 6),
    axis.ticks.y = element_blank(),
    legend.title       = element_blank(),
    legend.key.size    = unit(.25, 'cm'),
    legend.text        = element_text(size = 6),
    legend.box.spacing = unit(0, 'mm'),
    legend.box.margin  = margin(0),
    legend.position    = 'left',
    title = element_text(size = 12)
  )

p
```

```{r country-trend-static-save, echo=FALSE, eval=FALSE}
ggsave('img/covid.svg')
```


The following animates the previous via <span class="pack" style = "">gganimate</span>.

```{r country-trend-animate, cache=TRUE, dev='png', eval=F, echo = -1, dev.args=list(bg = '#fffff8')}
# note, this will create the files in the top level directory, so they need to
# be moved to the directory of the post to see
library(gganimate)

p_anim = p +
  transition_reveal(date) +
  shadow_wake(wake_length = 1/3, falloff = "cubic-in-out")

p_animate = animate(
  p_anim,
  nframes = 120,
  fps = 10,
  start_pause = 5,
  end_pause   = 15,
  width  = 800,
  height = 600,
  device =  'png',
  res    = 144
)
```

```{r country-trend-animate-save, echo=1, eval=FALSE}
p_animate

anim_save('_posts/2020-03-23-covid/img/covid.gif')

# for preview
p_animate_preview = animate(
  p_anim,
  nframes = 120,
  fps = 10,
  start_pause = 5,
  end_pause   = 15,
  width  = 400,
  height = 300,
  device =  'png',
  res    = 72
)

p_animate_preview
  
anim_save('img/covid_preview.gif')
```

```{r  country-trend-animate-show, echo=FALSE, layout='l-body'}
knitr::include_graphics('img/covid.gif')
```


<!-- <img src="../../img/covid.gif" style="display:block; margin: 0 auto; width: 100%;"> -->

### NY Times-style Daily Count

The following is similar to the plot shown on the [New York Times daily count](https://www.nytimes.com/interactive/2020/world/coronavirus-maps.html), just without the unnecessary discretizing of the color (the legend already does that for you).  I chose what I thought was a similar palette, but obviously you can play around with that.

```{r nytimes-daily}
# reduce to just the 20 countries with the most cases
top_20 = world_totals %>% 
  top_n(20, total_confirmed) %>% 
  arrange(desc(total_confirmed))
 
# this is to create a ruled effect, not necessary
plot_data = main %>%
  filter(is.na(region_code)) %>%
  filter(country_name %in% top_20$country_name) %>%
  mutate(
    country_name   = ordered(country_name, levels = rev(top_20$country_name)),
    line_positions = as.numeric(country_name) + .5,
    line_positions = ifelse(line_positions == max(line_positions), NA, line_positions)
  ) 
  
plot_data %>% 
  ggplot(aes(x = date, y = country_name)) +
  geom_tile(
    aes(
      fill   = daily_confirmed,
      width  = .9,
      height = 0.5
    ),
    na.rm = T,
    size  = 2
  ) +
  geom_hline(
    aes(yintercept = line_positions),
    color = 'gray92',
    size  = .25
  ) +
  scico::scale_fill_scico(
    end = .75,
    na.value = 'gray98',
    palette  = 'lajolla',
    trans    = 'log',
    breaks   = c(5, 25, 100, 500, 2500)
  ) +
  labs(x = '', y = '') +
  guides(fill = guide_legend(title = 'New Cases')) +
  visibly::theme_clean() +
  theme(
    axis.ticks.y = element_blank(),
    legend.text  = element_text(size = 6),
    legend.title = element_text(size = 10)
  )
```


The following shows the percentage increase in cases over the previous day (capped at 100 or greater).  Early on this isn't very useful (e.g. going from 5 to 10 is a 100% increase).  We can see that China and South Korea have minimal to no increase day to day at present, while other countries are continuing to see relatively large increases.

```{r percent-new-cases, echo = FALSE}
plot_data = main %>%
  filter(is.na(region_code)) %>%
  filter(country_name %in% top_20$country_name) %>% 
  group_by(country_code) %>% 
  mutate(
    daily_perc = 100 * (total_confirmed / lag(total_confirmed) - 1), 
    daily_perc = ifelse(daily_perc > 100, 100, daily_perc)
  ) %>% 
  ungroup() %>% 
  mutate(
    country_name   = ordered(country_name, levels = rev(top_20$country_name)),
    line_positions = as.numeric(country_name) + .5,
    line_positions = ifelse(line_positions == max(line_positions), NA, line_positions)
  ) 
  

plot_data %>% 
  ggplot(aes(x = date, y = country_name)) +
  geom_tile(
    aes(
      fill   = daily_perc,
      width  = .9,
      height = 0.5
    ),
    na.rm = T,
    size  = 2
  ) +
  geom_hline(
    aes(yintercept = line_positions),
    color = 'gray92',
    size  = .25
  ) +
  scico::scale_fill_scico(
    end = .75,
    na.value = 'gray98',
    palette  = 'lajolla',
    # trans    = 'log',
    # breaks   = c(seq(0, 100, 10))
  ) +
  labs(x = '', y = '') +
  guides(fill = guide_legend(title = '% New Cases')) +
  visibly::theme_clean() +
  theme(
    axis.ticks.y = element_blank(),
    legend.text  = element_text(size = 6),
    legend.title = element_text(size = 10)
  )
```

### Per Capita Country Trends

The following shows the number of confirmed cases per 10000 people.  However, this obviously doesn't account for the lack of testing.  To keep things clean, we again focus on the twenty countries with the most cases.

```{r world-top-20-per-capita, dpi = 320}
countries_rate = countries %>% 
  filter(country_code %in% top_20$country_code) %>% 
  mutate(rate = 10000*total_confirmed/population)

p = countries_rate %>% 
  ggplot(aes(x = date, y = rate)) +
  geom_path(aes(group = country_code), alpha = .1) +
  geom_point(
    aes(color = country_code),
    size  = .5,
    alpha = .5
  ) +
  geom_text_repel(
    aes(label = country_code, color = country_code),
    size  = 2,
    alpha = 1,
    data  = filter(countries_rate, date == max(date)-1),
    show.legend = FALSE
  ) +
  scico::scale_color_scico_d(begin = .1, end = .9) +
  scale_x_date(
    date_breaks = '2 weeks',
    labels = function(x) format(x, format = "%m/%d")
  ) +
  scale_y_continuous(
    position = "right"
  ) +
  visibly::theme_clean() + 
  labs(
    x = '', 
    y = '',
    subtitle =  'Confirmed Cases Per Ten Thousand People'
    ) +
  theme(
    axis.text.x  = element_text(size = 6),
    axis.text.y  = element_text(size = 6),
    axis.title.y = element_text(size = 6),
    axis.ticks.y = element_blank(),
    legend.title       = element_blank(),
    legend.key.size    = unit(.25, 'cm'),
    legend.text        = element_text(size = 6),
    legend.box.spacing = unit(0, 'mm'),
    legend.box.margin  = margin(0),
    legend.position    = 'left',
    title = element_text(size = 12)
  )

p
```


## US Trends

### Trends

We can visualize the state level data in numerous ways.  Here is the world trend plot previously seen, now applied just to the U.S. 


```{r state_trends, cache.rebuild=F, layout='l-body-offset'}
highlight = us_current %>% 
  filter(!is.na(region_code)) %>% 
  top_n(10, total_confirmed) %>% 
  pull(region_name)

p = us %>% 
  ggplot(aes(x = date, y = total_confirmed)) +
  geom_path(aes(group = region_code), alpha = .01) +
  geom_point(
    aes(),
    size  = 6,
    alpha = .1,
    data  = filter(us, is.na(region_code))
  ) +
  geom_point(
    aes(color = region_code),
    size  = 1.5,
    alpha = .5,
    data  = filter(us, region_name %in% highlight)
  ) +
  geom_text_repel(
    aes(label = region_code, color = region_code),
    size  = 2,
    alpha = .85,
    data  = filter(us_current, region_name %in% highlight)
  ) +
  scico::scale_color_scico_d(begin = .1, end = .9) +
  scale_x_date(date_breaks = '2 weeks') +
  scale_y_continuous(
    position = "right",
    trans    = 'log',
    breaks   = c(50, unlist(map(c(1,5), function(x) x*10^(2:6)))), 
    labels   = scales::comma
    ) +
  visibly::theme_clean() + 
  labs(
    x = '', 
    y = '',
    subtitle =  'Total Confirmed Cases',
    caption = 'Dark large dot is U.S. total'
    ) +
  theme(
    axis.text.x  = element_text(size = 6),
    axis.text.y  = element_text(size = 6),
    axis.title.y = element_text(size = 6),
    axis.ticks.y = element_blank(),
    legend.title       = element_blank(),
    legend.key.size    = unit(.25, 'cm'),
    legend.text        = element_text(size = 6),
    legend.box.spacing = unit(0, 'mm'),
    legend.box.margin  = margin(0),
    legend.position = 'left',
    title = element_text(size = 12)
  )

p
```

```{r trends-us-save, echo=FALSE}
ggsave('img/covid_us.svg')
```

### State Bins

Here we look at counts and death rates via a 'binned' map.  There are numerous issues with trying to depict numeric information on a map.  This at least tries to solve the issue of state size by making them all equal while retaining the basic shape of the U.S.


```{r statebins, layout="l-body-outset", cache.rebuild=F, out.width='800px'}
library(statebins)

us_current %>% 
  filter(region_code != 'DC') %>%
  statebins(
    state_col = 'region_name',
    value_col = "log(total_confirmed)",
    palette   = "OrRd", 
    direction = 1,
    name = "Covid Counts (log)"
  ) +
  theme_statebins(base_size = 8)

us_current %>% 
  filter(!is.na(region_name)) %>% 
  statebins(
    state_col = 'region_name',
    value_col = "death_rate",
    palette   = "OrRd", 
    direction = 1,
    name = "Death Rate"
  ) +
  theme_statebins(base_size = 8)
```

### Geofacet

We can plot trends in a map-like fashion too, and the following uses the <span class="pack" style = "">geofacet</span> package. As of late March, this is one of the scarier graphics, with no flattening in sight.

```{r geo-facet-trends, layout='l-page'}
library(geofacet)

us %>% 
  filter(total_confirmed != 0, region_code != 'DC') %>%
  ggplot(aes(date, total_confirmed, group = region_code)) +
  geom_path(color = '#ff550080') +
  labs(y = '', x = '') +
  facet_geo(~region_code, scales = 'free') +
  visibly::theme_clean() +
  theme(
    axis.text.x  = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.y  = element_text(size = 4),
    strip.text   = element_text(size = 4),
  )
```


### Daily counts

We can do the daily counts as before.

```{r us-daily, dpi = 144, cache.rebuild=F}
levs = us_current %>% 
  filter(!is.na(region_name)) %>% 
  arrange(total_confirmed) %>% 
  pull(region_name)

plot_data = us %>%
  filter(!is.na(region_code)) %>%
  mutate(
    region_name    = ordered(region_name, levels = levs),
    line_positions = as.numeric(region_name) + .5,
    line_positions = ifelse(line_positions == max(line_positions), NA, line_positions)
  ) 
  
plot_data %>% 
  ggplot(aes(x = date, y = region_name)) +
  geom_tile(
    aes(
      fill   = daily_confirmed,
      width  = .9,
      height = 0.5
    ),
    na.rm = T,
    size  = 2
  ) +
  geom_hline(
    aes(yintercept = line_positions),
    color = 'gray92',
    size  = .25
  ) +
  scico::scale_fill_scico(
    end = .75,
    na.value = 'gray98',
    palette  = 'lajolla',
    trans    = 'log',
    breaks   = c(5, 25, 100, 500, 2500)
  ) +
  labs(x = '', y = '') +
  guides(fill = guide_legend(title = 'New Cases')) +
  visibly::theme_clean() +
  theme(
    axis.text.y  = element_text(size = 6),
    axis.ticks.y = element_blank(),
    legend.text  = element_text(size = 6),
    legend.title = element_text(size = 10)
  )
```

### Per Capita State Trends

The following shows the number of confirmed cases per 10000 people.  Highlighted are the states with the most total cases (top 10).

```{r us-top-20-per-capita, echo = F, dpi = 320}
state_pop = readxl::read_xlsx('data/census-pop-2019.xlsx', col_names = T, skip = 1) %>% 
  select(region, `2019`) %>% 
  mutate(region = str_remove_all(region, '\\.')) %>% 
  rename(region_name = region, population = `2019`)

us_rate = us %>% 
  filter(!is.na(region_code)) %>% 
  select(-population) %>% 
  left_join(state_pop, by = 'region_name') %>% 
  mutate(rate = 10000*total_confirmed/population)


p = us_rate %>% 
  ggplot(aes(x = date, y = rate)) +
  geom_path(aes(group = region_code), alpha = .05) +
  geom_point(
    aes(color = region_code),
    size  = 1.5,
    alpha = .5,
    data = filter(us_rate, region_name %in% highlight)
  ) +
  geom_text_repel(
    aes(label = region_code, color = region_code),
    size  = 2,
    alpha = 1,
    data  = filter(us_rate, region_name %in% highlight, date == max(date)),
    show.legend = FALSE
  ) +
  scico::scale_color_scico_d(begin = .1, end = .9) +
  scale_x_date(
    date_breaks = '2 weeks',
    labels = function(x) format(x, format = "%m/%d")
  ) +
  scale_y_continuous(
    position = "right"
  ) +
  visibly::theme_clean() + 
  labs(
    x = '', 
    y = '',
    subtitle =  'Confirmed Cases Per Ten Thousand People'
    ) +
  theme(
    axis.text.x  = element_text(size = 6),
    axis.text.y  = element_text(size = 6),
    axis.title.y = element_text(size = 6),
    axis.ticks.y = element_blank(),
    legend.title       = element_blank(),
    legend.key.size    = unit(.25, 'cm'),
    legend.text        = element_text(size = 6),
    legend.box.spacing = unit(0, 'mm'),
    legend.box.margin  = margin(0),
    legend.position    = 'left',
    title = element_text(size = 12)
  )

p
```


## County Trends

The following function gets county level data trends from the Johns Hopkins data base.  The format and collection of this data fundamentally changed on March 22, so we begin there.  You can modify this function to grab data from other countries, but the data sets do not match to those previous to that date.

```{r get-county-data-function}
get_county_data = function(
  first_date = lubridate::mdy('03-22-2020'),
  last_date  = Sys.Date() - 1,
  parallel = FALSE
) {
  
  base_url = 'https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_daily_reports/'
  
  dates = first_date:last_date
  
  if (parallel) {
    library(future)
    library(furrr)
    
    suppressWarnings({plan(multiprocess)})
    
    result = future_map_dfr(
      dates, 
      function(date)
        suppressWarnings({
          read_csv(
            paste0(
              base_url,
              format(lubridate::as_date(date), format = '%m-%d-%Y'),
              '.csv'
            ),
            col_types = c('cccccddd')
          ) %>% mutate(date = lubridate::as_date(date))
        })
    )
    
    plan(sequential)
  }
  else {
    result = map_df(
      dates, 
      function(date)
        suppressWarnings({
          read_csv(
            paste0(
              base_url,
              format(lubridate::as_date(date), format = '%m-%d-%Y'),
              '.csv'
            ),
            col_types = c('cccccddd')
          ) %>% mutate(date = lubridate::as_date(date))
        })
      )
  }
  
  result %>%  
    rename_all(tolower) %>% 
    rename(
      county = admin2,
      state  = province_state,
      long   = long_
    ) %>% 
    filter(
      country_region == 'US',
      !state %in% c(
        'Puerto Rico',
        'Guam',
        'Northern Mariana Islands',
        'American Samoa',
        'Wuhan Evacuee',
        'Virgin Islands',
        'Grand Princess',
        'Diamond Princess'
      )
    ) %>% 
    select(date, everything()) %>% 
    mutate_at(vars(lat, long, confirmed), as.numeric) %>% 
    mutate(last_update = lubridate::as_datetime(last_update))
}
```


Now we can get the data. As time goes on, doing so in parallel will be quicker.

```{r get-county-data}
county_trends = get_county_data(parallel = TRUE)
```

### Michigan

The following creates an animated plot of Michigan counties over time.

```{r mi-county-map-animate}
library(sf)

mi_counties = county_trends %>% 
  filter(state == 'Michigan', date < '2020-04-01')

all_counties_sf = st_as_sf(maps::map("county", plot = FALSE, fill = TRUE))

prep_counties = mi_counties %>% 
  mutate(county = str_remove(tolower(county), '[[:punct:]]'), 
         state = tolower(state)) %>% 
  mutate(confirmed = if_else(is.na(confirmed), 0, confirmed))

mi_counties_sf = all_counties_sf %>% 
  filter(grepl("michigan", ID)) %>% 
  separate(ID, into = c('state', 'county'), remove = F, sep = ',') %>%
  select(-state) %>%
  left_join(prep_counties)

mi_plot =  mi_counties_sf %>% 
  ggplot() +
  geom_sf(aes(fill = confirmed), color = NA) +
  coord_sf(xlim = c(-91,-82),
           ylim = c(41, 48.5),
           expand = FALSE) +
  scico::scale_fill_scico(
    trans = 'log',
    breaks = c(1, 10, 50, 250, 1250, 5000),
    palette = 'lajolla',
    na.value = 'gray95'
  ) +
  guides(fill = guide_legend(title = '')) +
  theme_void() +
  theme(
    legend.key.size = unit(.25, 'cm'),
    legend.text     =  element_text(size = 6),
    legend.title    = element_text(size = 6)
  )

mi_plot
```

Now let's show it over time with <span class="pack" style = "">gganimate</span>.

```{r animate-show, eval=FALSE}
library(gganimate)

mi_plot_anim = mi_plot +
  labs(title = '{closest_state}') +
  transition_states(date, wrap = FALSE) +
  theme(title = element_text(color ='gray50'))

mi_plot_anim
```


```{r county-trend-anim-save, echo=FALSE, eval=FALSE}
animate(
  mi_plot_anim,
  nframes = 120,
  fps = 10,
  start_pause = 5,
  end_pause   = 15,
  width  = 800,
  height = 600,
  device =  'png',
  res    = 144
)

anim_save('img/mi-county-trend.gif')
```

```{r  county-trend-animate-show, echo=FALSE, layout='l-body'}
knitr::include_graphics('img/mi-county-trend.gif')
```

#### Interactive County Map

I thought I would try an interactive map for Michigan counties using highcharts via the <span class="pack" style = "">highcharter</span> package.  This requires creating a unique county code that is nothing more than a FIPS code (but oddly doesn't simply use the actual FIPS code).

```{r mi-county-interactive}
library(highcharter)

plot_data = mi_counties %>%
  filter(date == max(date)) %>%
  mutate(code = paste0('us-mi-', str_sub(fips, start = 3)))

hcmap(
  "countries/us/us-mi-all",
  data = plot_data,
  name = "Michigan",
  value = "confirmed",
  joinBy = c("hc-key", "code"),
  borderColor = "#fffff8",
  borderWidth = .1
) %>%
  hc_colorAxis(
    dataClasses = color_classes(
      c(0, 10, 100, 500, 1000, 2000, 5000),
      colors = scico::scico(6, end = .9, palette = 'lajolla')
    )
  ) %>%
  hc_legend(
    layout = "vertical",
    align = "right",
    floating = TRUE,
    valueDecimals = 0#,
    # valueSuffix = "%"
  ) %>% 
  hc_credits(enabled = FALSE)
```


### US

For the following map of the whole US, I wanted to do a point plot since counties are arbitrarily shaped, making it easy to think things are going weird in random places. We can use the county centroid locations, make very faint the county lines, and [not use a ridiculous point range size](https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html) to get a better sense of the overall pattern.  I'm not used to the <span class="pack" style = "">sf</span> package, so it took a while to get what I wanted beyond a simple county map.  Adding points was not very intuitive, but I got it sorted out in the end, so you get the benefit of the cleaned up code.

```{r us-county-map, layout='l-page'}
library(sf)

prep_counties = county_trends %>% 
  mutate(
    county = str_remove(tolower(county), '[[:punct:]]'),
    state  = tolower(state),
    confirmed = if_else(is.na(confirmed), 0, confirmed)
  ) %>% 
  filter(
    !state %in% c(
      'alaska',
      'hawaii'
    )
  ) 

all_counties_sf2 = all_counties_sf %>% 
  separate(ID, into = c('state', 'county'), remove = F, sep = ',') %>%
  left_join(prep_counties) %>% 
  select(ID, geom, everything())

county_point_plot = 
  ggplot(data = all_counties_sf2) +
  geom_sf(fill = 'gray99', color = 'gray97', size = .1) +
  geom_sf(
    aes(
      color = confirmed,
      size  = confirmed
    ),
    data = st_as_sf(
      prep_counties %>% drop_na(lat, long) %>% filter(lat > 0),
      coords = c('long', 'lat'),
      crs = '+proj=longlat'
    ),
    alpha = .1,
    show.legend = F
  ) +
  scico::scale_color_scico(
    trans    = 'log',
    breaks   = c(1, 10, 50, 250, 1250, 5000),
    na.value = 'gray99'
  ) +
  labs(title = 'Confirmed cases') +
  scale_size_continuous(range =  c(.1, 10)) +
  theme_void()  +
  theme(title = element_text(color = 'gray50'))

county_point_plot
```

What's interesting is if we do a similar plot, but actually look for more anomalous results, rather than just calling more largely populated areas hotspots.  To do this we need either a per capita rate, a percentage change or similar, or even adjusting the size range, while making the assumption that populated areas are already the ones that are going to have the most cases.


I grabbed population values with <span class="pack" style = "">tidycensus</span> (not shown), then removed the top 20 most populated counties from consideration.  You can get the data [here](https://github.com/m-clark/m-clark.github.io/raw/master/data/census-county-population.csv). 


The visualization shows numerous hotspots across the deep south, and others not considered in the midwest, e.g. the Indianapolis area, Rocky Mountain areas, and more.  It definitely makes the spread more apparent than the simple counts might suggest.

```{r get-county-census-pop, eval=FALSE, echo=FALSE}
state_codes = state.abb

library(future)
library(furrr)

plan(multiprocess)

pop <- future_map_dfr(
  state.abb,
  function(state)
    get_acs(
      geography = "county", 
      variables = c(population = "B01003_001"), 
      state = state, 
      year = 2018
    )
)
  
plan(sequential)

write_csv(pop, 'data/census-county-population.csv')
```

```{r county-rates, layout='l-page', echo=FALSE}
pop = read_csv('data/census-county-population.csv')

prep_counties = county_trends %>% 
  filter(date == max(date)) %>% 
  left_join(pop, by = c('fips' = 'GEOID')) %>% 
  mutate(
    county = str_remove(tolower(county), '[[:punct:]]'),
    state  = tolower(state),
    confirmed = if_else(is.na(confirmed), 0, confirmed)
  ) %>% 
  rename(population = estimate) %>% 
  mutate(rate = 10000*confirmed/population) %>% 
  filter(
    !state %in% c(
      'alaska',
      'hawaii'
    )
  ) %>% 
  arrange(desc(population)) %>% 
  slice(-(1:20))
  
  
all_counties_sf2 = all_counties_sf %>% 
  separate(ID, into = c('state', 'county'), remove = F, sep = ',') %>%
  left_join(prep_counties) %>% 
  select(ID, geom, everything())

county_point_plot = 
  ggplot(data = all_counties_sf2) +
  geom_sf(fill = 'gray99', color = 'gray97', size = .1) +
  geom_sf(
    aes(
      color = rate,
      size  = rate
    ),
    data = st_as_sf(
      prep_counties %>% drop_na(lat, long) %>% filter(lat > 0),
      coords = c('long', 'lat'),
      crs = '+proj=longlat'
    ),
    alpha = .2,
    show.legend = F) +
  scico::scale_color_scico(
    trans    = 'log',
    na.value = 'gray99'
  ) +
  scale_size_continuous(range =  c(.1, 10)) +
  labs(title = 'Cases per 10000', subtitle = 'Top 20 most populous counties not considered') +
  theme_void() +
  theme(title = element_text(color = 'gray50'))

county_point_plot
```



```{r all-county-anim, echo=FALSE, eval=FALSE}
## old code
# library("rnaturalearth")
# library("rnaturalearthdata")
# 
# world_map <- ne_countries(scale = "medium", returnclass = "sf")
# world_map_2 <-
#   st_as_sf(maps::map("world", plot = FALSE, fill = TRUE))
# us_map <-
#   ne_countries(scale = "medium",
#                country = 'United States of America',
#                returnclass = "sf")
# us_map <-
#   ne_countries(
#     scale = "medium",
#     country = 'United States of America',
#     type = 'map_units',
#     returnclass = "sf"
#   )
# 
# all_states_sf <- st_as_sf(maps::map("state", plot = FALSE, fill = TRUE))

# doesn't really work
all_plot_anim = all_plot +
  labs(title = '{closest_state}') +
  transition_states(states = date) +
  theme(
    title = element_text(color ='gray50')
  )

all_plot_anim
```

#### Interactive County Map

If you do want an actual county map, here is an interactive one as before.  To make it easier I add state abbreviations to the original data before creating codes for every county. A value is initially missing for Oglala county South Dakota, because highcharts hasn't updated its map data source in several years, and it has since been renamed from Shannon county. Likewise, in Alaska, highcharts still refers to Wade Hampton rather than Kusilvak.

```{r us-county-interactive, layout='l-page'}
states = tibble(state = state.name, state_abb = state.abb)

plot_data = county_trends %>%
  mutate(confirmed = if_else(is.na(confirmed), 0, confirmed)) %>% 
  filter(date == max(date)) %>% 
  left_join(states) %>% 
  mutate(
    code = paste0('us-', tolower(state_abb), '-', str_sub(fips, start = 3)),
    code = if_else(code == 'us-sd-102', 'us-sd-113', code),  # Oglala
    code = if_else(code == 'us-ak-158', 'us-ak-270', code),  # Kusilvak
  )
  

# plot_data

hcmap(
  "countries/us/us-all-all",
  data = plot_data,
  name = "Confirmed cases:",
  value = "confirmed",
  joinBy = c("hc-key", "code"),
  borderColor = "#fffff8",
  borderWidth = .1,
  download_map_data = T
) %>%
  hc_colorAxis(
    dataClasses = color_classes(
      c(0, sort(unlist(map(c(1, 5), function(x)  x * 10^(1:4))))),
      colors = scico::scico(6, end = .9, palette = 'lajolla')
    )
  ) %>%
  hc_legend(
    layout = "vertical",
    align = "right",
    floating = TRUE,
    valueDecimals = 0#,
    # valueSuffix = "%"
  ) %>% 
  hc_credits(enabled = FALSE)
```

<!-- ## Model Country Trends -->

<!-- ```{r} -->
<!-- # Model it ---------------------------------------------------------------- -->


<!-- # plot doubling -->

<!-- countries %>% -->
<!--   qplot( -->
<!--   data = ., -->
<!--   x = date, -->
<!--   y = total_confirmed, -->
<!--   geom = 'path', -->
<!--   color = country_code, -->
<!--   show.legend = F -->
<!-- ) -->

<!-- # plot derivs -->
<!-- all_for_model = countries %>% -->
<!--   mutate(country_code = factor(country_code), -->
<!--          date_num = as.numeric(date)) %>% -->
<!--   filter(is.na(region_code)) %>% -->
<!--   select(-contains('region'), -latitude, -longitude) %>% -->
<!--   group_by(country_name) %>% -->
<!--   mutate(N = n(), total_confirmed_log = log(total_confirmed + 1)) %>% -->
<!--   ungroup() %>% -->
<!--   filter( -->
<!--     (country_name %in% highlight | -->
<!--        N >= 40 -->
<!--     ) & -->
<!--       date >= '2020-02-01' -->
<!--   ) %>% -->
<!--   droplevels() -->


<!-- library(lubridate) -->

<!-- library(mgcv) -->

<!-- mod = bam( -->
<!--   total_confirmed ~ s(date_num, country_code, bs = 'fs', k = 5), -->
<!--   # family = ziP(), -->
<!--   # family = Gamma(link = 'log'), -->
<!--   family = gaussian(link = 'log'), -->
<!--   data = all_for_model, -->
<!--   # nthreads = 10, -->
<!--   discrete = FALSE -->
<!-- ) -->

<!-- summary(mod) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- highlight = all_for_model %>% -->
<!--   filter(country_name %in% highlight) %>% -->
<!--   pull(country_code) -->

<!-- visibly::plot_gam_by( -->
<!--   mod, -->
<!--   date_num, -->
<!--   country_code, -->
<!--   begin = .1, -->
<!--   end = .8, -->
<!--   alpha = .25 -->
<!--   ) + -->
<!--   geom_text( -->
<!--     aes(label = country_code), -->
<!--     size = 2, -->
<!--     vjust = -.75, -->
<!--     show.legend = FALSE, -->
<!--     data = . %>% filter(date_num == max(date_num) & country_code %in% highlight) -->
<!--   ) + -->
<!--   guides(color = 'none') -->
<!-- ``` -->

<!-- ```{r} -->
<!-- library(gratia) -->

<!-- deriv_dat_1 = derivatives(mod, term = 'date_num', n = 250) -->

<!-- plot_dat = deriv_dat_1 %>% -->
<!--   mutate( -->
<!--     date = lubridate::as_date(data), -->
<!--     country_code = str_remove_all(smooth, 's\\(date_num\\):country_code'), -->
<!--     country_code = fs_var -->
<!--   ) -->


<!-- plot_dat_peaks_valleys = plot_dat %>% -->
<!--   group_by(country_code) %>% -->
<!--   slice(quantmod::findPeaks(derivative) - 1, -->
<!--         quantmod::findValleys(derivative) - 1)  # see helpfile for why -1 -->

<!-- library(ggrepel) -->

<!-- plot_dat %>% -->
<!--   ggplot(aes(date, y = derivative)) + -->
<!--   # geom_ribbon(aes(ymin=lower, ymax=upper, group=country_code), alpha = .02) + -->
<!--   geom_hline(yintercept = 0, color = 'gray92') + -->
<!--   geom_line(aes(color = country_code), alpha = .5) + -->
<!--   # geom_point( -->
<!--   #   aes(color = country_code), -->
<!--   #   size = 2, -->
<!--   #   data = plot_dat_peaks_valleys %>% filter(country_code == 'CN') -->
<!--   # ) + -->
<!--   # geom_text_repel( -->
<!--   #   aes(label = as.character(date), color = country_code), -->
<!--   #   size = 2, -->
<!--   #   alpha = .5, -->
<!--   #   data = plot_dat_peaks_valleys %>% filter(country_code == 'CN') -->
<!--   # ) + -->
<!--   geom_text_repel( -->
<!--     aes(label = country_code), -->
<!--     size = 2, -->
<!--     alpha = .5, -->
<!--     data = plot_dat %>% filter(date == max(date) & derivative > 1000) -->
<!--   ) + -->
<!--   guides(color = 'none') + -->
<!--   labs(x = '') + -->
<!--   scico::scale_color_scico_d(begin = .25, end = .75) + -->
<!--   visibly::theme_clean() + -->
<!--   theme(legend.position = 'bottom') -->
<!-- ``` -->

