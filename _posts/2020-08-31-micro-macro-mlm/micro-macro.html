<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
  <title>Micro-macro models</title>
  
  <meta property="description" itemprop="description" content="An analysis in the wrong direction? Predicting group level targets with lower level covariates."/>
  
  
  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2020-08-31"/>
  <meta property="article:created" itemprop="dateCreated" content="2020-08-31"/>
  <meta name="article:author" content="Michael Clark"/>
  
  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Micro-macro models"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="An analysis in the wrong direction? Predicting group level targets with lower level covariates."/>
  <meta property="og:locale" content="en_US"/>
  
  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Micro-macro models"/>
  <meta property="twitter:description" content="An analysis in the wrong direction? Predicting group level targets with lower level covariates."/>
  
  <!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Reliability from $\alpha$ to $\omega$: A tutorial.;citation_publication_date=2019;citation_publisher=American Psychological Association;citation_volume=31;citation_author=William Revelle;citation_author=David M Condon"/>
  <meta name="citation_reference" content="citation_title=Hypothesis testing using factor score regression: A comparison of four methods;citation_publication_date=2016;citation_publisher=Sage Publications Sage CA: Los Angeles, CA;citation_volume=76;citation_author=Ines Devlieger;citation_author=Axel Mayer;citation_author=Yves Rosseel"/>
  <meta name="citation_reference" content="citation_title=Predicting group-level outcome variables: An empirical comparison of analysis strategies;citation_publication_date=2018;citation_publisher=Springer;citation_volume=50;citation_author=Lynn Foster-Johnson;citation_author=Jeffrey D Kromrey"/>
  <!--radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","preview","output","bibliography","draft","tags","categories","date"]}},"value":[{"type":"character","attributes":{},"value":["Micro-macro models"]},{"type":"character","attributes":{},"value":["An analysis in the wrong direction? Predicting group level targets with lower level covariates.\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Michael Clark"]},{"type":"character","attributes":{},"value":["https://m-clark.github.io"]}]}]},{"type":"character","attributes":{},"value":["../../img/micromacro/sem.png"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc","css"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["../../styles.css"]}]}]},{"type":"character","attributes":{},"value":["../../bibs/mixed.bib"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["mixed models","multilevel models micro-macro","macro-micro","measurement error","bias","group-level outcomes","structural model"]},{"type":"character","attributes":{},"value":["mixed models"]},{"type":"character","attributes":{},"value":["08-31-2020"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["micro-macro_files/bowser-1.9.3/bowser.min.js","micro-macro_files/DiagrammeR-styles-0.2/styles.css","micro-macro_files/distill-2.2.21/template.v2.js","micro-macro_files/grViz-binding-1.0.6.1/grViz.js","micro-macro_files/htmlwidgets-1.5.1/htmlwidgets.js","micro-macro_files/jquery-1.11.3/jquery.min.js","micro-macro_files/kePrint-0.0.1/kePrint.js","micro-macro_files/viz-1.8.2/viz.js","micro-macro_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->
  
  <style type="text/css">
  
  body {
    background-color: white;
  }
  
  .pandoc-table {
    width: 100%;
  }
  
  .pandoc-table>caption {
    margin-bottom: 10px;
  }
  
  .pandoc-table th:not([align]) {
    text-align: left;
  }
  
  .pagedtable-footer {
    font-size: 15px;
  }
  
  .html-widget {
    margin-bottom: 2.0em;
  }
  
  .l-screen-inset {
    padding-right: 16px;
  }
  
  .l-screen .caption {
    margin-left: 10px;
  }
  
  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .shaded-content {
    background: white;
  }
  
  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }
  
  .hidden {
    display: none !important;
  }
  
  d-article {
    padding-bottom: 30px;
  }
  
  d-appendix {
    padding-top: 30px;
  }
  
  d-article>p>img {
    width: 100%;
  }
  
  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }
  
  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  /* CSS for table of contents */
  
  .d-toc {
    color: rgba(0,0,0,0.8);
    font-size: 0.8em;
    line-height: 1em;
  }
  
  .d-toc-header {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    text-transform: uppercase;
    margin-top: 0;
    margin-bottom: 1.3em;
  }
  
  .d-toc a {
    border-bottom: none;
  }
  
  .d-toc ul {
    padding-left: 0;
  }
  
  .d-toc li>ul {
    padding-top: 0.8em;
    padding-left: 16px;
    margin-bottom: 0.6em;
  }
  
  .d-toc ul,
  .d-toc li {
    list-style-type: none;
  }
  
  .d-toc li {
    margin-bottom: 0.9em;
  }
  
  .d-toc-separator {
    margin-top: 20px;
    margin-bottom: 2em;
  }
  
  .d-article-with-toc {
    border-top: none;
    padding-top: 0;
  }
  
  
  
  /* Tweak code blocks (note that this CSS is repeated above in an injection
     into the d-code shadow dom) */
  
  d-code {
    overflow-x: auto !important;
  }
  
  pre.d-code code.d-code {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }
  
  pre.text-output {
  
    font-size: 12px;
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  @media(min-width: 768px) {
  
  d-code {
    overflow-x: visible !important;
  }
  
  pre.d-code code.d-code  {
      padding-left: 18px;
      font-size: 14px;
  }
  pre.text-output {
    font-size: 14px;
  }
  }
  
  /* Figure */
  
  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }
  
  .figure img {
    width: 100%;
  }
  
  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }
  
  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }
  
  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }
  
  
  
  /* Tweak 1000px media break to show more text */
  
  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }
  
    .grid {
      grid-column-gap: 16px;
    }
  
    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }
  
  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }
  
    .grid {
      grid-column-gap: 32px;
    }
  }
  
  
  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */
  
  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  
  
  /* Social footer */
  
  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }
  
  .disqus-comments {
    margin-right: 30px;
  }
  
  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }
  
  #disqus_thread {
    margin-top: 30px;
  }
  
  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }
  
  .article-sharing a:hover {
    border-bottom: none;
  }
  
  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .subscribe p {
    margin-bottom: 0.5em;
  }
  
  
  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }
  
  
  .sidebar-section.custom {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .custom p {
    margin-bottom: 0.5em;
  }
  
  
  /* Improve display for browsers without grid (IE/Edge <= 15) */
  
  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }
  
  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }
  
  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }
  
  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }
  
  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }
  
  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }
  
  
  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }
  
  .downlevel .footnotes ol {
    padding-left: 13px;
  }
  
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }
  
  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }
  
  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }
  
  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  </style>
  
  <script type="application/javascript">
  
  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }
  
  // show body when load is complete
  function on_load_complete() {
  
    // set body to visible
    document.body.style.visibility = 'visible';
  
    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }
  
    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }
  
  function init_distill() {
  
    init_common();
  
    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);
  
    // create d-title
    $('.d-title').changeElementType('d-title');
  
    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);
  
    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();
  
    // move posts container into article
    $('.posts-container').appendTo($('d-article'));
  
    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');
  
    // create d-bibliography
    var bibliography = $('<d-bibliography></d-bibliography>');
    $('#distill-bibliography').wrap(bibliography);
  
    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;
  
    // replace citations with <d-cite>
    $('.citation').each(function(i, val) {
      appendix = true;
      var cites = $(this).attr('data-cites').split(" ");
      var dt_cite = $('<d-cite></d-cite>');
      dt_cite.attr('key', cites.join());
      $(this).replaceWith(dt_cite);
    });
    // remove refs
    $('#refs').remove();
  
    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();
  
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-toc a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });
  
    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');
  
    // replace code blocks with d-code
    $('pre>code').each(function(i, val) {
      var code = $(this);
      var pre = code.parent();
      var clz = "";
      var language = pre.attr('class');
      if (language) {
        // map unknown languages to "clike" (without this they just dissapear)
        if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                                 "javascript", "js", "julia", "lua", "markdown",
                                 "markup", "mathml", "python", "svg", "xml"]) == -1)
          language = "clike";
        language = ' language="' + language + '"';
        var dt_code = $('<d-code block' + language + clz + '></d-code>');
        dt_code.text(code.text());
        pre.replaceWith(dt_code);
      } else {
        code.addClass('text-output').unwrap().changeElementType('pre');
      }
    });
  
    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {
  
      // capture layout
      var layout = $(this).attr('data-layout');
  
      // apply layout to markdown level block elements
      var elements = $(this).children().not('d-code, pre.text-output, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });
  
  
      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });
  
    // load distill framework
    load_distill_framework();
  
    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {
  
      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;
  
      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');
  
      // table of contents
      if (have_authors) // adjust border if we are in authors
        $('.d-toc').parent().addClass('d-article-with-toc');
  
      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');
  
      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }
  
      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');
  
      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");
  
      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }
  
       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }
  
      // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
      $('d-code').each(function(i, val) {
        var style = document.createElement('style');
        style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                          '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
        if (this.shadowRoot)
          this.shadowRoot.appendChild(style);
      });
  
      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();
  
      // clear polling timer
      clearInterval(tid);
  
      // show body now that everything is ready
      on_load_complete();
    }
  
    var tid = setInterval(distill_post_process, 50);
    distill_post_process();
  
  }
  
  function init_downlevel() {
  
    init_common();
  
     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));
  
    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
  
    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();
  
    // remove toc
    $('.d-toc-header').remove();
    $('.d-toc').remove();
    $('.d-toc-separator').remove();
  
    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });
  
  
    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);
  
    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);
  
    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();
  
    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();
  
    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));
  
    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });
  
    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));
  
    $('body').addClass('downlevel');
  
    on_load_complete();
  }
  
  
  function init_common() {
  
    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};
  
        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });
  
        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);
  
    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});
  
    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });
  
      }
    });
  
    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });
  
    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }
  
    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');
  
    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");
  
    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();
  
    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }
  
  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });
  
  </script>
  
  <!--/radix_placeholder_distill-->
  <script src="micro-macro_files/htmlwidgets-1.5.1/htmlwidgets.js"></script>
  <script src="micro-macro_files/viz-1.8.2/viz.js"></script>
  <link href="micro-macro_files/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
  <script src="micro-macro_files/grViz-binding-1.0.6.1/grViz.js"></script>
  <script src="micro-macro_files/kePrint-0.0.1/kePrint.js"></script>
  <script src="micro-macro_files/jquery-1.11.3/jquery.min.js"></script>
  <script src="micro-macro_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="micro-macro_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="micro-macro_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->

  <link rel="stylesheet" href="../../styles.css" type="text/css"/>

</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Micro-macro models","description":"An analysis in the wrong direction? Predicting group level targets with lower level covariates.","authors":[{"author":"Michael Clark","authorURL":"https://m-clark.github.io","affiliation":"&nbsp;","affiliationURL":"#"}],"publishedDate":"2020-08-31T00:00:00.000-04:00","citationText":"Clark, 2020"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Micro-macro models</h1>
<p><p>An analysis in the wrong direction? Predicting group level targets with lower level covariates.</p></p>
</div>

<div class="d-byline">
  Michael Clark <a href="https://m-clark.github.io" class="uri">https://m-clark.github.io</a> 
  
<br/>08-31-2020
</div>

<div class="d-article">
<h3 class="d-toc-header">Table of Contents</h3>
<nav class="d-toc" id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#predicting-group-level-outcomes">Predicting Group-Level Outcomes</a></li>
<li><a href="#issues-with-aggregate-approaches">Issues with Aggregate Approaches</a></li>
<li><a href="#issues-with-adjustment">Issues with Adjustment</a></li>
<li><a href="#my-perspective">My Perspective</a></li>
<li><a href="#model-setup">Model Setup</a></li>
<li><a href="#data-setup">Data Setup</a></li>
<li><a href="#results">Results</a></li>
<li><a href="#reliability">Reliability</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
</nav>
<hr class="d-toc-separator"/>
<h2 id="introduction">Introduction</h2>
<p>Every once in a while, it comes up that someone has clustered data, with covariates that vary at different levels, and where mixed models or similar would normally be implemented, but in which the target variable only varies at the cluster level (or ‘group’ level- I will use the terms interchangeably). Though the outcome is at the cluster level, the individual may still want to use information from lower-level/within-cluster variables. Such situations are generically referred to as <em>micro-macro</em> models, to distinguish between the standard setting where the target varies at the lower level (which does not require a special name). An example might be using team member traits to predict team level scores. While conceptually one wants to use all available information in a model, normally we just run a model at the cluster (team) level using summaries of variables that would otherwise vary within the cluster, for example, using mean scores or proportions. Not only is it natural, it makes conceptual sense, and as such it is the default approach. Alternatives include using the within cluster variables as predictors, but this wouldn’t be applicable except in balanced settings where they would represent the same thing for each group, and even in the balanced settings collinearity might be a notable issue. So how would we deal with this?</p>
<h2 id="predicting-group-level-outcomes">Predicting Group-Level Outcomes</h2>
<p>Croon and van Veldhoven <span class="citation" data-cites="croon2007predicting">Croon and Veldhoven (<a href="#ref-croon2007predicting" role="doc-biblioref">2007</a>)</span> (CV) present a group-level regression model (e.g. a basic linear model) as follows.</p>
<p><span class="math display">\[y_g = \beta_0 + \xi_g\beta_1 + Z_g\beta_2 + \epsilon_g\]</span></p>
<p>In this depiction, <span class="math inline">\(y_g\)</span> is the group level target variable, the <span class="math inline">\(Z_g\)</span> represent the typical observed group-level covariates and corresponding coefficients (<span class="math inline">\(\beta_2\)</span>). If this were the entirety of the model, there would be no ‘levels’ to consider and we could use a standard model, say OLS regression. In the case we are interested in, some variables vary within these clusters, while others do not. Again, normally we might do a mixed model, but remember, <span class="math inline">\(y_g\)</span> only varies at the group level, so that won’t really work.</p>
<p>In this setting then, <span class="math inline">\(\xi_g\)</span> represents an aggregated effect of the lower level variables. In standard practice it would just be the calculated mean, proportion, or some other metric with values for each cluster. In the CV depiction however, it is a <em>latent</em> (or perhaps several) latent variables and their corresponding effects <span class="math inline">\(\beta_1\)</span>.</p>
<p>If we assume a single <span class="math inline">\(\xi_g\)</span> variable, the model for the underlying within-cluster variables is the standard latent variable model, a.k.a factor analysis. With an observed multivariate <span class="math inline">\(x\)</span>, e.g. repeated observations of some measure for an individual or, as before, team member scores, we have the <a href="https://m-clark.github.io/docs/FA_notes.html">latent linear model</a> as follows:</p>
<p><span class="math display">\[\textbf{x}_{ig} = \xi_g\lambda + v_{ig}\]</span></p>
<p>where <span class="math inline">\(x_{ig}\)</span> are the (possibly repeated) observations <span class="math inline">\(i\)</span> for a group/individual <span class="math inline">\(g\)</span>, <span class="math inline">\(\lambda\)</span> are the factor loadings and variances are constant. We can now see the full model as a structural equation model as follows for a situation with five observations per group.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure" style="text-align: center"><span id="fig:sem-plot"></span>
<div id="htmlwidget-efb0aa0f6c7fa2e42672" style="width:624px;height:436.8px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-efb0aa0f6c7fa2e42672">{"x":{"diagram":"digraph Factor  {\n  // basically everything about this is ignored besides the most basic attributes\n  graph [rankdir=TB  bgcolor=transparent splines=\"line\"]\n  \n  subgraph structural {\n    rank=min // puts z and y first\n    node [fontname=\"Roboto\" fontsize=10 fontcolor=gray50 shape=box width=.5 color=\"#ff5500\"];\n    edge [fontname=\"Roboto\" fontsize=10 fontcolor=gray50 color=\"#00aaff80\" minlen=3 arrowsize=.5];\n   \n    node [shape=square width=.5 fontcolor=\"#fffff8\" color=\"transparent\" \n    fillcolor=\"#00aaff80\" style=filled fontsize=12];\n  \n    Z;\n    \n    node [shape=square width=.5 fontcolor=\"#fffff8\" color=\"transparent\" \n    fillcolor=\"#ff5500\" style=filled fontsize=12];\n    Z -> Y ;\n  }\n\n  subgraph lv {\n    node [shape=circle width=.5 fontcolor=\"#fffff8\" color=\"transparent\" \n    fillcolor=\"#00aaff80\" style=filled fontsize=12];\n     \n    X [label = <&xi;>];\n    \n    node [shape=square width=.25 fontcolor=\"#ff5500\" color=\"#ff5500\" fillcolor=\"#ffffff\" style=filled fontsize=12];\n    edge [fontname=\"Roboto\" fontsize=10 fontcolor=gray50 color=\"#00aaff80\" arrowsize=.25];\n\n    X1  [label = \"X1\"];\n    X2  [label = \"X2\"];\n    X3  [label = \"X3\"];\n    X4  [label = \"X4\"];\n    X5  [label = \"X5\"];\n    \n    X -> X1, X2, X3, X4, X5; \n    \n    edge [arrowsize=.5]\n    X -> Y ;\n    \n    Z -> X [dir=\"both\" splines=\"curved\" color=\"#00aaff20\"]\n  }\n  \n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
<p class="caption">
Figure 1: The structural equation model
</p>
</div>
</div>
<h2 id="issues-with-aggregate-approaches">Issues with Aggregate Approaches</h2>
<p>CV suggest that simple aggregation, e.g. using a group mean, will result in problems, specifically biased estimates. They simulate data that varies the number of groups/clusters, the number of observations within groups, the intraclass correlation of observations within a group. In most of the cases they explore, the bias for the aggregate mean effect is notable, and there is sometimes small bias for the group level covariates, if they are collinear with the aggregate covariate. We will duplicate this approach later.</p>
<p>An approach to adjusting the group mean is offered by CV, with the structural model implied. These adjusted group means, or in their parlance, best linear unbiased predictors (BLUPs), result in a bias-free result. The notion of a BLUP will be familiar to those who use mixed models, as that is what the random effects are for a standard linear mixed model. As such, later on we’ll take a look at using a mixed model as a possible solution. In any case, once the adjusted means are calculated, you can then run your standard regression with the bias mostly eliminated.</p>
<h2 id="issues-with-adjustment">Issues with Adjustment</h2>
<p>It turns out the the weighting calculation proffered by CV is somewhat complicated, not easily implemented, and rarely used. Foster-Johnson &amp; Kromrey <span class="citation" data-cites="foster2018predicting">Foster-Johnson and Kromrey (<a href="#ref-foster2018predicting" role="doc-biblioref">2018</a>)</span> (FJK) looked further into its utility, as well as other possible solutions that might be easier to implement. As far as type I error rate goes, FJK demonstrated that using the CV adjusted group means offers no advantage over unadjusted, and even showed less statistical power. They suggested that a standard correction for heteroscedasticity (White’s) might be enough. In applying corrected standard errors for both unadjusted and adjusted group means, FJK found there to be additional power for both approaches, but if anything still favored the standard group mean. What’s more, while the bias remained, there was actually notable variability in the adjusted mean results. FJK’s final recommendation was to use the usual group means with robust standard errors, easily implemented in any statistical package.</p>
<h2 id="my-perspective">My Perspective</h2>
<p>My first glance at the method suggested by CV immediately called to mind the standard measurement model. So my interpretation was that we are simply talking about a well known fact in measurement that reliability of the measure is key in using a mean or sum score, and decreased reliability attenuates the correlation among the variables in question. I even did <a href="https://m-clark.github.io/docs/lv_sim.html">a simulation demonstrating the problem</a> a while back. So in this case, I’m interested in the issue from a reliability perspective.</p>
<p>It turns out that factor models and mixed models share a lot in common. Those familiar with <em>growth curve models</em> know that they are equivalent to mixed models, but the comparison is a more general one of random effects methods. To demonstrate the equivalence, I’ll use a cleaned up version of the <a href="https://en.wikipedia.org/wiki/Big_Five_personality_traits">Big 5</a> data in the <span class="pack" style="">psych</span> package. Specifically, we’ll use the five items that belong to the Agreeableness measure.</p>
<p>First we make the data in both wide and long. The former makes it amenable to factor analysis, while the latter is what we need for a mixed model.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# data prep for long and wide format

agree_df = noiris::big_five %&gt;% 
  select(A1:A5) %&gt;% 
  drop_na()

agree_long = agree_df %&gt;% 
  mutate(id = factor(row_number())) %&gt;% 
  pivot_longer(-id, names_to = &#39;variable&#39;, values_to = &#39;value&#39;)</code></pre>
</div>
<p>The standard factor model will have to be constrained to have equal loadings and item variances. In addition, we’ll estimate the intercepts, but otherwise this is your basic factor analysis.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
 # or use growth() to save some of the model tedium
cfa_model_agree = &quot;
  agree =~ a*A1 + a*A2 + a*A3 + a*A4 + a*A5
  
  A1 ~~ var*A1
  A2 ~~ var*A2
  A3 ~~ var*A3
  A4 ~~ var*A4
  A5 ~~ var*A5
&quot;

library(lavaan)

cfa_fit_agree = cfa(cfa_model_agree, data = agree_df, meanstructure = T) 

summary(cfa_fit_agree)</code></pre>
<pre><code>
lavaan 0.6-7 ended normally after 11 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of free parameters                         11
  Number of equality constraints                     4
                                                      
  Number of observations                          2709
                                                      
Model Test User Model:
                                                      
  Test statistic                               744.709
  Degrees of freedom                                13
  P-value (Chi-square)                           0.000

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  agree =~                                            
    A1         (a)    1.000                           
    A2         (a)    1.000                           
    A3         (a)    1.000                           
    A4         (a)    1.000                           
    A5         (a)    1.000                           

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .A1               -2.412    0.026  -94.340    0.000
   .A2                4.797    0.026  187.611    0.000
   .A3                4.599    0.026  179.859    0.000
   .A4                4.682    0.026  183.107    0.000
   .A5                4.551    0.026  177.982    0.000
    agree             0.000                           

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .A1       (var)    1.201    0.016   73.607    0.000
   .A2       (var)    1.201    0.016   73.607    0.000
   .A3       (var)    1.201    0.016   73.607    0.000
   .A4       (var)    1.201    0.016   73.607    0.000
   .A5       (var)    1.201    0.016   73.607    0.000
    agree             0.571    0.022   25.621    0.000</code></pre>
</div>
<p>When we run the mixed model, we get the same variance and intercept estimates.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(lme4)</code></pre>
<pre><code>
Loading required package: Matrix</code></pre>
<pre><code>
Attaching package: &#39;Matrix&#39;</code></pre>
<pre><code>
The following objects are masked from &#39;package:tidyr&#39;:

    expand, pack, unpack</code></pre>
<pre class="r"><code>
library(mixedup) # for post-processing

mixed_fit = lmer(value ~ -1 + variable + (1 |id), data = agree_long,  REML = FALSE)
summarise_model(mixed_fit, digits = 3)</code></pre>
<pre><code>
Computing profile confidence intervals ...</code></pre>
<pre><code>
Variance Components:</code></pre>
<pre><code>
    Group    Effect Variance    SD SD_2.5 SD_97.5 Var_prop
       id Intercept    0.571 0.755  0.727   0.785    0.322
 Residual              1.201 1.096  1.081   1.111    0.678</code></pre>
<pre><code>
Fixed Effects:</code></pre>
<pre><code>
       Term  Value    SE       t P_value Lower_2.5 Upper_97.5
 variableA1 -2.412 0.026 -94.340   0.000    -2.462     -2.362
 variableA2  4.797 0.026 187.611   0.000     4.747      4.847
 variableA3  4.599 0.026 179.859   0.000     4.549      4.649
 variableA4  4.682 0.026 183.107   0.000     4.632      4.732
 variableA5  4.551 0.026 177.982   0.000     4.501      4.601</code></pre>
</div>
<p>We can also see that the estimated factor scores agree with the estimated random effects.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
index
</th>
<th style="text-align:right;">
Estimated.Factor.Scores
</th>
<th style="text-align:right;">
Estimated.Random.Effects
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-0.453
</td>
<td style="text-align:right;">
-0.453
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
-0.312
</td>
<td style="text-align:right;">
-0.312
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
-0.594
</td>
<td style="text-align:right;">
-0.594
</td>
</tr>
<tr>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
-0.031
</td>
<td style="text-align:right;">
-0.031
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
-0.453
</td>
<td style="text-align:right;">
-0.453
</td>
</tr>
<tr>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
-0.031
</td>
<td style="text-align:right;">
-0.031
</td>
</tr>
<tr>
<td style="text-align:right;">
2704
</td>
<td style="text-align:right;">
-0.453
</td>
<td style="text-align:right;">
-0.453
</td>
</tr>
<tr>
<td style="text-align:right;">
2705
</td>
<td style="text-align:right;">
-1.720
</td>
<td style="text-align:right;">
-1.720
</td>
</tr>
<tr>
<td style="text-align:right;">
2706
</td>
<td style="text-align:right;">
-0.312
</td>
<td style="text-align:right;">
-0.312
</td>
</tr>
<tr>
<td style="text-align:right;">
2707
</td>
<td style="text-align:right;">
-0.453
</td>
<td style="text-align:right;">
-0.453
</td>
</tr>
<tr>
<td style="text-align:right;">
2708
</td>
<td style="text-align:right;">
-1.297
</td>
<td style="text-align:right;">
-1.297
</td>
</tr>
<tr>
<td style="text-align:right;">
2709
</td>
<td style="text-align:right;">
-1.157
</td>
<td style="text-align:right;">
-1.157
</td>
</tr>
</tbody>
</table>
</div>
<p>Usually when the term BLUP comes up it is in reference to the random effects estimated from a linear mixed model. As such, I thought it might be interesting to see how a mixed or factor model might be used to deal with the bias. I also thought it was a bit odd that neither CV nor FJK actually conduct the implied SEM (but see the paper co-authored by the <span class="pack" style="">lavaan</span> package author <span class="citation" data-cites="devlieger2016hypothesis">Devlieger, Mayer, and Rosseel (<a href="#ref-devlieger2016hypothesis" role="doc-biblioref">2016</a>)</span>), so I wanted to look at that too.</p>
<h2 id="model-setup">Model Setup</h2>
<p>For our demonstration, I will create some data as CV did and run a variety of models to see what we get. My focus is on bias, not coverage or power, as I think FJK covered those aspects plenty. The models in particular are:</p>
<ul>
<li><strong>Standard linear model</strong>: a basic group level analysis using unadjusted means.</li>
<li><strong>Random effects</strong>: a group level model using estimated factor scores using <span class="pack" style="">lavaan</span>, or the BLUPs from <span class="pack" style="">lme4</span>, or those with heterogeneous variance via <span class="pack" style="">glmmTMB</span><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. These involved a two-step approach, with the factor/mixed model followed by the standard linear model.</li>
<li><strong>Structural equation model</strong>: A full, single-step SEM via <span class="pack" style="">lavaan</span>. This model has the ability to account for the correlation of the Z and latent variable. It is exactly as CV depict in their Figure 1 and Figure <a href="#fig:sem-plot">1</a> above.</li>
<li><strong>Adjusted means</strong>: Use CV’s approach</li>
</ul>
<h2 id="data-setup">Data Setup</h2>
<p>I made a function<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> to create data with the values shown in CV (p. 52) for a single aggregate <span class="math inline">\(X\)</span> and single group-level covariate <span class="math inline">\(Z\)</span>. Using their notation, the model that generates the data is the following:</p>
<p><span class="math display">\[y_g = .3 + .3Z_g + .3\xi_g + \epsilon_g\]</span> <span class="math display">\[x_{ig} = \xi + \nu_g\]</span></p>
<p>As there, <span class="math inline">\(\sigma^2_\epsilon\)</span> is .35. While they look at a variety of situations, I’ll just consider a single scenario for our purposes, where the correlation of the <span class="math inline">\(Z\)</span> and <span class="math inline">\(\xi\)</span> was .3, the intraclass correlation of the observed <span class="math inline">\(x_{ig}\)</span> was .1 (i.e. <span class="math inline">\(\sigma^2_\nu\)</span> = 9), the number of groups was 100 and the number of observations per group was balanced at 10 (row 16 of their table 1). I simulated 1000 such data sets so that we could examine the mean value of the estimated coefficients. I first started by analyzing the result with a factor analysis, and if there are any problems such as negative variances or lack of convergence, the data is regenerated, as that will also help with any issues the mixed model would have. So the final 1000 data sets don’t have convergence issues or other problems that might make the results a little wonky.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<h2 id="results">Results</h2>
<p>Here are the results. We can first take a peek at the estimated scores from the two-step approaches. The CV adjustment appears closely matched to the true score at first, but we see it’s range is very wild, which is what FJK found also. Interestingly, the BLUPs from the mixed models have less variance than the true scores. The factor score is in keeping with the BLUPs, but appears also to have notable extremes, but far less than the CV adjustment. We’ll talk about why these extremes may arise later.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:results-summary-load">Table 1: </span>Estimated scores
</caption>
<thead>
<tr>
<th style="text-align:left;">
Variable
</th>
<th style="text-align:right;">
N
</th>
<th style="text-align:right;">
Mean
</th>
<th style="text-align:right;">
SD
</th>
<th style="text-align:right;">
Min
</th>
<th style="text-align:right;">
Q1
</th>
<th style="text-align:right;">
Median
</th>
<th style="text-align:right;">
Q3
</th>
<th style="text-align:right;">
Max
</th>
<th style="text-align:right;">
% Missing
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
True
</td>
<td style="text-align:right;">
1e+05
</td>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
-4.31
</td>
<td style="text-align:right;">
-0.67
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.68
</td>
<td style="text-align:right;">
4.44
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
CV Adj
</td>
<td style="text-align:right;">
1e+05
</td>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:right;">
1.07
</td>
<td style="text-align:right;">
-22.97
</td>
<td style="text-align:right;">
-0.65
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.66
</td>
<td style="text-align:right;">
25.64
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
Unadjusted
</td>
<td style="text-align:right;">
1e+05
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
1.39
</td>
<td style="text-align:right;">
-6.32
</td>
<td style="text-align:right;">
-0.93
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.94
</td>
<td style="text-align:right;">
6.96
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
BLUP_mixed
</td>
<td style="text-align:right;">
1e+05
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.74
</td>
<td style="text-align:right;">
-4.20
</td>
<td style="text-align:right;">
-0.48
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.48
</td>
<td style="text-align:right;">
3.98
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
BLUP_mixed_hetvar
</td>
<td style="text-align:right;">
1e+05
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.74
</td>
<td style="text-align:right;">
-4.18
</td>
<td style="text-align:right;">
-0.48
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.47
</td>
<td style="text-align:right;">
3.97
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
Factor Score
</td>
<td style="text-align:right;">
1e+05
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.87
</td>
<td style="text-align:right;">
-7.29
</td>
<td style="text-align:right;">
-0.47
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.46
</td>
<td style="text-align:right;">
6.54
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
</div>
<p>Now let’s look at the bias in the estimates.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:results-summary">Table 2: </span>Percent bias
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:right;">
Intercept
</th>
<th style="text-align:right;">
Z
</th>
<th style="text-align:right;">
X
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Unadjusted
</td>
<td style="text-align:right;">
0.149
</td>
<td style="text-align:right;">
14.494
</td>
<td style="text-align:right;">
-49.877
</td>
</tr>
<tr>
<td style="text-align:left;">
BLUP_mixed
</td>
<td style="text-align:right;">
0.051
</td>
<td style="text-align:right;">
14.494
</td>
<td style="text-align:right;">
-1.828
</td>
</tr>
<tr>
<td style="text-align:left;">
BLUP_mixed_hetvar
</td>
<td style="text-align:right;">
0.053
</td>
<td style="text-align:right;">
14.647
</td>
<td style="text-align:right;">
-1.673
</td>
</tr>
<tr>
<td style="text-align:left;">
Factor Score
</td>
<td style="text-align:right;">
0.063
</td>
<td style="text-align:right;">
16.502
</td>
<td style="text-align:right;">
11.968
</td>
</tr>
<tr>
<td style="text-align:left;">
CV Adj
</td>
<td style="text-align:right;">
-0.663
</td>
<td style="text-align:right;">
-2.368
</td>
<td style="text-align:right;">
7.992
</td>
</tr>
<tr>
<td style="text-align:left;">
SEM
</td>
<td style="text-align:right;">
-0.017
</td>
<td style="text-align:right;">
-1.777
</td>
<td style="text-align:right;">
4.744
</td>
</tr>
<tr>
<td style="text-align:left;">
True
</td>
<td style="text-align:right;">
-0.567
</td>
<td style="text-align:right;">
-0.380
</td>
<td style="text-align:right;">
0.513
</td>
</tr>
</tbody>
</table>
</div>
<p>The results suggest a couple things. First, the results of CV were duplicated for the unadjusted setting, where the group level covariate has a slight bias upward, but the aggregate is severely downwardly biased. We can also see that a two-step approach using BLUPs from a mixed model (with or without heterogeneous variances), or factor scores, either eliminate or notably reduce the bias for the aggregate score, but still have issue with the group level covariate. This is because of the correlation between the group level and lower level covariates, which if zero, would result in no bias, and has long been a known issue with mixed models. The factor scores had some very wild results at times, even after overcoming basic inadmissible results. In the end, we see that the calculated adjustment and SEM both essentially eliminate the bias by practical standards. It is worth noting that the bias for either the factor analysis or SEM would be completely eliminated if the model adds a regression of the latent variable onto the group level covariate <span class="math inline">\(Z\)</span>.</p>
<p>Note that in practice, a two-step approach, such as using the mixed model BLUPs or factor scores, comes with the same issue of using an estimate rather than observed score that we have using the mean. Even if there is no bias, the estimated uncertainty would be optimistic as it doesn’t take into account the estimation process. This uncertainty decreases with the number of observations per group (or number of items from the factor analytic perspective), but would technically need to be dealt with, e.g. using ‘factor score regression’ <span class="citation" data-cites="devlieger2016hypothesis">Devlieger, Mayer, and Rosseel (<a href="#ref-devlieger2016hypothesis" role="doc-biblioref">2016</a>)</span> or more simply, just doing the SEM.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<h2 id="reliability">Reliability</h2>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<p>Interestingly, if we look at the reliability of the measure, we shouldn’t be surprised at the results. Reliability may be thought of as the amount of variance in an observed score that is true score variance <span class="citation" data-cites="revelle2019reliability">Revelle and Condon (<a href="#ref-revelle2019reliability" role="doc-biblioref">2019</a>)</span>. Since the underlying construct is assumed unidimensional, we can examine something like coefficient <span class="math inline">\(\alpha\)</span>, which gives a sense of how reliable the mean or total score would be. Doing so reveals a fairly poor measure for 10 observations per group under the CV settings. The mean coefficient <span class="math inline">\(\alpha\)</span> is 0.52, the max of which is 0.74, which, from a measurement model perspective, would be unacceptable<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. This is all to say that we have rediscovered attenuation in correlation due to (lack of) reliability, something <a href="https://en.wikipedia.org/wiki/Correction_for_attenuation">addressed by Spearman over a century ago</a><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
<p>In actual repeated measures, or with constructed scales, it’s probably unlikely we would have this poor of a measure. Indeed, if we think a mean is appropriate in the first place, we are probably assuming that the scores are something that can be meaningfully combined in the first place, because if a latent construct doesn’t actually explain the observations well, then what is the point of estimating it?</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<p>In our current context, we can create a more reliable measure by decreasing the variance value for <span class="math inline">\(\sigma^2_\nu\)</span> which is the residual variance for the observed items at the lower level. Decreasing it from 9 to 1, puts the observed scores in a notably better place (<span class="math inline">\(\alpha\)</span> = 0.91), and if we actually have a reliable measure (or even just increase the number of observations per group, as noted by CV), the results show hardly any bias for the group level effect and a near negligible one for the mean effect.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:reliable-lm">Table 3: </span>Percent bias
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:right;">
Intercept
</th>
<th style="text-align:right;">
Z
</th>
<th style="text-align:right;">
X
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Unadjusted
</td>
<td style="text-align:right;">
-0.011
</td>
<td style="text-align:right;">
2.698
</td>
<td style="text-align:right;">
-9.651
</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<h2 id="summary">Summary</h2>
<p>In the end we relearn a valuable, but very old lesson. The take home story here, at least to me, is to have a reliable measure and/or get more observations per group if you can, which would be the same advice for any clustered data situation. If you do have a reliable measure, such as a proportion of simple counts, or a known scale with good properties, using the mean should not give you too much pause. As a precaution, you might go ahead and use White’s correction as suggested by FJK. If you have enough data and the model isn’t overly complicated, consider doing the SEM.</p>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-croon2007predicting">
<p>Croon, Marcel A, and Marc JPM van Veldhoven. 2007. “Predicting Group-Level Outcome Variables from Variables Measured at the Individual Level: A Latent Variable Multilevel Model.” <em>Psychological Methods</em> 12 (1): 45.</p>
</div>
<div id="ref-devlieger2016hypothesis">
<p>Devlieger, Ines, Axel Mayer, and Yves Rosseel. 2016. “Hypothesis Testing Using Factor Score Regression: A Comparison of Four Methods.” <em>Educational and Psychological Measurement</em> 76 (5): 741–70.</p>
</div>
<div id="ref-foster2018predicting">
<p>Foster-Johnson, Lynn, and Jeffrey D Kromrey. 2018. “Predicting Group-Level Outcome Variables: An Empirical Comparison of Analysis Strategies.” <em>Behavior Research Methods</em> 50 (6): 2461–79.</p>
</div>
<div id="ref-revelle2019reliability">
<p>Revelle, William, and David M Condon. 2019. “Reliability from <span class="math inline">\(\alpha\)</span> to <span class="math inline">\(\omega\)</span>: A Tutorial.” <em>Psychological Assessment</em> 31 (12): 1395.</p>
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>I wasn’t sure in the mixed model whether to include the item and or group level Z as fixed effects. Results did not change much, so I went with a mixed model with no fixed effects to make them closer to the mean scores/scale.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>All code is contained within the <a href="https://github.com/m-clark/m-clark.github.io/blob/master/_posts/2020-08-31-micro-macro-mlm/micro-macro.Rmd">R markdown file</a> that produced this post.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>A typical cutoff for coefficient <span class="math inline">\(\alpha\)</span> for a good measure is .8. We can actually use a ‘G-theory’ approach and calculate this by hand <span class="math inline">\(\frac{1}{1+9/10}\)</span>, where 1 is the variance CV fixed for the true score, and 9 is residual variance. <span class="math inline">\(\frac{1}{1+9}\)</span> is the <span class="math inline">\(\rho_x\)</span>, i.e. intraclass correlation, that they have in Table 1. In the better scenario <span class="math inline">\(\rho_x\)</span> = <span class="math inline">\(\frac{1}{1+4}\)</span> = .2 and the reliability is <span class="math inline">\(\frac{1}{1+4/10}\)</span> = .71, which is notably better, though still substandard. Even then we can see from their table dramatic decreases in bias from that improvement in reliability.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>The lack of reliability is likely the culprit behind the wider range in the estimated factor scores as well.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<script id="distill-bibliography" type="text/bibtex">
@ARTICLE{mundlak1978,
  title = {On the Pooling of Time Series and Cross Section Data},
  author = {Mundlak, Yair},
  year = {1978},
  journal = {Econometrica},
  volume = {46},
  number = {1},
  pages = {69-85},
  url = {https://EconPapers.repec.org/RePEc:ecm:emetrp:v:46:y:1978:i:1:p:69-85}
}


@article{bell2015explaining,
  title={Explaining fixed effects: Random effects modeling of time-series cross-sectional and panel data},
  author={Bell, Andrew and Jones, Kelvyn},
  journal={Political Science Research and Methods},
  volume={3},
  number={1},
  pages={133--153},
  year={2015},
  publisher={Cambridge University Press}
}

Zotero automatically redirected your request to psycnet.apa.org through the proxy at proxy.lib.umich.edu.
Don’t Proxy This Site
Proxy Settings
✕

@article{revelle2019reliability,
  title={Reliability from $\alpha$ to $\omega$: A tutorial.},
  author={Revelle, William and Condon, David M},
  journal={Psychological assessment},
  volume={31},
  number={12},
  pages={1395},
  year={2019},
  publisher={American Psychological Association}
}

@article{devlieger2016hypothesis,
  title={Hypothesis testing using factor score regression: A comparison of four methods},
  author={Devlieger, Ines and Mayer, Axel and Rosseel, Yves},
  journal={Educational and Psychological Measurement},
  volume={76},
  number={5},
  pages={741--770},
  year={2016},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}


@article{bell2019fixed,
  title={Fixed and random effects models: making an informed choice},
  author={Bell, Andrew and Fairbrother, Malcolm and Jones, Kelvyn},
  journal={Quality \& Quantity},
  volume={53},
  number={2},
  pages={1051--1074},
  year={2019},
  publisher={Springer}
}

@article{bell2018understanding,
  title={Understanding and misunderstanding group mean centering: a commentary on Kelley et al.’s dangerous practice},
  author={Bell, Andrew and Jones, Kelvyn and Fairbrother, Malcolm},
  journal={Quality \& quantity},
  volume={52},
  number={5},
  pages={2031--2036},
  year={2018},
  publisher={Springer}
}


@article{schmidt2016random,
  title={The random effects in multilevel models: Getting them wrong and getting them right},
  author={Schmidt-Catran, Alexander W and Fairbrother, Malcolm},
  journal={European sociological review},
  volume={32},
  number={1},
  pages={23--38},
  year={2016},
  publisher={Oxford University Press}
}

@article{fairbrother2014two,
  title={Two multilevel modeling techniques for analyzing comparative longitudinal survey datasets},
  author={Fairbrother, Malcolm},
  journal={Political Science Research and Methods},
  volume={2},
  number={1},
  pages={119--140},
  year={2014},
  publisher={Cambridge University Press}
}


@article{luo2017testing,
  title={Testing mediation effects in cross-classified multilevel data},
  author={Luo, Wen},
  journal={Behavior research methods},
  volume={49},
  number={2},
  pages={674--684},
  year={2017},
  publisher={Springer}
}


@article{foster2018predicting,
  title={Predicting group-level outcome variables: An empirical comparison of analysis strategies},
  author={Foster-Johnson, Lynn and Kromrey, Jeffrey D},
  journal={Behavior Research Methods},
  volume={50},
  number={6},
  pages={2461--2479},
  year={2018},
  publisher={Springer}
}

@article{croon2007predicting,
  title={Predicting group-level outcome variables from variables measured at the individual level: a latent variable multilevel model.},
  author={Croon, Marcel A and van Veldhoven, Marc JPM},
  journal={Psychological methods},
  volume={12},
  number={1},
  pages={45},
  year={2007},
  publisher={American Psychological Association}
}

</script>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
