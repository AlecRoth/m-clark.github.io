---
title: "Categorical Effects as Random"
description: |
  blah blah
author:
  - name: Michael Clark
    url: https://m-clark.github.io
date: '`r format(Sys.Date(), "%B %d, %Y")`'
preview: ../../img/198R.png   # apparently no way to change the size displayed via css (ignored) or file (stretched)
output:
  distill::distill_article:
    self_contained: false
    toc: true
    css: ../../styles.css
draft: true
tags: [tags, taggy]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo=T, 
  message = F, 
  warning = F, 
  comment = NA,
  R.options = list(width = 120),
  cache.rebuild = F,
  cache = F,
  fig.align = 'center',
  fig.asp = .7, 
  dev = 'svg', 
  dev.args=list(bg = 'transparent')
)

library(tidyverse); library(broom); library(kableExtra); library(visibly)

kable_df <- function(..., digits=3) {
  kable(..., digits=digits) %>% 
    kable_styling(full_width = F)
}

rnd = tidyext::rnd
```

Prerequisites: familiarity with mixed models

##  Introduction

It's often the case where, for mixed models, we want to look at random 'slopes' as well as random intercepts, such that coefficients for the fixed effects are expected to vary by group.  This is very common in longitudinal settings, were we want to examine an overall trend, but allow the trend to vary by individual.

In such settings, when time is numeric, things are straightforward.  The variance is decomposed into parts for the intercept, the coefficient for the time indicator, and the residual variance (for linear mixed models).  But what happens if we have only three time points?  Does it make sense to treat it as numeric and hope for the best?

This came up in consulting because someone had a similar issue, and tried to keep the format for random slopes while treating the time indicator as categorical. This led to convergence issues, so we thought about what models might be possible.  This post explores that scenario.


Packages used:

```{r packages}
library(tidyverse)
library(lme4)
library(mixedup)  # http://m-clark.github.io/mixedup
```

## Machines

### The Data

Let's start with a very simple data set from the <span class="pack" style = "">nlme</span> package, which comes with the standard R installation.  The reason I chose this is because [Doug Bates has a good treatment on this topic](http://pages.stat.wisc.edu/~bates/UseR2008/WorkshopD.pdf) using that example  (starting at slide 85), which I just extend a bit.

Here is the data description from the help file.

> Data on an experiment to compare three brands of machines used in an industrial process are presented in Milliken and Johnson (p. 285, 1992). Six workers were chosen randomly among the employees of a factory to operate each machine three times. The response is an overall productivity score taking into account the number and quality of components produced.

So for each worker and each machine, we'll have three scores.  Let's look.

```{r load-data}
machines = nlme::Machines

# for some reason worker is an ordered factor.
machines = machines %>% 
  mutate(Worker = factor(Worker, levels = 1:6, ordered = FALSE))
```

```{r show-data, echo=FALSE}
machines %>%
  arrange(Worker, Machine) %>% 
  head() %>% 
  kable_df()
```

This duplicates the plot in Bates' notes.

```{r vis-data, echo=FALSE}
# the order in the plot doesn't match the 'ordered' worker factor- go figure 
machines %>% 
  mutate(Worker = ordered(Worker, levels = rev(c(3, 5, 1, 4, 2, 6)))) %>% 
  group_by(Worker, Machine) %>% 
  mutate(mean = mean(score)) %>% 
  arrange(Worker) %>%
  ggplot(aes(
    x = score,
    y = Worker,
    color = Machine,
    group = Machine
  )) +
  geom_point() +
  geom_path(aes(x = mean)) +
  scico::scale_color_scico_d(begin = .25, end = .66) +
  visibly::theme_clean()
```

### Random Effects Models

The random effects of potential interest are for worker and machine, so how do we specify this?  Let's try the following standard approach. The following is the type of model tried by our client.

```{r model_m_slope, warning=TRUE}
model_m_slope = lmer(score ~ Machine + (1 + Machine | Worker), machines)
```

This was exactly the same issue our client had- problematic convergence.  This could be more of an issue with <span class="pack" style = "">lme4</span>, and we could certainly explore tweaks to make the problem go away (or use a different package like <span class="pack" style = "">glmmTMB</span>), but let's go ahead and keep it.

```{r m-slope-results, message = TRUE}
summarize_model(model_m_slope, ci = FALSE, cor_re = TRUE)
```

We get the variance components we expect, i.e. the variance attributable to the intercept (i.e. Machine A), as well as for the slopes for the difference in machine B vs. A, and C vs. A.  We also see the correlations among the random effects.  It's this part that Bates acknowledges is hard to estimate, and incurs estimating potentially notably more parameters than typical random effects models.  We have different options that will be available to us, so let's try some.

Let's start with the simplest, most plausible models.  The first would be to have at least a worker effect.  The next baseline model could be if we only had a machine by worker effect, i.e. a separate effect of each machine for each worker, essentially treating the interaction term as the sole clustering unit.


```{r baseline-models}
model_base_w  = lmer(score ~ Machine + (1 | Worker), machines)
model_base_wm = lmer(score ~ Machine + (1 | Worker:Machine), machines)
```

Examining the random effects makes clear the difference between the two models.  For our first baseline model, we only have 6 effects, one for each worker. For the second we have an effect of each machine for each worker.

```{r machines-baseline-re, eval=FALSE}
extract_random_effects(model_base_w)  # only 6 effects
extract_random_effects(model_base_wm) # 6 workers by 3 machines = 18 effects
```

```{r machines-baseline-re-pretty, echo=FALSE}
extract_random_effects(model_base_w)   %>% kable_df()
extract_random_effects(model_base_wm)  %>% kable_df()
```

Now let's add an interaction of worker with machine.  This essentially combines our two baseline models.

```{r machines-model_w_wm}
model_w_wm = lmer(score ~ Machine + (1 | Worker) + (1 | Worker:Machine), machines)
```

Now we have 6 worker effects plus 18 machine within worker effects[^within].  

```{r machines-model_w_wm-re, eval=FALSE}
extract_random_effects(model_w_wm)
```

```{r machines-model_w_wm-re-show, echo=FALSE}
extract_random_effects(model_w_wm) %>% 
  kable_df()
```

If you look closely at these effects, and add them together, you will get a value similar to our second baseline model, which is probably not too surprising. For example in the above model `1:B + 1` = `r extract_random_effects(model_w_wm)$value[2]` `+` `r extract_random_effects(model_w_wm)$value[19]`.  Looking at the initial model, the estimated random effect for `1:B` was `r extract_random_effects(model_base_wm)$value[2]`. So this model allows us to disentangle the worker and machine effects, where our baseline models did not.


```{r misc1, echo=FALSE}
# any interest in this?
# model_w_wm2 = lmer(score ~ Machine + (1 | Worker) + (0 + Machine | Worker), machines)
```

Next we'll do the 'vector-valued' model Bates describes.  This removes the intercept portion of the forumla in the initial model, but is otherwise the same. We can look at the results here, but I will hold off description for comparing it to other models. Note at least that we have no convergence problem.

```{r machines-model_m_vv, message=TRUE}
model_m_vv = lmer(score ~ Machine + (0 + Machine | Worker), machines)

summarize_model(model_m_vv, ci = 0, cor_re = TRUE)
```

```{r misc2, echo=FALSE}
# machines_dum = data.frame(machines, model.matrix(score ~ 0 + Machine, machines))
# model_m_dummy = lmer(
#   score ~ Machine + 
#     (1 | Worker:MachineA) + 
#     (1 | Worker:MachineB) + 
#     (1 | Worker:MachineC),
#   machines_dum
# )
# 
# summary(model_m_dummy)
```

### Summarize All the Models

Now let's extract the fixed effect and variance component summaries for all the models.

```{r machines-model-list}
model_list = mget(ls(pattern = 'model_'))

fe = map_df(model_list, extract_fixed_effects, .id = 'model')

vc = map_df(model_list, extract_vc, ci_level = 0, .id = 'model')
```

First, let's look at the fixed effects.  We see that there are no differences in the coefficients for the fixed effect of machine.  However, there are notable differences for the estimated standard errors.  Practically we'd come to no differences in our conclusions, but the uncertainty associated with them would be different.

```{r machines-fe, echo=FALSE}
kable_df(fe)
```

Here are the variance components, there are definitely some differences here, but, as we'll see, maybe not as much as we suspect.

```{r machines-vc, echo=FALSE}
kable_df(vc)
```


We can see that the `base_wm` model has (non-residual) variance `r extract_vc(model_base_wm, ci_level = 0)$variance[1]`.  This equals the total of the two (non-residual) variance components of the `w_wm` model `r extract_vc(model_w_wm, ci_level = 0)$variance[1]` `+` `r extract_vc(model_w_wm, ci_level = 0)$variance[2]`, which agains speaks to the latter model decomposing a machine effect into worker + machine effects.  This value also equals the variance of the vector-valued model divided by the number of groups (`r paste(extract_vc(model_m_vv, ci_level = 0)$variance[1:3], collapse = ' + ')`) `/` `r nlevels(machines$Machine)`.

We can see that the estimated random effects from the vector-valued model are essentially the same as from the baseline, interaction-only model.  However, the way it is estimated allows for incorporation of correlations among the machine random effects, so they are not identical (but pretty close).

```{r machines-ranef, echo=FALSE}
extract_random_effects(model_m_vv) %>%
  arrange(fct_inorder(group), effect) %>% 
  kable_df()

extract_random_effects(model_base_wm) %>% 
  kable_df()
```

Even the default way that the extracted random effects are structured implies this difference. In the vector-valued model we have a multivariate normal draw for 6 workers and 3 machines (i.e. 3 variances and 3 covariances).  In the baseline model, we do not estimate any covariances  and assume equal variance to draw for 18 groups (1 variance).

```{r machines-base-ranef}
ranef(model_base_wm)
ranef(model_m_vv)
```

Now let's compare the models directly via AIC. As we would expect if we dummy coded vs. running a model without the intercept (e.g. `lm(score ~ machine)`, vs. `lm(score ~ -1 + machine)`), the random slope model and vector-valued models are identical and produce the same AIC. Likewise the intercept variance of the former is equal to the first group variance of the vector-valued model.  

```{r machines-aic, echo=FALSE}
map_df(model_list, AIC) %>% 
  kable_df()
```

While such a model is doing better than either of our baseline models, it turns out that our other approach is slightly better, as the additional complexity wasn't really worth it.


<!-- https://github.com/m-clark/Visuals/tree/master/random_effects -->

## Simulation

The following is a simple approach to creating data in this scenario, an allows us to play around with the settings to see what happens.  

### Data Creation

First we need some data.  The following creates a group identifier similar to `Worker` in our previous example, a `cat_var` like our `Machine`, and other covariates just to make it interesting.


```{r sim-data}
# for simplicity keeping to 3 cat levels
set.seed(1234)
ng = 5000     # n groups
cat_levs = 3  # n obs per group
reps = 5      # number of obs per level per cat

id = rep(1:ng, each = cat_levs * reps)           # id indicator (e.g. like Worker)
cat_var = rep(1:cat_levs, times = ng, e = reps)  # categorical variable (e.g. Machine)
x = rnorm(ng * cat_levs * reps)                  # continuous covariate
x_c = rep(rnorm(ng), e = cat_levs*reps)          # continuous cluster level covariate
```


So we have the basic data in place, now we need to create the random effects.  There are several ways we could do this, including more efficient ones, but this approach focuses on a conceptual approach and on the model that got us here, i.e. something of the form `(1 + cat_var | group)`.   In this case we assume this model is 'correct', so we're going to create a multivariate normal draw of random effects for each level of the `cat_var`, which is only `r cat_levs` levels. 

```{r sim-re-cor}
# as correlated  (1, .5, .5) var, (1, .25, .25) sd 
cov_mat = lazerhawk::create_corr(c(.1, .25, .25), diagonal = c(1, .5, .5))

cov2cor(cov_mat)  # as a correlation matrix

# take a multivariate normal draw for the number of groups in `id`
re_id_cat_lev = mvtnorm::rmvnorm(ng, mean = rep(0, 3), sigma = cov_mat) %>% 
  data.frame()

head(re_id_cat_lev)
```

Now that we have the random effects, we can create our target variable.  We do this by adding our first effect to the intercept, and the others to their respective coefficients.

```{r sim-y}
y = 
  # fixed effect = (2, .5, -.5)
  2  + .5*x - .5*x_c +   
  # random intercept
  rep(re_id_cat_lev[, 1], each = cat_levs * reps) +                           
  # .25 is coef for group 2 vs. 1
  (.25 + rep(re_id_cat_lev[, 2], each = cat_levs * reps)) * (cat_var == 2) +  
  # .40 is coef for group 3 vs. 1
  (.40 + rep(re_id_cat_lev[, 3], each = cat_levs * reps)) * (cat_var == 3) +  
  rnorm(ng * cat_levs * reps, sd = .5)
```

Now we create a data frame so we can see everything together.

```{r sim-df}
df = tibble(
    id,
    cat_var,
    x,
    x_c,
    y,
    re_id = rep(re_id_cat_lev[, 1], each = cat_levs*reps),
    re_id_cat_lev2 = rep(re_id_cat_lev[, 2], each = cat_levs*reps),
    re_id_cat_lev3 = rep(re_id_cat_lev[, 3], each = cat_levs*reps)
  ) %>% 
  mutate(
    cat_var = factor(cat_var),
    cat_as_num = as.integer(cat_var),
    id = factor(id),
    cat_var_1 = factor(cat_var == 1),
    cat_var_2 = factor(cat_var == 2),
    cat_var_3 = factor(cat_var == 3)
  )

df %>% print(n = 30)

```

### Run the Models & Summarize

With everything in place, let's run four models similar to our previous models from the Machine example:

1. The baseline model that does not distinguish the id from cat_var variance.
2. The random slope approach
3. The vector valued model (equivalent to #2)
4. The scalar model that does not estimate the random effect correlations

```{r sim-models}
m_interaction_only = lmer(y ~ x + x_c + cat_var + (1 | id:cat_var), df)
m_random_slope = lmer(y ~ x + x_c + cat_var + (1 + cat_var | id), df)    # problems!
m_vector_valued = lmer(y ~ x + x_c + cat_var + (0 + cat_var | id), df)
m_separate_re = lmer(y ~ x + x_c + cat_var + (1 | id) + (1 | id:cat_var), df)
```


```{r sim-summarize}
model_mixed = list(
  m_interaction_only = m_interaction_only,
  m_random_slope = m_random_slope,
  m_vector_valued = m_vector_valued,
  m_separate_re = m_separate_re
)

# map(model_mixed, summarize_model, ci = 0, cor_re = TRUE)
fe = map_df(model_mixed, extract_fixed_effects, .id = 'model') 
vc = map_df(model_mixed, extract_vc, ci_level = 0, .id = 'model')
```

Looking

```{r sim-fe, echo = FALSE}
kable_df(fe)
```

```{r sim-vc, echo = FALSE}
kable_df(vc)
```

In this case, we know the model with correlations is the better model, and this is born out via AIC.

```{r sim-aic, echo = FALSE}
kable_df(map_df(model_mixed, AIC))
```

### Change the model orientation

Now I will make the `vector_valued` model reduce to the `separate_re` model.  First, we create a covariance matrix that has equal variances/covariances (i.e. compound symmetry).  Then, when we create the target variable, we make a slight alteration to apply it to the vector valued model instead.

```{r sim-data2}
set.seed(1234)

cov_mat = lazerhawk::create_corr(c(0.1, 0.1, 0.1), diagonal = c(.5, .5, .5))

re_id_cat_lev = mvtnorm::rmvnorm(ng, mean = rep(0, 3), sigma = cov_mat) %>% 
  data.frame()

y = 2  + .5*x - .5*x_c +   # fixed effect = (2, .5, -.5)
  rep(re_id_cat_lev[, 1], each = cat_levs * reps) * (cat_var == 1) +     # added this
  rep(re_id_cat_lev[, 2], each = cat_levs * reps) * (cat_var == 2) +
  rep(re_id_cat_lev[, 3], each = cat_levs * reps) * (cat_var == 3) +
  .25 * (cat_var == 2) +  # .25 is coef for group 2 vs. 1
  .40 * (cat_var == 3) +  # .40 is coef for group 3 vs. 1
  rnorm(ng * cat_levs * reps, sd = .5)


df = tibble(
    id,
    cat_var  = factor(cat_var),
    x,
    x_c,
    y
  )
```

Rerun the models.

```{r sim-models2}
m_random_slope = lmer(y ~ x + x_c + cat_var + (1 + cat_var | id), df) 
m_vector_valued = lmer(y ~ x + x_c + cat_var + (0 + cat_var | id), df)    # still problems!
m_separate_re = lmer(y ~ x + x_c + cat_var + (1 | id) + (1 | id:cat_var), df)
```

Examine the variance components.

```{r sim-summarize2}
model_mixed = list(
  m_random_slope = m_random_slope,
  m_vector_valued = m_vector_valued,
  m_separate_re = m_separate_re
)

vc = map_df(model_mixed, extract_vc, ci_level = 0, .id = 'model')
```



```{r sim-vc2, echo = FALSE}
kable_df(vc)
```

In this case, we know the true case regards zero correlations and equal variances, so estimating them is adding complexity we don't need, thus our simpler model wins (log likelihoods are essentially the same).

```{r sim-aic2, echo = FALSE}
map_df(model_mixed, logLik) %>% 
  mutate(parameter = 'LL') %>% 
  bind_rows(map_df(model_mixed, AIC) %>% mutate(parameter = 'AIC')) %>% 
  select(parameter, everything()) %>% 
  kable_df()
```

## Summary


```{r eval = FALSE, echo=FALSE}
# adding actual slope re in this case we're assuming the form of (1 + cat_var |
# id) with corresponding correlations



# for simplicity keeping to 3 cat levels
set.seed(1234)
ng = 5000     # n groups
cat_levs = 3  # n obs per group
reps = 5      # number of obs per level per cat

id = rep(1:ng, each = cat_levs*reps)
cat_var = rep(1:cat_levs, times = ng, e = reps)
x = rnorm(ng*cat_levs*reps)
x_c = rep(rnorm(ng), e = cat_levs*reps)  # cluster level covariate


# as independent
# re_id = rep(rnorm(ng, sd = .5), each = cat_levs*reps)
# re_id_cat_lev2 = rep(rnorm(ng*cat_levs, sd = .25), each = reps)
# re_id_cat_lev3 = rep(rnorm(ng*cat_levs, sd = .25), each = reps)

# as correlated
cov_mat = lazerhawk::create_corr(c(.25, .25, .25), diagonal = c(1, .5, .5))

# cov_mat = matrix(c(.5, .25, .25, .5), 2, byrow = T)  # .5 var, .25 sd  .5 cor
cov2cor(cov_mat)

re_id_cat_lev = mvtnorm::rmvnorm(ng, mean = rep(0, 3), sigma = cov_mat) %>% 
  data.frame()

y = 2  + .5*x - .5*x_c + 
  rep(re_id_cat_lev[,1], each = cat_levs*reps) + 
  (.25 + rep(re_id_cat_lev[,2], each = cat_levs*reps)) * (cat_var == 2) +
  (.40 + rep(re_id_cat_lev[,3], each = cat_levs*reps)) * (cat_var == 3) +
  rnorm(ng*cat_levs*reps, sd = .5)

df = tibble(
    id,
    cat_var,
    x,
    x_c,
    y,
    re_id = rep(re_id_cat_lev[, 1], each = cat_levs*reps),
    re_id_cat_lev2 = rep(re_id_cat_lev[, 2], each = cat_levs*reps),
    re_id_cat_lev3 = rep(re_id_cat_lev[, 3], each = cat_levs*reps)
  ) %>% 
  mutate(
    cat_var = factor(cat_var),
    cat_as_num = as.integer(cat_var),
    id = factor(id),
    cat_var_1 = factor(cat_var == 1),
    cat_var_2 = factor(cat_var == 2),
    cat_var_3 = factor(cat_var == 3)
  )

df %>% print(n = 30)

m_lm = lm(y ~ x + x_c + cat_var, df)

m_int_only = lmer(y ~ x + x_c + cat_var + (1 | id), df)
m_interaction_only = lmer(y ~ x + x_c + cat_var + (1 | id:cat_var), df)
m_random_slope = lmer(y ~ x + x_c + cat_var + (1 + cat_var | id), df)    # problems!
m_as_numeric = lmer(y ~ x + x_c + cat_var + (1 + cat_as_num | id), df)
m_vector_valued = lmer(y ~ x + x_c + cat_var + (0 + cat_var | id), df)
m_separate_re = lmer(y ~ x + x_c + cat_var + (1 | id) + (1 | id:cat_var), df)
m4 = lmer(y ~ x + x_c + cat_var + (1 | id:cat_var_1) + (1 | id:cat_var_2)  + (1 | id:cat_var_3),
          df
)

model_mixed = list(
  m_int_only = m_int_only,
  m_interaction_only = m_interaction_only,
  m_as_numeric = m_as_numeric,
  m_random_slope = m_random_slope,
  m_vector_valued = m_vector_valued,
  m_separate_re = m_separate_re
)

summary(m_lm)
map_df(model_mixed, extract_fixed_effects, .id = 'model') %>% data.frame()
map_df(model_mixed, extract_vc, ci_level = 0, .id = 'model')

# summarize_model(m2, cor_re = T, ci = 0)

# preds = tibble(
#   m2 = predict(m2),
#   m5 = predict(m5)
# )

# cor(preds)

```

[^within]: Though I use the word 'within', do not take it to mean we have nested data.