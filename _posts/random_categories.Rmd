---
title: "Categorical Effects as Random"
description: |
  blah blah
author:
  - name: Michael Clark
    url: https://m-clark.github.io
date: '`r format(Sys.Date(), "%B %d, %Y")`'
preview: ../../img/198R.png   # apparently no way to change the size displayed via css (ignored) or file (stretched)
output:
  distill::distill_article:
    self_contained: false
    toc: true
    css: ../../styles.css
draft: true
tags: [tags, taggy]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo=T, 
  message = F, 
  warning = F, 
  comment = NA,
  R.options = list(width = 120),
  cache.rebuild = F,
  cache = T,
  fig.align = 'center',
  fig.asp = .7, 
  dev = 'svg', 
  dev.args=list(bg = 'transparent')
)

library(tidyverse); library(broom); library(kableExtra); library(visibly)

kable_df <- function(..., digits=3) {
  kable(..., digits=digits) %>% 
    kable_styling(full_width = F)
}

rnd = tidyext::rnd
```

Prereq: familiarity with mixed models

##  Introduction

It's often the case where, for mixed models, we want to look at random 'slopes' as well as random intercepts, such that coefficients for the fixed effects are expected to vary by group.  This is very common in longitudinal settings, were we want to examine an overall trend, but allow the trend to vary by individual.

In such settings, when time is numeric, things are straightforward.  The variance is decomposed into parts for the intercept, the coefficient for the time indicator, and the residual variance (for linear mixed models).  But what happens if we have only three time points?  Does it make sense to treat it as numeric and hope for the best?

This came up in consulting because someone had a similar issue, and tried to keep the format for random slopes while treating the time indicator as categorical. This lead to convergence issues, so we thought about what models might be possible.  This post explores the scenario.


Packages used:

```{r packages}
library(tidyverse)
library(lme4)
library(mixedup)  # http://m-clark.github.io/mixedup
```

## Machines

Let's start with a very simple data set from the nlme package, which comes with the standard R installation.  The reason I chose this is because [Doug Bates has a good treatment](http://pages.stat.wisc.edu/~bates/UseR2008/WorkshopD.pdf) (see slides starting at 85) on this topic using that example, which I just extend a bit.

Here is the data description from the help file.
>Data on an experiment to compare three brands of machines used in an industrial process are presented in Milliken and Johnson (p. 285, 1992). Six workers were chosen randomly among the employees of a factory to operate each machine three times. The response is an overall productivity score taking into account the number and quality of components produced.

So for each worker and each machine, we'll have three scores.  Let's look.

```{r load-data}
machines = nlme::Machines

# for some reason worker is an ordered factor.
machines = machines %>% 
  mutate(Worker = factor(Worker, levels = 1:6, ordered = FALSE))
```

```{r show-data, echo=FALSE}
machines %>%
  arrange(Worker, Machine) %>% 
  kable_df()
```

This duplicates the plot in Bates' notes.

```{r vis-data, echo=FALSE}
# the order in the plot doesn't match the 'ordered' worker factor- go figure 
machines %>% 
  mutate(Worker = ordered(Worker, levels = rev(c(3,5,1,4,2,6)))) %>%
  group_by(Worker, Machine) %>% 
  mutate(mean = mean(score)) %>% 
  arrange(Worker) %>%
  ggplot(aes(
    x = score,
    y = Worker,
    color = Machine,
    group = Machine
  )) +
  geom_point() +
  geom_path(aes(x = mean)) +
  visibly::theme_clean()
```


The random effects of potential interest are for worker and machine, so how do we specify this?  Let's try the following standard approach.

```{r model_m_slope}
model_m_slope = lmer(score ~ Machine + (1 + Machine | Worker), machines)
```

This was exactly the same issue our client had- problematic convergence.  This could be more of an issue with `lme4`, and we could certainly explore tweaks to make the problem go away (or use a different package like `glmmTMB`), but let's run with it.

```{r m-slope-results}
summarize_model(model_m_slope, ci = FALSE, cor_re = TRUE)
```

We get the variance components we expect, i.e. the variance attributable to the intercept (i.e. Machine A), as well as for the slopes for the difference in machine B vs. A, and C vs. A.  We also see the correlations among the random effects.  It's this part that Bates notes is hard to estimate and incurs estimating potentially notably more parameters than typical random effects models.  In this case we have different options that will be available to us.  

Let's start with the simplest, most plausible models.  The first would be to have at least a worker effect.  The next baseline model could be if we only had a machine by worker effect, i.e. a separate effect of each machine for each worker, essentially treating the interaction term as the sole clustering unit.


```{r baseline-models}
model_base_w  = lmer(score ~ Machine + (1 | Worker), machines)
model_base_wm = lmer(score ~ Machine + (1 | Worker:Machine), machines)
```

Examine the random effects to make clear the difference.  For our first baseline model, we only have 6 effects, one for each worker. For the second we have an effect of each machine for each worker.

```{r machines-baseline-re, eval=FALSE}
extract_random_effects(model_base_w)  # only 6 effects
extract_random_effects(model_base_wm) # 6 workers by 3 machines = 18 effects
```

```{r machines-baseline-re, echo=FALSE}
extract_random_effects(model_base_w)   %>% kable_df()
extract_random_effects(model_base_wm)  %>% kable_df()
```

Now let's add an interaction of worker with machine rather than machine as a random slope.  This essentially combines our two baseline models.

```{r machines-model_w_wm}
model_w_wm = lmer(score ~ Machine + (1 | Worker) + (1 | Worker:Machine), machines)
```

Now we have 6 worker effects plus 18 machine within worker effects[^within]. 

```{r machines-model_w_wm-re}
extract_random_effects(model_w_wm)
```


```{r}
# any interest in this?
# model_w_wm2 = lmer(score ~ Machine + (1 | Worker) + (0 + Machine | Worker), machines)
```

Next we'll do the 'vector-valued' model Bates describes.  This removes the intercept of the initial model, but otherwise is the same.

```{r machines-model_m_vv}
model_m_vv = lmer(score ~ Machine + (0 + Machine | Worker), machines)
```

```{r}
# machines_dum = data.frame(machines, model.matrix(score ~ 0 + Machine, machines))
# model_m_dummy = lmer(
#   score ~ Machine + 
#     (1 | Worker:MachineA) + 
#     (1 | Worker:MachineB) + 
#     (1 | Worker:MachineC),
#   machines_dum
# )
# 
# summary(model_m_dummy)
```

Now let's extract the fixed effect and variance component summaries for all the models

```{r machines-model-list}
model_list = mget(ls(pattern = 'model_'))
fe = map_df(model_list, extract_fixed_effects, .id = 'model')
vc = map_df(model_list, extract_vc, ci_level = 0, .id = 'model')
```

Here are the fixed effects.  There are no differences in the coefficients for the fixed effect of machine.  However, there are notable differences for the estimated standard errors.  Practically we'd come to know differences in our conclusions, but the uncertainty associated with them would be different.

```{r machines-fe, echo=FALSE}
kable_df(fe)
```

Here are the variance components

```{r machines-vc, echo=FALSE}
kable_df(vc)
```

As we would expect if we dummy coded vs. running a model without the intercept, the random slope model and vector-valued models are identical and produce the same AIC. Likewise the intercept variance of the former is equal to the first group variance of the vector-valued model.

```{r}
map_df(model_list, AIC) %>% data.frame()
```

We can see that the `base_wm` model has (non-residual) variance `r extract_vc(model_base_wm, ci_level = 0)$variance[1]`.  This equals the total of the two (non-residual) variance components of the `w_wm` model, and variance of the vector-valued model divided by the number of groups `r extract_vc(model_m_vv, ci_level = 0)$variance[1:3]` `/` `r nlevels(machines$Machine)`.

We can see that the estimated random effects are essentially the same as from the baseline, interaction-only model (also the two identical models produce identical random effects).  However, the way it is estimated allows for estimation of correlations among the machine random effects, so they are not identical.

```{r echo=FALSE}
extract_random_effects(model_m_vv) %>% arrange(group, effect) %>% 
  kable_df()
extract_random_effects(model_base_wm) %>% 
  kable_df()
```

Even the default way that the extracted random effects are structured implies this. In the first we have a multivariate normal draw for 6 workers and 3 machines (i.e. 3 variances and 3 covariances).  In the latter, we do not estimate any covariances  and assume equal variance to draw for 18 groups (1 variance).

```{r}
ranef(model_m_vv)
ranef(model_base_wm)
```


https://github.com/m-clark/Visuals/tree/master/random_effects

## Simulation






```{r}
# adding actual slope re in this case we're assuming the form of (1 + cat_var |
# id) with corresponding correlations



# for simplicity keeping to 3 cat levels
set.seed(1234)
ng = 5000     # n groups
cat_levs = 3  # n obs per group
reps = 5      # number of obs per level per cat

id = rep(1:ng, each = cat_levs*reps)
cat_var = rep(1:cat_levs, times = ng, e = reps)
x = rnorm(ng*cat_levs*reps)
x_c = rep(rnorm(ng), e = cat_levs*reps)  # cluster level covariate


# as independent
# re_id = rep(rnorm(ng, sd = .5), each = cat_levs*reps)
# re_id_cat_lev2 = rep(rnorm(ng*cat_levs, sd = .25), each = reps)
# re_id_cat_lev3 = rep(rnorm(ng*cat_levs, sd = .25), each = reps)

# as correlated
cov_mat = lazerhawk::create_corr(c(.25, .25, .25), diagonal = c(1, .5, .5))

# cov_mat = matrix(c(.5, .25, .25, .5), 2, byrow = T)  # .5 var, .25 sd  .5 cor
cov2cor(cov_mat)

re_id_cat_lev = mvtnorm::rmvnorm(ng, mean = rep(0, 3), sigma = cov_mat) %>% 
  data.frame()

y = 2  + .5*x - .5*x_c + 
  rep(re_id_cat_lev[,1], each = cat_levs*reps) + 
  (.25 + rep(re_id_cat_lev[,2], each = cat_levs*reps)) * (cat_var == 2) +
  (.40 + rep(re_id_cat_lev[,3], each = cat_levs*reps)) * (cat_var == 3) +
  rnorm(ng*cat_levs*reps, sd = .5)

df = tibble(
    id,
    cat_var,
    x,
    x_c,
    y,
    re_id = rep(re_id_cat_lev[, 1], each = cat_levs*reps),
    re_id_cat_lev2 = rep(re_id_cat_lev[, 2], each = cat_levs*reps),
    re_id_cat_lev3 = rep(re_id_cat_lev[, 3], each = cat_levs*reps)
  ) %>% 
  mutate(
    cat_var = factor(cat_var),
    cat_as_num = as.integer(cat_var),
    id = factor(id),
    cat_var_1 = factor(cat_var == 1),
    cat_var_2 = factor(cat_var == 2),
    cat_var_3 = factor(cat_var == 3)
  )

df %>% print(n = 30)

m_lm = lm(y ~ x + x_c + cat_var, df)

m_int_only = lmer(y ~ x + x_c + cat_var + (1 | id), df)
m_interaction_only = lmer(y ~ x + x_c + cat_var + (1 | id:cat_var), df)
m_random_slope = lmer(y ~ x + x_c + cat_var + (1 + cat_var | id), df)    # problems!
m_as_numeric = lmer(y ~ x + x_c + cat_var + (1 + cat_as_num | id), df)
m_vector_valued = lmer(y ~ x + x_c + cat_var + (0 + cat_var | id), df)
m_separate_re = lmer(y ~ x + x_c + cat_var + (1 | id) + (1 | id:cat_var), df)
m4 = lmer(y ~ x + x_c + cat_var + (1 | id:cat_var_1) + (1 | id:cat_var_2)  + (1 | id:cat_var_3),
          df
)

model_mixed = list(
  m_int_only = m_int_only,
  m_interaction_only = m_interaction_only,
  m_as_numeric = m_as_numeric,
  m_random_slope = m_random_slope,
  m_vector_valued = m_vector_valued,
  m_separate_re = m_separate_re
)

summary(m_lm)
map_df(model_mixed, extract_fixed_effects, .id = 'model') %>% data.frame()
map_df(model_mixed, extract_vc, ci_level = 0, .id = 'model')

# summarize_model(m2, cor_re = T, ci = 0)

# preds = tibble(
#   m2 = predict(m2),
#   m5 = predict(m5)
# )

# cor(preds)

```

[^within]: Though I use the word 'within', do not take it to mean we have nested data.