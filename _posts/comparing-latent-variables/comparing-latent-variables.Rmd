---
title: "Comparing means with lavaan"
description: |
  Comparing means and intercepts of latent variables
author:
  - name: Michael Clark
    url: https://m-clark.github.io
date: '`r format(Sys.Date(), "%B %d, %Y")`'
preview: ../../img/198R.png   # apparently no way to change the size displayed via css (ignored) or file (stretched)
output:
  distill::distill_article:
    self_contained: false
    toc: true
    css: ../../test.css
draft: true
tags: [R, factor analysis, growth curve, structural equation modeling, SEM, intercepts, means]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo=T, 
  message = F, 
  warning = F, 
  comment = NA,
  R.options=list(width=120), 
  cache.rebuild=F, 
  cache=FALSE,
  fig.align='center', 
  dev = 'svg', 
  dev.args=list(bg = 'transparent')
)

library(tidyverse); library(broom); library(kableExtra); library(visibly)

kable_df <- function(..., digits=3) {
  kable(..., digits=digits) %>% 
    kable_styling(full_width = F)
}
```



## Introduction

In some cases we are interested in looking at group differences in latent variables.  For example, social scientists are interested in race and sex differences on psychological measures, or educational scientists might want to create exams in different languages. There are a variety of ways in to assess group differences across latent structure, such as anxiety or verbal ability, and this post provides a demo using lavaan.  

My motivation for doing this is that it comes up from time to time in consulting, and I wanted a quick reminder for the syntax to refer back to.  As a starting point though, you can find some demonstration on the [lavaan website](https://lavaan.ugent.be).  For more on factor analysis, structural equation modeling, and more, see [my document](https://m-clark.github.io/sem/).

## Multiple group analysis

A common way to assess group differences is via multiple group analysis, which amounts to doing separate structural equation models of some kind across the groups of interest.  We will use a classic data set to demonstrate the approach. From the help file:

> The Holzinger and Swineford (1939) dataset consists of mental ability test scores of seventh- and eighth-grade children from two different schools (Pasteur and Grant-White). In the original dataset, there are scores for 26 tests. However, a smaller subset with 9 variables is more widely used in the literature...

```{r data}
library(lavaan)
data(HolzingerSwineford1939)
```

The basic model is a factor analysis with three latent variables, with items for visual-spatial ability (`x1-x3`), verbal comprehension (`x4-x6`), and so-called 'speed' tests (`x7-x9`), e.g. for addition and counting, which might be thought of general cognitive processing.

With lavaan, we specify the model for three factor (or latent variables).  After that, a simple group argument will allow the multigroup analysis, providing the factor analysis for both school groups.

```{r standard_multigroup}
library(tidyverse)
library(lavaan)

hs_model_baseline <- ' 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
'

fit_baseline <- cfa(
  hs_model_baseline, 
  data = HolzingerSwineford1939, 
  group = "school"
)

summary(fit_baseline)  
```

So we're left with visual inspection to note whether there are general differences among the groups. This is all well and good, but perhaps we want a more statistical approach.  Say our question specifically concerns a mean difference between schools on the visual latent variable.  How do we go about it?

Note that the intercepts for the latent variables are zero.  They have to be for the model to be identified, much in the same way that at least one factor loading (the first by default) has to be fixed to one.  We only have so much information to estimate so many parameters.

## Latent variable intercepts

```{r baseline_2, eval=FALSE, echo=TRUE}
fit_baseline_2 <- cfa(
  hs_model_baseline, 
  data = HolzingerSwineford1939, 
  group = "school",
  group.equal = c('loadings', 'intercepts')
)

summary(fit_baseline_2) 
```


To get around this limitation, we could try and fix some parameters, thereby freeing the intercepts to be estimated.  For example, if instead we fix the mean of one of the observed variables to be zero instead, we would be able to estimate the intercept for the latent variable. In the following we'll do this for the visuo-spatial ability construct.


```{r hs_model_1}
hs_model_1 <- ' 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
  
  
  # intercepts: in order to have an identified model, you would have to fix the
  # intercepts of observed to 0, 1 represents the intercept, 0* fixes it to be 0
  x1 ~ 0*1   

  # intercept for Pasteur and Grant-White schools
  visual ~  c(int_p, int_gw)*1    
   
  # comparisons
  diff := int_p - int_gw
'

fit_1 <- cfa(hs_model_1, 
           data = HolzingerSwineford1939, 
           group = "school",
           meanstructure = T)
summary(fit_1, std=T)

coef_1 = broom::tidy(fit_1) %>% 
  filter(label != '')

coef_1 %>% kable_df()
```

The above shows the schools not to be much different from one another on the visual-spatial ability latent variable.  But compare this result to the intercepts for `x1` in our baseline model.  This model would would be identical to comparing the intercepts on whichever observed variable you previously fixed to zero.  Much like we must scale the latent variable to that of one of the observed variables by fixing the loading to be 1, we essentially come to the same type of issue by fixing its mean to be on that of the observed variable.

To make this more explicit, we'll label the `x1` intercepts in our baseline model and look at their difference.

```{r hs_model_2}
hs_model_2 <- ' 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
  
  x1 ~ c(a, b)*1   
   
  # comparisons
   diff := a - b
'

fit_2 <- cfa(hs_model_2, 
           data = HolzingerSwineford1939, 
           group = "school",
           meanstructure = T)

summary(fit_2, std=T)

coef_2 = broom::tidy(fit_2) %>% 
  filter(label != '')

coef_2 %>% kable_df()
```

Same difference.


## Observed variable group differences

The following approach is not the same model, but would also provide the same result. In this case, each observed variable is affected by the school grouping, and the path coefficient for `x1` is the same difference in means as before.


```{r hs_model_3}
hs_model_3 <- ' 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
  
  x1 ~ diff*school 
  x2 + x3 + x4 + x5 + x6 +  x7 + x8 + x9 ~ school
'

fit_3 <- cfa(hs_model_3, 
             data = HolzingerSwineford1939,
             meanstructure = T)

summary(fit_3, std=T)

coef_3 = broom::tidy(fit_3)
```

A comparison of all three shows the same results, but that the third model has fewer parameters, as the loadings and latent variable variances are not changing across groups.

```{r compare_123_data, echo=FALSE}
bind_rows(
  coef_1 %>% filter(label == 'diff'), 
  coef_2 %>% filter(label == 'diff'), 
  coef_3 %>% filter(label == 'diff'), .id = 'model'
) %>% 
  select(estimate, std.error, conf.low, conf.high)

model_list = list(fit_1=fit_1, fit_2=fit_2, fit_3=fit_3)
```


```{r compare_123_Npar, echo=FALSE}
model_list %>% 
  map_df(function(x) length(coef(x))) %>% 
  kable_df(caption = 'Model N parameters')
```


```{r compare_123_AIC, echo=FALSE}
model_list %>% 
  map_df(AIC) %>% 
  kable_df(caption = 'Model AIC')
```

## Structural model

In the models I see, people would more commonly address such a theoretical question without a multigroup approach, simply regressing the latent variable of interest on the group factor.  We can do that here.

```{r hs_model_4a}
# standard cfa with school predicting visual
hs_model_4a <- ' 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
  
  visual ~ diff*school
  
  visual ~~ speed + verbal  # lavaan will not estimate this by default
'

fit_4a = sem(hs_model_4a, data=HolzingerSwineford1939, meanstructure=T)
summary(fit_4a)
```

At first blush, it would seem we are not getting the same result. Our difference is notably larger and significant.

```{r compare_1234a, echo=FALSE}
model_list = mget(ls(pattern = '^fit'))

model_list %>% 
  map_df(AIC)
model_list %>% map_df(function(x) length(coef(x)))
```

But as before, we can recover the multigroup results by regressing the other observed variables on school as well.

```{r hs_model_4b}
hs_model_4b <- ' 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
  
  visual ~ diff*school
  
  x2 + x3 + x4 + x5 + x6 +  x7 + x8 + x9 ~ school
'

fit_4b = sem(hs_model_4b, data=HolzingerSwineford1939, meanstructure=T)
```

```{r compare_1234b, echo=FALSE}
model_list = mget(ls(pattern = '^fit'))

coef_4b = broom::tidy(fit_4b)

model_list %>% 
  map_df(AIC)
model_list %>% map_df(function(x) length(coef(x)))

bind_rows(
  coef_1 %>% filter(label == 'diff'), 
  coef_2 %>% filter(label == 'diff'), 
  coef_3 %>% filter(label == 'diff'),
  coef_4b %>% filter(label == 'diff'), 
  .id = 'model'
) %>% 
  mutate(model = c(1:3, '4b')) %>% 
  select(model, estimate, std.error, conf.low, conf.high)
```

Going back to the first structural model `hs_model_4a`, it might be interesting to some to see that it the group difference *still* regards a difference on the `x1` observed variable.  We can see this more clearly if we set the x1 loading to be estimated rather than fixed at one, then use the product of coefficients approach (a la mediation) to estimate the group difference.

```{r hs_model_4c}
hs_model_4c <- ' 
  visual =~ x2 + a*x1 + x3    # estimate x1 loading vs. scaling by it
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 

  visual ~ b*school
  
  visual ~~ verbal + speed
  
  diff := a*b    # "indirect" effect of school on x1
'

# same as fit_4a
fit_4c = cfa(hs_model_4c, data = HolzingerSwineford1939, meanstructure=T)
coef_4c = broom::tidy(fit_4c) %>% filter(label=='diff') 
coef_4a = broom::tidy(fit_4a) %>% filter(label=='diff') 

bind_rows(coef_4a, coef_4c) %>% 
  mutate(model = c('4a', '4c')) %>% 
  select(model, label:conf.high)
```

And what is this value of `r coef_4c$estimate`?





The following is equivalent to the result one would get from `group.equal = c('loadings', 'intercepts')`.  The first group would have latent variable means at zero, while the second group would be allowed to vary.  This is more or less what is desired. 

```{r hs_model_test}
hs_model_test <- ' 
  # make loadings equal across groups
  
  visual =~ c(1, 1)*x1 + c(v_x2, v_x2)*x2 + c(v_x3, v_x3)*x3
  verbal =~ c(1, 1)*x4 + c(v_x5, v_x5)*x5 + c(v_x6, v_x6)*x6
  speed  =~ c(1, 1)*x7 + c(v_x8, v_x8)*x8 + c(v_x9, v_x9)*x9 
  
  # make intercepts equal across groups
  
  x1 ~ c(0, 0) * 1
  x2 ~ c(int_x2, int_x2) * 1
  x3 ~ c(int_x3, int_x3) * 1
  x4 ~ c(0, 0) * 1
  x5 ~ c(int_x5, int_x5) * 1
  x6 ~ c(int_x6, int_x6) * 1
  x7 ~ c(0, 0) * 1
  x8 ~ c(int_x8, int_x8) * 1
  x9 ~ c(int_x9, int_x9) * 1
  
  # make covariances equal across groups
  
  # visual ~~ c(cov_vv, cov_vv) * verbal + c(cov_visp, cov_visp) * speed
  # verbal ~~ c(cov_vesp, cov_vesp) * speed
  
  # make variances equal
  
  # visual ~~ c(vvar, vvar) * visual
  # verbal ~~ c(tvar, tvar) * verbal
  # speed  ~~ c(svar, svar) * speed
  
  # x1 ~~ c(x1var, x1var) * x1
  # x2 ~~ c(x2var, x2var) * x2
  # x3 ~~ c(x3var, x3var) * x3
  # x4 ~~ c(x4var, x4var) * x4
  # x5 ~~ c(x5var, x5var) * x5
  # x6 ~~ c(x6var, x6var) * x6
  # x7 ~~ c(x7var, x7var) * x7
  # x8 ~~ c(x8var, x8var) * x8
  # x9 ~~ c(x9var, x9var) * x9
  
  
  visual ~ c(vis_int_p, vis_int_gw)*1
  verbal ~ c(verb_int_p, verb_int_gw)*1
  speed  ~ c(speed_int_p, speed_int_gw)*1
  
  
   
  # comparisons
   diff := vis_int_p - vis_int_gw
'

fit_test  = sem(hs_model_test, 
                data=HolzingerSwineford1939, 
                group = 'school',
                meanstructure=T)

summary(fit_test)

lavaanPlot::lavaanPlot(model = fit_test, coefs=T, covs=T)
```


The more simple and obvious way to do it.

```{r hs_model_4d, echo=FALSE}
hs_model_4d <- ' 
  visual =~ x1 + x2 + x3    # estimate x1 loading vs. scaling by it
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 

  visual ~ diff*school
  
  verbal + speed ~ school
  
'

fit_4d = cfa(hs_model_4d, data = HolzingerSwineford1939, meanstructure=T)
summary(fit_4d)

coef_4d = broom::tidy(fit_4d) %>% filter(label=='diff')

bind_rows(
  coef_1 %>% filter(label == 'diff'), 
  coef_2 %>% filter(label == 'diff'), 
  coef_3 %>% filter(label == 'diff'),
  coef_4b %>% filter(label == 'diff'), 
  coef_4d %>% filter(label == 'diff'), 
  .id = 'model'
) %>% 
  mutate(model = c(1:3, '4b', '4d')) %>% 
  select(model, estimate, std.error, conf.low, conf.high)
```


## Sum/Factor score

```{r sum_score}
hs_model_5 <- ' 
  visual =~ x1 + l1*x2 + l1*x3
  verbal =~ x4 + l2*x5 + l2*x6
  speed  =~ x7 + l3*x8 + l3*x9 
  
  # x1 ~~ a*x1
  # x2 ~~ a*x2
  # x3 ~~ a*x3
  # x4 ~~ a*x4
  # x5 ~~ a*x5
  # x6 ~~ a*x6
  # x7 ~~ a*x7
  # x8 ~~ a*x8
  # x9 ~~ a*x9
'


fit_5 = cfa(hs_model_5, data = HolzingerSwineford1939, meanstructure=T)


HolzingerSwineford1939 = HolzingerSwineford1939 %>% 
  mutate(visual = lavPredict(fit_5)[,'visual'],
         verbal = lavPredict(fit_5)[,'verbal'],
         speed  = lavPredict(fit_5)[,'speed'])
ttest1 = lm(visual ~ school, data = HolzingerSwineford1939)
coef(ttest1)  # same as x1 diffs

hs_model_fsr <- ' 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
  
  visual ~ school
'

# fsr function now hidden and evidently broken? even naive method doesn't work;
# tried all methods for scores and approach
# ttest1b = lavaan:::fsr(hs_model_fsr,
#                        data = HolzingerSwineford1939)
# coef(ttest1b)


ttest2 = lm(rowSums(HolzingerSwineford1939 %>% select(x1:x3)) ~ HolzingerSwineford1939$school)
coef(ttest2)  # same as structural diffs
```


What should be apparent at this point is that the multigroup approach is an interaction of everything with the grouping variable.  Honestly I think this is rarely desirable theoretically, or at least we rarely do this in other modeling contexts.


## Measurement invariance

In some cases we are instead looking for similarities across groups among the latent constructs, rather than differences.  This is especially the case in scale development, where one would like a measure to be consistent across groups of individuals (e.g. sex, age, race, etc.).  

Aside from general problems of 'accepting the null hypothesis', the basic idea is to test a restricted model vs. the less restrictive one that assumes the differences across groups exist, and if they are not appreciably different, then one can claim equivalence across groups.  As a starting point, we assume <span class="emph">configural</span> equivalence, or in other words, that the factor structure is the same.  There is no point in testing measurement equivalence if there is not a similar factor structure.  The first restricted model is that the loadings are equivalent.  The next is that observed variable intercepts are equivalent, followed by latent variable means, and finally residual variances/covariances.



```{r measurement_invariance}
hs_model_4 <- ' 
  visual  =~ x1 + x2 + x3
  verbal  =~ x4 + x5 + x6
  speed   =~ x7 + x8 + x9 
'

semTools::measurementInvariance(
  model = hs_model_4, 
  data = HolzingerSwineford1939, 
  group = "school"
)


```

```{r measurement_invariance_current_approach}
# wow, from one line to this. this is an awful choice for an alternative
test.seq <- c("loadings","intercepts","means","residuals")
meq.list <- list()
for (i in 0:length(test.seq)) {
  if (i == 0L) {
    meq.label <- "configural"
    group.equal <- ""
    # long.equal <- ""
  } else {
    meq.label <- test.seq[i]
    group.equal <- test.seq[1:i]
    # long.equal <- test.seq[1:i]
  }
  meq.list[[meq.label]] <- semTools::measEq.syntax(
    configural.model = hs_model_baseline,
    data = HolzingerSwineford1939,
    ID.fac = "auto.fix.first",
    group = "school",
    group.equal = group.equal,
    # longFacNames = longFacNames,
    # long.equal = long.equal,
    return.fit = TRUE
  )
}

# and of course, this is still a borked function
semTools::compareFit(meq.list)


# means_only
test.seq <- c("means")
meq.list <- list()
for (i in 0:length(test.seq)) {
  if (i == 0L) {
    meq.label <- "configural"
    group.equal <- ""
    # long.equal <- ""
  } else {
    meq.label <- test.seq[i]
    group.equal <- test.seq[1:i]
    # long.equal <- test.seq[1:i]
  }
  meq.list[[meq.label]] <- semTools::measEq.syntax(
    configural.model = hs_model_baseline,
    data = HolzingerSwineford1939,
    ID.fac = "auto.fix.first",
    group = "school",
    group.equal = group.equal,
    # longFacNames = longFacNames,
    # long.equal = long.equal,
    return.fit = TRUE
  )
}

semTools::compareFit(meq.list)
```
