<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
  <title>Comparing means with lavaan</title>
  
  <meta property="description" itemprop="description" content="Comparing means and intercepts of latent variables"/>
  
  
  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2019-04-17"/>
  <meta property="article:created" itemprop="dateCreated" content="2019-04-17"/>
  <meta name="article:author" content="Michael Clark"/>
  
  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Comparing means with lavaan"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="Comparing means and intercepts of latent variables"/>
  <meta property="og:locale" content="en_US"/>
  
  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Comparing means with lavaan"/>
  <meta property="twitter:description" content="Comparing means and intercepts of latent variables"/>
  
  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","preview","output","draft","tags"]}},"value":[{"type":"character","attributes":{},"value":["Comparing means with lavaan"]},{"type":"character","attributes":{},"value":["Comparing means and intercepts of latent variables\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Michael Clark"]},{"type":"character","attributes":{},"value":["https://m-clark.github.io"]}]}]},{"type":"character","attributes":{},"value":["April 17, 2019"]},{"type":"character","attributes":{},"value":["../../img/198R.png"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc","css"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["../../test.css"]}]}]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["R","factor analysis","growth curve","structural equation modeling","SEM","intercepts","means"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["comparing-latent-variables_files/bowser-1.9.3/bowser.min.js","comparing-latent-variables_files/DiagrammeR-styles-0.2/styles.css","comparing-latent-variables_files/distill-2.2.21/template.v2.js","comparing-latent-variables_files/grViz-binding-1.0.0/grViz.js","comparing-latent-variables_files/htmlwidgets-1.3/htmlwidgets.js","comparing-latent-variables_files/jquery-1.11.3/jquery.min.js","comparing-latent-variables_files/kePrint-0.0.1/kePrint.js","comparing-latent-variables_files/viz-0.3/viz.js","comparing-latent-variables_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->
  
  <style type="text/css">
  
  body {
    background-color: white;
  }
  
  .pandoc-table {
    width: 100%;
  }
  
  .pandoc-table>caption {
    margin-bottom: 10px;
  }
  
  .pandoc-table th:not([align]) {
    text-align: left;
  }
  
  .pagedtable-footer {
    font-size: 15px;
  }
  
  .html-widget {
    margin-bottom: 2.0em;
  }
  
  .l-screen-inset {
    padding-right: 16px;
  }
  
  .l-screen .caption {
    margin-left: 10px;
  }
  
  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .shaded-content {
    background: white;
  }
  
  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }
  
  .hidden {
    display: none !important;
  }
  
  d-article {
    padding-bottom: 30px;
  }
  
  d-appendix {
    padding-top: 30px;
  }
  
  d-article>p>img {
    width: 100%;
  }
  
  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }
  
  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  /* CSS for table of contents */
  
  .d-toc {
    color: rgba(0,0,0,0.8);
    font-size: 0.8em;
    line-height: 1em;
  }
  
  .d-toc-header {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    text-transform: uppercase;
    margin-top: 0;
    margin-bottom: 1.3em;
  }
  
  .d-toc a {
    border-bottom: none;
  }
  
  .d-toc ul {
    padding-left: 0;
  }
  
  .d-toc li>ul {
    padding-top: 0.8em;
    padding-left: 16px;
    margin-bottom: 0.6em;
  }
  
  .d-toc ul,
  .d-toc li {
    list-style-type: none;
  }
  
  .d-toc li {
    margin-bottom: 0.9em;
  }
  
  .d-toc-separator {
    margin-top: 20px;
    margin-bottom: 2em;
  }
  
  .d-article-with-toc {
    border-top: none;
    padding-top: 0;
  }
  
  
  
  /* Tweak code blocks (note that this CSS is repeated above in an injection
     into the d-code shadow dom) */
  
  d-code {
    overflow-x: auto !important;
  }
  
  pre.d-code code.d-code {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }
  
  pre.text-output {
  
    font-size: 12px;
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  @media(min-width: 768px) {
  
  d-code {
    overflow-x: visible !important;
  }
  
  pre.d-code code.d-code  {
      padding-left: 18px;
      font-size: 14px;
  }
  pre.text-output {
    font-size: 14px;
  }
  }
  
  /* Figure */
  
  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }
  
  .figure img {
    width: 100%;
  }
  
  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }
  
  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }
  
  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }
  
  
  
  /* Tweak 1000px media break to show more text */
  
  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }
  
    .grid {
      grid-column-gap: 16px;
    }
  
    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }
  
  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }
  
    .grid {
      grid-column-gap: 32px;
    }
  }
  
  
  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */
  
  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  
  
  /* Social footer */
  
  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }
  
  .disqus-comments {
    margin-right: 30px;
  }
  
  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }
  
  #disqus_thread {
    margin-top: 30px;
  }
  
  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }
  
  .article-sharing a:hover {
    border-bottom: none;
  }
  
  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .subscribe p {
    margin-bottom: 0.5em;
  }
  
  
  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }
  
  
  /* Improve display for browsers without grid (IE/Edge <= 15) */
  
  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }
  
  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }
  
  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }
  
  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }
  
  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }
  
  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }
  
  
  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }
  
  .downlevel .footnotes ol {
    padding-left: 13px;
  }
  
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }
  
  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }
  
  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }
  
  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  </style>
  
  <script type="application/javascript">
  
  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }
  
  // show body when load is complete
  function on_load_complete() {
  
    // set body to visible
    document.body.style.visibility = 'visible';
  
    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }
  
    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }
  
  function init_distill() {
  
    init_common();
  
    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);
  
    // create d-title
    $('.d-title').changeElementType('d-title');
  
    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);
  
    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();
  
    // move posts container into article
    $('.posts-container').appendTo($('d-article'));
  
    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');
  
    // create d-bibliography
    var bibliography = $('<d-bibliography></d-bibliography>');
    $('#distill-bibliography').wrap(bibliography);
  
    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;
  
    // replace citations with <d-cite>
    $('.citation').each(function(i, val) {
      appendix = true;
      var cites = $(this).attr('data-cites').split(" ");
      var dt_cite = $('<d-cite></d-cite>');
      dt_cite.attr('key', cites.join());
      $(this).replaceWith(dt_cite);
    });
    // remove refs
    $('#refs').remove();
  
    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();
  
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-toc a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });
  
    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');
  
    // replace code blocks with d-code
    $('pre>code').each(function(i, val) {
      var code = $(this);
      var pre = code.parent();
      var clz = "";
      var language = pre.attr('class');
      if (language) {
        // map unknown languages to "clike" (without this they just dissapear)
        if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                                 "javascript", "js", "julia", "lua", "markdown",
                                 "markup", "mathml", "python", "svg", "xml"]) == -1)
          language = "clike";
        language = ' language="' + language + '"';
        var dt_code = $('<d-code block' + language + clz + '></d-code>');
        dt_code.text(code.text());
        pre.replaceWith(dt_code);
      } else {
        code.addClass('text-output').unwrap().changeElementType('pre');
      }
    });
  
    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {
  
      // capture layout
      var layout = $(this).attr('data-layout');
  
      // apply layout to markdown level block elements
      var elements = $(this).children().not('d-code, pre.text-output, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });
  
  
      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });
  
    // load distill framework
    load_distill_framework();
  
    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {
  
      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;
  
      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');
  
      // table of contents
      if (have_authors) // adjust border if we are in authors
        $('.d-toc').parent().addClass('d-article-with-toc');
  
      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');
  
      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }
  
      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');
  
      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");
  
      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }
  
       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }
  
      // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
      $('d-code').each(function(i, val) {
        var style = document.createElement('style');
        style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                          '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
        if (this.shadowRoot)
          this.shadowRoot.appendChild(style);
      });
  
      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();
  
      // clear polling timer
      clearInterval(tid);
  
      // show body now that everything is ready
      on_load_complete();
    }
  
    var tid = setInterval(distill_post_process, 50);
    distill_post_process();
  
  }
  
  function init_downlevel() {
  
    init_common();
  
     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));
  
    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
  
    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();
  
    // remove toc
    $('.d-toc-header').remove();
    $('.d-toc').remove();
    $('.d-toc-separator').remove();
  
    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });
  
  
    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);
  
    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);
  
    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();
  
    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();
  
    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));
  
    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });
  
    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));
  
    $('body').addClass('downlevel');
  
    on_load_complete();
  }
  
  
  function init_common() {
  
    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};
  
        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });
  
        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);
  
    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});
  
    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });
  
      }
    });
  
    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });
  
    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }
  
    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');
  
    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");
  
    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();
  
    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }
  
  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });
  
  </script>
  
  <!--/radix_placeholder_distill-->
  <script src="comparing-latent-variables_files/kePrint-0.0.1/kePrint.js"></script>
  <script src="comparing-latent-variables_files/htmlwidgets-1.3/htmlwidgets.js"></script>
  <script src="comparing-latent-variables_files/viz-0.3/viz.js"></script>
  <link href="comparing-latent-variables_files/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
  <script src="comparing-latent-variables_files/grViz-binding-1.0.0/grViz.js"></script>
  <script src="comparing-latent-variables_files/jquery-1.11.3/jquery.min.js"></script>
  <script src="comparing-latent-variables_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="comparing-latent-variables_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="comparing-latent-variables_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->

  <link rel="stylesheet" href="../../test.css" type="text/css"/>

</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Comparing means with lavaan","description":"Comparing means and intercepts of latent variables","authors":[{"author":"Michael Clark","authorURL":"https://m-clark.github.io","affiliation":"&nbsp;","affiliationURL":"#"}],"publishedDate":"2019-04-17T00:00:00.000-05:00","citationText":"Clark, 2019"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Comparing means with lavaan</h1>
<p>Comparing means and intercepts of latent variables</p>
</div>

<div class="d-byline">
  Michael Clark <a href="https://m-clark.github.io" class="uri">https://m-clark.github.io</a> 
  
<br/>April 17, 2019
</div>

<div class="d-article">
<h3 class="d-toc-header">Table of Contents</h3>
<nav class="d-toc" id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#multiple-group-analysis">Multiple group analysis</a></li>
<li><a href="#latent-variable-intercepts">Latent variable intercepts</a></li>
<li><a href="#observed-variable-group-differences">Observed variable group differences</a></li>
<li><a href="#structural-model">Structural model</a></li>
<li><a href="#sumfactor-score">Sum/Factor score</a></li>
<li><a href="#measurement-invariance">Measurement invariance</a></li>
</ul>
</nav>
<hr class="d-toc-separator"/>
<h2 id="introduction">Introduction</h2>
<p>In some cases we are interested in looking at group differences in latent variables. For example, social scientists are interested in race and sex differences on psychological measures, or educational scientists might want to create exams in different languages. There are a variety of ways in to assess group differences across latent structure, such as anxiety or verbal ability, and this post provides a demo using lavaan.</p>
<p>My motivation for doing this is that it comes up from time to time in consulting, and I wanted a quick reminder for the syntax to refer back to. As a starting point though, you can find some demonstration on the <a href="https://lavaan.ugent.be">lavaan website</a>. For more on factor analysis, structural equation modeling, and more, see <a href="https://m-clark.github.io/sem/">my document</a>.</p>
<h2 id="multiple-group-analysis">Multiple group analysis</h2>
<p>A common way to assess group differences is via multiple group analysis, which amounts to doing separate structural equation models of some kind across the groups of interest. We will use a classic data set to demonstrate the approach. From the help file:</p>
<blockquote>
<p>The Holzinger and Swineford (1939) dataset consists of mental ability test scores of seventh- and eighth-grade children from two different schools (Pasteur and Grant-White). In the original dataset, there are scores for 26 tests. However, a smaller subset with 9 variables is more widely used in the literature…</p>
</blockquote>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(lavaan)
data(HolzingerSwineford1939)</code></pre>
</div>
<p>The basic model is a factor analysis with three latent variables, with items for visual-spatial ability (<code>x1-x3</code>), verbal comprehension (<code>x4-x6</code>), and so-called ‘speed’ tests (<code>x7-x9</code>), e.g. for addition and counting, which might be thought of general cognitive processing.</p>
<p>With lavaan, we specify the model for three factor (or latent variables). After that, a simple group argument will allow the multigroup analysis, providing the factor analysis for both school groups.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(tidyverse)
library(lavaan)

hs_model_baseline &lt;- &#39; 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
&#39;

fit_baseline &lt;- cfa(
  hs_model_baseline, 
  data = HolzingerSwineford1939, 
  group = &quot;school&quot;
)

summary(fit_baseline)  </code></pre>
<pre><code>
lavaan 0.6-3 ended normally after 57 iterations

  Optimization method                           NLMINB
  Number of free parameters                         60

  Number of observations per group         
  Pasteur                                          156
  Grant-White                                      145

  Estimator                                         ML
  Model Fit Test Statistic                     115.851
  Degrees of freedom                                48
  P-value (Chi-square)                           0.000

Chi-square for each group:

  Pasteur                                       64.309
  Grant-White                                   51.542

Parameter Estimates:

  Information                                 Expected
  Information saturated (h1) model          Structured
  Standard Errors                             Standard


Group 1 [Pasteur]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                1.000                           
    x2                0.394    0.122    3.220    0.001
    x3                0.570    0.140    4.076    0.000
  verbal =~                                           
    x4                1.000                           
    x5                1.183    0.102   11.613    0.000
    x6                0.875    0.077   11.421    0.000
  speed =~                                            
    x7                1.000                           
    x8                1.125    0.277    4.057    0.000
    x9                0.922    0.225    4.104    0.000

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~~                                           
    verbal            0.479    0.106    4.531    0.000
    speed             0.185    0.077    2.397    0.017
  verbal ~~                                           
    speed             0.182    0.069    2.628    0.009

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                4.941    0.095   52.249    0.000
   .x2                5.984    0.098   60.949    0.000
   .x3                2.487    0.093   26.778    0.000
   .x4                2.823    0.092   30.689    0.000
   .x5                3.995    0.105   38.183    0.000
   .x6                1.922    0.079   24.321    0.000
   .x7                4.432    0.087   51.181    0.000
   .x8                5.563    0.078   71.214    0.000
   .x9                5.418    0.079   68.440    0.000
    visual            0.000                           
    verbal            0.000                           
    speed             0.000                           

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.298    0.232    1.286    0.198
   .x2                1.334    0.158    8.464    0.000
   .x3                0.989    0.136    7.271    0.000
   .x4                0.425    0.069    6.138    0.000
   .x5                0.456    0.086    5.292    0.000
   .x6                0.290    0.050    5.780    0.000
   .x7                0.820    0.125    6.580    0.000
   .x8                0.510    0.116    4.406    0.000
   .x9                0.680    0.104    6.516    0.000
    visual            1.097    0.276    3.967    0.000
    verbal            0.894    0.150    5.963    0.000
    speed             0.350    0.126    2.778    0.005


Group 2 [Grant-White]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                1.000                           
    x2                0.736    0.155    4.760    0.000
    x3                0.925    0.166    5.583    0.000
  verbal =~                                           
    x4                1.000                           
    x5                0.990    0.087   11.418    0.000
    x6                0.963    0.085   11.377    0.000
  speed =~                                            
    x7                1.000                           
    x8                1.226    0.187    6.569    0.000
    x9                1.058    0.165    6.429    0.000

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~~                                           
    verbal            0.408    0.098    4.153    0.000
    speed             0.276    0.076    3.639    0.000
  verbal ~~                                           
    speed             0.222    0.073    3.022    0.003

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                4.930    0.095   51.696    0.000
   .x2                6.200    0.092   67.416    0.000
   .x3                1.996    0.086   23.195    0.000
   .x4                3.317    0.093   35.625    0.000
   .x5                4.712    0.096   48.986    0.000
   .x6                2.469    0.094   26.277    0.000
   .x7                3.921    0.086   45.819    0.000
   .x8                5.488    0.087   63.174    0.000
   .x9                5.327    0.085   62.571    0.000
    visual            0.000                           
    verbal            0.000                           
    speed             0.000                           

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.715    0.126    5.676    0.000
   .x2                0.899    0.123    7.339    0.000
   .x3                0.557    0.103    5.409    0.000
   .x4                0.315    0.065    4.870    0.000
   .x5                0.419    0.072    5.812    0.000
   .x6                0.406    0.069    5.880    0.000
   .x7                0.600    0.091    6.584    0.000
   .x8                0.401    0.094    4.249    0.000
   .x9                0.535    0.089    6.010    0.000
    visual            0.604    0.160    3.762    0.000
    verbal            0.942    0.152    6.177    0.000
    speed             0.461    0.118    3.910    0.000</code></pre>
</div>
<p>So we’re left with visual inspection to note whether there are general differences among the groups. This is all well and good, but perhaps we want a more statistical approach. Say our question specifically concerns a mean difference between schools on the visual latent variable. How do we go about it?</p>
<p>Note that the intercepts for the latent variables are zero. They have to be for the model to be identified, much in the same way that at least one factor loading (the first by default) has to be fixed to one. We only have so much information to estimate so many parameters.</p>
<h2 id="latent-variable-intercepts">Latent variable intercepts</h2>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
fit_baseline_2 &lt;- cfa(
  hs_model_baseline, 
  data = HolzingerSwineford1939, 
  group = &quot;school&quot;,
  group.equal = c(&#39;loadings&#39;, &#39;intercepts&#39;)
)

summary(fit_baseline_2) </code></pre>
</div>
<p>To get around this limitation, we could try and fix some parameters, thereby freeing the intercepts to be estimated. For example, if instead we fix the mean of one of the observed variables to be zero instead, we would be able to estimate the intercept for the latent variable. In the following we’ll do this for the visuo-spatial ability construct.</p>
<div class="layout-chunk" data-layout="l-body">

<pre class="r"><code>
hs_model_1 &lt;- &#39; 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
  
  
  # intercepts: in order to have an identified model, you would have to fix the
  # intercepts of observed to 0, 1 represents the intercept, 0* fixes it to be 0
  x1 ~ 0*1   

  # intercept for Pasteur and Grant-White schools
  visual ~  c(int_p, int_gw)*1    
   
  # comparisons
  diff := int_p - int_gw
&#39;

fit_1 &lt;- cfa(hs_model_1, 
           data = HolzingerSwineford1939, 
           group = &quot;school&quot;,
           meanstructure = T)
summary(fit_1, std=T)</code></pre>
<pre><code>
lavaan 0.6-3 ended normally after 101 iterations

  Optimization method                           NLMINB
  Number of free parameters                         60

  Number of observations per group         
  Pasteur                                          156
  Grant-White                                      145

  Estimator                                         ML
  Model Fit Test Statistic                     115.851
  Degrees of freedom                                48
  P-value (Chi-square)                           0.000

Chi-square for each group:

  Pasteur                                       64.309
  Grant-White                                   51.542

Parameter Estimates:

  Information                                 Expected
  Information saturated (h1) model          Structured
  Standard Errors                             Standard


Group 1 [Pasteur]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  visual =~                                                             
    x1                1.000                               1.047    0.887
    x2                0.394    0.122    3.220    0.001    0.412    0.336
    x3                0.570    0.140    4.076    0.000    0.597    0.515
  verbal =~                                                             
    x4                1.000                               0.946    0.823
    x5                1.183    0.102   11.613    0.000    1.119    0.856
    x6                0.875    0.077   11.421    0.000    0.827    0.838
  speed =~                                                              
    x7                1.000                               0.591    0.547
    x8                1.125    0.277    4.058    0.000    0.665    0.682
    x9                0.922    0.225    4.104    0.000    0.545    0.551

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  visual ~~                                                             
    verbal            0.479    0.106    4.531    0.000    0.484    0.484
    speed             0.185    0.077    2.397    0.017    0.299    0.299
  verbal ~~                                                             
    speed             0.182    0.069    2.628    0.009    0.325    0.325

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .x1                0.000                               0.000    0.000
    visual  (int_)    4.941    0.095   52.249    0.000    4.718    4.718
   .x2                4.039    0.611    6.606    0.000    4.039    3.293
   .x3               -0.329    0.696   -0.473    0.636   -0.329   -0.284
   .x4                2.823    0.092   30.689    0.000    2.823    2.457
   .x5                3.995    0.105   38.183    0.000    3.995    3.057
   .x6                1.922    0.079   24.321    0.000    1.922    1.947
   .x7                4.432    0.087   51.181    0.000    4.432    4.098
   .x8                5.563    0.078   71.214    0.000    5.563    5.702
   .x9                5.418    0.079   68.440    0.000    5.418    5.480
    verbal            0.000                               0.000    0.000
    speed             0.000                               0.000    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .x1                0.298    0.232    1.286    0.198    0.298    0.214
   .x2                1.334    0.158    8.464    0.000    1.334    0.887
   .x3                0.989    0.136    7.271    0.000    0.989    0.735
   .x4                0.425    0.069    6.138    0.000    0.425    0.322
   .x5                0.456    0.086    5.292    0.000    0.456    0.267
   .x6                0.290    0.050    5.780    0.000    0.290    0.297
   .x7                0.820    0.125    6.580    0.000    0.820    0.701
   .x8                0.510    0.116    4.406    0.000    0.510    0.535
   .x9                0.680    0.104    6.516    0.000    0.680    0.696
    visual            1.097    0.276    3.967    0.000    1.000    1.000
    verbal            0.894    0.150    5.963    0.000    1.000    1.000
    speed             0.350    0.126    2.778    0.005    1.000    1.000


Group 2 [Grant-White]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  visual =~                                                             
    x1                1.000                               0.777    0.677
    x2                0.736    0.155    4.760    0.000    0.572    0.517
    x3                0.925    0.166    5.584    0.000    0.719    0.694
  verbal =~                                                             
    x4                1.000                               0.971    0.866
    x5                0.990    0.087   11.418    0.000    0.961    0.829
    x6                0.963    0.085   11.377    0.000    0.935    0.826
  speed =~                                                              
    x7                1.000                               0.679    0.659
    x8                1.226    0.187    6.569    0.000    0.833    0.796
    x9                1.058    0.165    6.429    0.000    0.719    0.701

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  visual ~~                                                             
    verbal            0.408    0.098    4.153    0.000    0.541    0.541
    speed             0.276    0.076    3.639    0.000    0.523    0.523
  verbal ~~                                                             
    speed             0.222    0.073    3.022    0.003    0.336    0.336

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .x1                0.000                               0.000    0.000
    visual  (int_)    4.930    0.095   51.696    0.000    6.345    6.345
   .x2                2.571    0.768    3.347    0.001    2.571    2.321
   .x3               -2.563    0.821   -3.121    0.002   -2.563   -2.474
   .x4                3.317    0.093   35.625    0.000    3.317    2.959
   .x5                4.712    0.096   48.986    0.000    4.712    4.068
   .x6                2.469    0.094   26.277    0.000    2.469    2.182
   .x7                3.921    0.086   45.819    0.000    3.921    3.805
   .x8                5.488    0.087   63.174    0.000    5.488    5.246
   .x9                5.327    0.085   62.571    0.000    5.327    5.196
    verbal            0.000                               0.000    0.000
    speed             0.000                               0.000    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .x1                0.715    0.126    5.675    0.000    0.715    0.542
   .x2                0.899    0.123    7.339    0.000    0.899    0.733
   .x3                0.557    0.103    5.409    0.000    0.557    0.519
   .x4                0.315    0.065    4.870    0.000    0.315    0.251
   .x5                0.419    0.072    5.812    0.000    0.419    0.312
   .x6                0.406    0.069    5.880    0.000    0.406    0.317
   .x7                0.600    0.091    6.584    0.000    0.600    0.566
   .x8                0.401    0.094    4.248    0.000    0.401    0.367
   .x9                0.535    0.089    6.010    0.000    0.535    0.509
    visual            0.604    0.160    3.762    0.000    1.000    1.000
    verbal            0.942    0.152    6.177    0.000    1.000    1.000
    speed             0.461    0.118    3.910    0.000    1.000    1.000

Defined Parameters:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
    diff              0.011    0.134    0.085    0.933   -1.627   -1.627</code></pre>
<pre class="r"><code>
coef_1 = broom::tidy(fit_1) %&gt;% 
  filter(label != &#39;&#39;)

coef_1 %&gt;% kable_df()</code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:left;">
op
</th>
<th style="text-align:right;">
block
</th>
<th style="text-align:right;">
group
</th>
<th style="text-align:left;">
label
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
<th style="text-align:right;">
std.lv
</th>
<th style="text-align:right;">
std.all
</th>
<th style="text-align:right;">
std.nox
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
visual ~1
</td>
<td style="text-align:left;">
~1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
int_p
</td>
<td style="text-align:right;">
4.941
</td>
<td style="text-align:right;">
0.095
</td>
<td style="text-align:right;">
52.249
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
4.756
</td>
<td style="text-align:right;">
5.127
</td>
<td style="text-align:right;">
4.718
</td>
<td style="text-align:right;">
4.718
</td>
<td style="text-align:right;">
4.718
</td>
</tr>
<tr>
<td style="text-align:left;">
visual ~1
</td>
<td style="text-align:left;">
~1
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
int_gw
</td>
<td style="text-align:right;">
4.930
</td>
<td style="text-align:right;">
0.095
</td>
<td style="text-align:right;">
51.696
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
4.743
</td>
<td style="text-align:right;">
5.117
</td>
<td style="text-align:right;">
6.345
</td>
<td style="text-align:right;">
6.345
</td>
<td style="text-align:right;">
6.345
</td>
</tr>
<tr>
<td style="text-align:left;">
diff := int_p-int_gw
</td>
<td style="text-align:left;">
:=
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
diff
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.134
</td>
<td style="text-align:right;">
0.085
</td>
<td style="text-align:right;">
0.933
</td>
<td style="text-align:right;">
-0.252
</td>
<td style="text-align:right;">
0.275
</td>
<td style="text-align:right;">
-1.627
</td>
<td style="text-align:right;">
-1.627
</td>
<td style="text-align:right;">
-1.627
</td>
</tr>
</tbody>
</table>
</div>
<p>The above shows the schools not to be much different from one another on the visual-spatial ability latent variable. But compare this result to the intercepts for <code>x1</code> in our baseline model. This model would would be identical to comparing the intercepts on whichever observed variable you previously fixed to zero. Much like we must scale the latent variable to that of one of the observed variables by fixing the loading to be 1, we essentially come to the same type of issue by fixing its mean to be on that of the observed variable.</p>
<p>To make this more explicit, we’ll label the <code>x1</code> intercepts in our baseline model and look at their difference.</p>
<div class="layout-chunk" data-layout="l-body">

<pre class="r"><code>
hs_model_2 &lt;- &#39; 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
  
  x1 ~ c(a, b)*1   
   
  # comparisons
   diff := a - b
&#39;

fit_2 &lt;- cfa(hs_model_2, 
           data = HolzingerSwineford1939, 
           group = &quot;school&quot;,
           meanstructure = T)

summary(fit_2, std=T)</code></pre>
<pre><code>
lavaan 0.6-3 ended normally after 57 iterations

  Optimization method                           NLMINB
  Number of free parameters                         60

  Number of observations per group         
  Pasteur                                          156
  Grant-White                                      145

  Estimator                                         ML
  Model Fit Test Statistic                     115.851
  Degrees of freedom                                48
  P-value (Chi-square)                           0.000

Chi-square for each group:

  Pasteur                                       64.309
  Grant-White                                   51.542

Parameter Estimates:

  Information                                 Expected
  Information saturated (h1) model          Structured
  Standard Errors                             Standard


Group 1 [Pasteur]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  visual =~                                                             
    x1                1.000                               1.047    0.887
    x2                0.394    0.122    3.220    0.001    0.412    0.336
    x3                0.570    0.140    4.076    0.000    0.597    0.515
  verbal =~                                                             
    x4                1.000                               0.946    0.823
    x5                1.183    0.102   11.613    0.000    1.119    0.856
    x6                0.875    0.077   11.421    0.000    0.827    0.838
  speed =~                                                              
    x7                1.000                               0.591    0.547
    x8                1.125    0.277    4.057    0.000    0.665    0.682
    x9                0.922    0.225    4.104    0.000    0.545    0.551

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  visual ~~                                                             
    verbal            0.479    0.106    4.531    0.000    0.484    0.484
    speed             0.185    0.077    2.397    0.017    0.299    0.299
  verbal ~~                                                             
    speed             0.182    0.069    2.628    0.009    0.325    0.325

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .x1         (a)    4.941    0.095   52.249    0.000    4.941    4.183
   .x2                5.984    0.098   60.949    0.000    5.984    4.880
   .x3                2.487    0.093   26.778    0.000    2.487    2.144
   .x4                2.823    0.092   30.689    0.000    2.823    2.457
   .x5                3.995    0.105   38.183    0.000    3.995    3.057
   .x6                1.922    0.079   24.321    0.000    1.922    1.947
   .x7                4.432    0.087   51.181    0.000    4.432    4.098
   .x8                5.563    0.078   71.214    0.000    5.563    5.702
   .x9                5.418    0.079   68.440    0.000    5.418    5.480
    visual            0.000                               0.000    0.000
    verbal            0.000                               0.000    0.000
    speed             0.000                               0.000    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .x1                0.298    0.232    1.286    0.198    0.298    0.214
   .x2                1.334    0.158    8.464    0.000    1.334    0.887
   .x3                0.989    0.136    7.271    0.000    0.989    0.735
   .x4                0.425    0.069    6.138    0.000    0.425    0.322
   .x5                0.456    0.086    5.292    0.000    0.456    0.267
   .x6                0.290    0.050    5.780    0.000    0.290    0.297
   .x7                0.820    0.125    6.580    0.000    0.820    0.701
   .x8                0.510    0.116    4.406    0.000    0.510    0.535
   .x9                0.680    0.104    6.516    0.000    0.680    0.696
    visual            1.097    0.276    3.967    0.000    1.000    1.000
    verbal            0.894    0.150    5.963    0.000    1.000    1.000
    speed             0.350    0.126    2.778    0.005    1.000    1.000


Group 2 [Grant-White]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  visual =~                                                             
    x1                1.000                               0.777    0.677
    x2                0.736    0.155    4.760    0.000    0.572    0.517
    x3                0.925    0.166    5.583    0.000    0.719    0.694
  verbal =~                                                             
    x4                1.000                               0.971    0.866
    x5                0.990    0.087   11.418    0.000    0.961    0.829
    x6                0.963    0.085   11.377    0.000    0.935    0.826
  speed =~                                                              
    x7                1.000                               0.679    0.659
    x8                1.226    0.187    6.569    0.000    0.833    0.796
    x9                1.058    0.165    6.429    0.000    0.719    0.701

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  visual ~~                                                             
    verbal            0.408    0.098    4.153    0.000    0.541    0.541
    speed             0.276    0.076    3.639    0.000    0.523    0.523
  verbal ~~                                                             
    speed             0.222    0.073    3.022    0.003    0.336    0.336

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .x1         (b)    4.930    0.095   51.696    0.000    4.930    4.293
   .x2                6.200    0.092   67.416    0.000    6.200    5.599
   .x3                1.996    0.086   23.195    0.000    1.996    1.926
   .x4                3.317    0.093   35.625    0.000    3.317    2.959
   .x5                4.712    0.096   48.986    0.000    4.712    4.068
   .x6                2.469    0.094   26.277    0.000    2.469    2.182
   .x7                3.921    0.086   45.819    0.000    3.921    3.805
   .x8                5.488    0.087   63.174    0.000    5.488    5.246
   .x9                5.327    0.085   62.571    0.000    5.327    5.196
    visual            0.000                               0.000    0.000
    verbal            0.000                               0.000    0.000
    speed             0.000                               0.000    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .x1                0.715    0.126    5.676    0.000    0.715    0.542
   .x2                0.899    0.123    7.339    0.000    0.899    0.733
   .x3                0.557    0.103    5.409    0.000    0.557    0.519
   .x4                0.315    0.065    4.870    0.000    0.315    0.251
   .x5                0.419    0.072    5.812    0.000    0.419    0.312
   .x6                0.406    0.069    5.880    0.000    0.406    0.317
   .x7                0.600    0.091    6.584    0.000    0.600    0.566
   .x8                0.401    0.094    4.249    0.000    0.401    0.367
   .x9                0.535    0.089    6.010    0.000    0.535    0.509
    visual            0.604    0.160    3.762    0.000    1.000    1.000
    verbal            0.942    0.152    6.177    0.000    1.000    1.000
    speed             0.461    0.118    3.910    0.000    1.000    1.000

Defined Parameters:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
    diff              0.011    0.134    0.085    0.933    0.011   -0.110</code></pre>
<pre class="r"><code>
coef_2 = broom::tidy(fit_2) %&gt;% 
  filter(label != &#39;&#39;)

coef_2 %&gt;% kable_df()</code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:left;">
op
</th>
<th style="text-align:right;">
block
</th>
<th style="text-align:right;">
group
</th>
<th style="text-align:left;">
label
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
<th style="text-align:right;">
std.lv
</th>
<th style="text-align:right;">
std.all
</th>
<th style="text-align:right;">
std.nox
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
x1 ~1
</td>
<td style="text-align:left;">
~1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
a
</td>
<td style="text-align:right;">
4.941
</td>
<td style="text-align:right;">
0.095
</td>
<td style="text-align:right;">
52.249
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
4.756
</td>
<td style="text-align:right;">
5.127
</td>
<td style="text-align:right;">
4.941
</td>
<td style="text-align:right;">
4.183
</td>
<td style="text-align:right;">
4.183
</td>
</tr>
<tr>
<td style="text-align:left;">
x1 ~1
</td>
<td style="text-align:left;">
~1
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
b
</td>
<td style="text-align:right;">
4.930
</td>
<td style="text-align:right;">
0.095
</td>
<td style="text-align:right;">
51.696
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
4.743
</td>
<td style="text-align:right;">
5.117
</td>
<td style="text-align:right;">
4.930
</td>
<td style="text-align:right;">
4.293
</td>
<td style="text-align:right;">
4.293
</td>
</tr>
<tr>
<td style="text-align:left;">
diff := a-b
</td>
<td style="text-align:left;">
:=
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
diff
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.134
</td>
<td style="text-align:right;">
0.085
</td>
<td style="text-align:right;">
0.933
</td>
<td style="text-align:right;">
-0.252
</td>
<td style="text-align:right;">
0.275
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
-0.110
</td>
<td style="text-align:right;">
-0.110
</td>
</tr>
</tbody>
</table>
</div>
<p>Same difference.</p>
<h2 id="observed-variable-group-differences">Observed variable group differences</h2>
<p>The following approach is not the same model, but would also provide the same result. In this case, each observed variable is affected by the school grouping, and the path coefficient for <code>x1</code> is the same difference in means as before.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
hs_model_3 &lt;- &#39; 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
  
  x1 ~ diff*school 
  x2 + x3 + x4 + x5 + x6 +  x7 + x8 + x9 ~ school
&#39;

fit_3 &lt;- cfa(hs_model_3, 
             data = HolzingerSwineford1939,
             meanstructure = T)

summary(fit_3, std=T)</code></pre>
<pre><code>
lavaan 0.6-3 ended normally after 70 iterations

  Optimization method                           NLMINB
  Number of free parameters                         39

  Number of observations                           301

  Estimator                                         ML
  Model Fit Test Statistic                      88.086
  Degrees of freedom                                24
  P-value (Chi-square)                           0.000

Parameter Estimates:

  Information                                 Expected
  Information saturated (h1) model          Structured
  Standard Errors                             Standard

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  visual =~                                                             
    x1                1.000                               0.873    0.749
    x2                0.592    0.101    5.837    0.000    0.517    0.440
    x3                0.782    0.110    7.084    0.000    0.683    0.605
  verbal =~                                                             
    x4                1.000                               0.959    0.825
    x5                1.088    0.067   16.187    0.000    1.043    0.810
    x6                0.914    0.057   15.928    0.000    0.876    0.801
  speed =~                                                              
    x7                1.000                               0.619    0.569
    x8                1.186    0.163    7.299    0.000    0.734    0.727
    x9                1.063    0.146    7.276    0.000    0.658    0.653

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  x1 ~                                                                  
    school  (diff)    0.011    0.134    0.084    0.933    0.011    0.005
  x2 ~                                                                  
    school           -0.216    0.135   -1.600    0.110   -0.216   -0.092
  x3 ~                                                                  
    school            0.491    0.127    3.866    0.000    0.491    0.218
  x4 ~                                                                  
    school           -0.495    0.131   -3.776    0.000   -0.495   -0.213
  x5 ~                                                                  
    school           -0.717    0.143   -5.022    0.000   -0.717   -0.278
  x6 ~                                                                  
    school           -0.547    0.122   -4.476    0.000   -0.547   -0.250
  x7 ~                                                                  
    school            0.511    0.122    4.193    0.000    0.511    0.235
  x8 ~                                                                  
    school            0.075    0.117    0.642    0.521    0.075    0.037
  x9 ~                                                                  
    school            0.091    0.116    0.780    0.436    0.091    0.045

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  visual ~~                                                             
    verbal            0.414    0.072    5.777    0.000    0.495    0.495
    speed             0.245    0.054    4.531    0.000    0.452    0.452
  verbal ~~                                                             
    speed             0.199    0.049    4.042    0.000    0.336    0.336

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .x1                4.919    0.215   22.888    0.000    4.919    4.220
   .x2                6.416    0.216   29.728    0.000    6.416    5.458
   .x3                1.504    0.203    7.403    0.000    1.504    1.332
   .x4                3.812    0.209   18.205    0.000    3.812    3.280
   .x5                5.429    0.228   23.793    0.000    5.429    4.214
   .x6                3.016    0.195   15.443    0.000    3.016    2.757
   .x7                3.409    0.195   17.489    0.000    3.409    3.134
   .x8                5.413    0.186   29.062    0.000    5.413    5.355
   .x9                5.237    0.186   28.219    0.000    5.237    5.198
    visual            0.000                               0.000    0.000
    verbal            0.000                               0.000    0.000
    speed             0.000                               0.000    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .x1                0.596    0.106    5.641    0.000    0.596    0.439
   .x2                1.103    0.100   11.038    0.000    1.103    0.798
   .x3                0.748    0.086    8.752    0.000    0.748    0.587
   .x4                0.371    0.048    7.737    0.000    0.371    0.274
   .x5                0.444    0.057    7.788    0.000    0.444    0.267
   .x6                0.354    0.043    8.329    0.000    0.354    0.296
   .x7                0.735    0.076    9.616    0.000    0.735    0.621
   .x8                0.481    0.074    6.538    0.000    0.481    0.471
   .x9                0.580    0.070    8.320    0.000    0.580    0.572
    visual            0.762    0.137    5.575    0.000    1.000    1.000
    verbal            0.919    0.107    8.562    0.000    1.000    1.000
    speed             0.383    0.083    4.592    0.000    1.000    1.000</code></pre>
<pre class="r"><code>
coef_3 = broom::tidy(fit_3)</code></pre>
</div>
<p>A comparison of all three shows the same results, but that the third model has fewer parameters, as the loadings and latent variable variances are not changing across groups.</p>
<div class="layout-chunk" data-layout="l-body">
<pre><code>
# A tibble: 3 x 4
  estimate std.error conf.low conf.high
     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1   0.0114     0.134   -0.252     0.275
2   0.0114     0.134   -0.252     0.275
3   0.0114     0.134   -0.252     0.275</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
(#tab:compare_123_Npar)Model N parameters
</caption>
<thead>
<tr>
<th style="text-align:right;">
fit_1
</th>
<th style="text-align:right;">
fit_2
</th>
<th style="text-align:right;">
fit_3
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
60
</td>
<td style="text-align:right;">
60
</td>
<td style="text-align:right;">
39
</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
(#tab:compare_123_AIC)Model AIC
</caption>
<thead>
<tr>
<th style="text-align:right;">
fit_1
</th>
<th style="text-align:right;">
fit_2
</th>
<th style="text-align:right;">
fit_3
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
7484.395
</td>
<td style="text-align:right;">
7484.395
</td>
<td style="text-align:right;">
7474.493
</td>
</tr>
</tbody>
</table>
</div>
<h2 id="structural-model">Structural model</h2>
<p>In the models I see, people would more commonly address such a theoretical question without a multigroup approach, simply regressing the latent variable of interest on the group factor. We can do that here.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# standard cfa with school predicting visual
hs_model_4a &lt;- &#39; 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
  
  visual ~ diff*school
  
  visual ~~ speed + verbal  # lavaan will not estimate this by default
&#39;

fit_4a = sem(hs_model_4a, data=HolzingerSwineford1939, meanstructure=T)
summary(fit_4a)</code></pre>
<pre><code>
lavaan 0.6-3 ended normally after 49 iterations

  Optimization method                           NLMINB
  Number of free parameters                         31

  Number of observations                           301

  Estimator                                         ML
  Model Fit Test Statistic                     161.444
  Degrees of freedom                                32
  P-value (Chi-square)                           0.000

Parameter Estimates:

  Information                                 Expected
  Information saturated (h1) model          Structured
  Standard Errors                             Standard

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                1.000                           
    x2                0.570    0.100    5.723    0.000
    x3                0.797    0.111    7.212    0.000
  verbal =~                                           
    x4                1.000                           
    x5                1.113    0.065   17.021    0.000
    x6                0.928    0.055   16.741    0.000
  speed =~                                            
    x7                1.000                           
    x8                1.194    0.168    7.124    0.000
    x9                1.060    0.148    7.152    0.000

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~                                            
    school  (diff)    0.287    0.110    2.612    0.009

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
 .visual ~~                                           
    speed             0.241    0.054    4.446    0.000
    verbal            0.429    0.073    5.846    0.000
  verbal ~~                                           
    speed             0.172    0.049    3.483    0.000

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                4.500    0.180   24.997    0.000
   .x2                5.840    0.122   47.989    0.000
   .x3                1.903    0.151   12.631    0.000
   .x4                3.061    0.067   45.694    0.000
   .x5                4.341    0.074   58.452    0.000
   .x6                2.186    0.063   34.667    0.000
   .x7                4.186    0.063   66.766    0.000
   .x8                5.527    0.058   94.854    0.000
   .x9                5.374    0.058   92.546    0.000
   .visual            0.000                           
    verbal            0.000                           
    speed             0.000                           

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.604    0.105    5.739    0.000
   .x2                1.137    0.102   11.172    0.000
   .x3                0.795    0.090    8.879    0.000
   .x4                0.372    0.048    7.821    0.000
   .x5                0.448    0.058    7.698    0.000
   .x6                0.354    0.043    8.254    0.000
   .x7                0.796    0.081    9.775    0.000
   .x8                0.470    0.076    6.209    0.000
   .x9                0.580    0.071    8.195    0.000
   .visual            0.754    0.135    5.597    0.000
    verbal            0.978    0.112    8.735    0.000
    speed             0.387    0.087    4.462    0.000</code></pre>
</div>
<p>At first blush, it would seem we are not getting the same result. Our difference is notably larger and significant.</p>
<div class="layout-chunk" data-layout="l-body">
<pre><code>
# A tibble: 1 x 5
  fit_1 fit_2 fit_3 fit_4a fit_baseline
  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;        &lt;dbl&gt;
1 7484. 7484. 7474.  7532.        7484.</code></pre>
<pre><code>
# A tibble: 1 x 5
  fit_1 fit_2 fit_3 fit_4a fit_baseline
  &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;        &lt;int&gt;
1    60    60    39     31           60</code></pre>
</div>
<p>But as before, we can recover the multigroup results by regressing the other observed variables on school as well.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
hs_model_4b &lt;- &#39; 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
  
  visual ~ diff*school
  
  x2 + x3 + x4 + x5 + x6 +  x7 + x8 + x9 ~ school
&#39;

fit_4b = sem(hs_model_4b, data=HolzingerSwineford1939, meanstructure=T)</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<pre><code>
# A tibble: 1 x 6
  fit_1 fit_2 fit_3 fit_4a fit_4b fit_baseline
  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;        &lt;dbl&gt;
1 7484. 7484. 7474.  7532.  7527.        7484.</code></pre>
<pre><code>
# A tibble: 1 x 6
  fit_1 fit_2 fit_3 fit_4a fit_4b fit_baseline
  &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;  &lt;int&gt;        &lt;int&gt;
1    60    60    39     31     37           60</code></pre>
<pre><code>
# A tibble: 4 x 5
  model estimate std.error conf.low conf.high
  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 1       0.0114     0.134   -0.252     0.275
2 2       0.0114     0.134   -0.252     0.275
3 3       0.0114     0.134   -0.252     0.275
4 4b      0.0113     0.134   -0.252     0.275</code></pre>
</div>
<p>Going back to the first structural model <code>hs_model_4a</code>, it might be interesting to some to see that it the group difference <em>still</em> regards a difference on the <code>x1</code> observed variable. We can see this more clearly if we set the x1 loading to be estimated rather than fixed at one, then use the product of coefficients approach (a la mediation) to estimate the group difference.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
hs_model_4c &lt;- &#39; 
  visual =~ x2 + a*x1 + x3    # estimate x1 loading vs. scaling by it
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 

  visual ~ b*school
  
  visual ~~ verbal + speed
  
  diff := a*b    # &quot;indirect&quot; effect of school on x1
&#39;

# same as fit_4a
fit_4c = cfa(hs_model_4c, data = HolzingerSwineford1939, meanstructure=T)
coef_4c = broom::tidy(fit_4c) %&gt;% filter(label==&#39;diff&#39;) 
coef_4a = broom::tidy(fit_4a) %&gt;% filter(label==&#39;diff&#39;) 

bind_rows(coef_4a, coef_4c) %&gt;% 
  mutate(model = c(&#39;4a&#39;, &#39;4c&#39;)) %&gt;% 
  select(model, label:conf.high)</code></pre>
<pre><code>
# A tibble: 2 x 8
  model label estimate std.error statistic p.value conf.low conf.high
  &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 4a    diff     0.287     0.110      2.61 0.00901   0.0717     0.503
2 4c    diff     0.287     0.110      2.61 0.00901   0.0717     0.503</code></pre>
</div>
<p>And what is this value of 0.2872632?</p>
<p>The following is equivalent to the result one would get from <code>group.equal = c('loadings', 'intercepts')</code>. The first group would have latent variable means at zero, while the second group would be allowed to vary. This is more or less what is desired.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
hs_model_test &lt;- &#39; 
  # make loadings equal across groups
  
  visual =~ c(1, 1)*x1 + c(v_x2, v_x2)*x2 + c(v_x3, v_x3)*x3
  verbal =~ c(1, 1)*x4 + c(v_x5, v_x5)*x5 + c(v_x6, v_x6)*x6
  speed  =~ c(1, 1)*x7 + c(v_x8, v_x8)*x8 + c(v_x9, v_x9)*x9 
  
  # make intercepts equal across groups
  
  x1 ~ c(0, 0) * 1
  x2 ~ c(int_x2, int_x2) * 1
  x3 ~ c(int_x3, int_x3) * 1
  x4 ~ c(0, 0) * 1
  x5 ~ c(int_x5, int_x5) * 1
  x6 ~ c(int_x6, int_x6) * 1
  x7 ~ c(0, 0) * 1
  x8 ~ c(int_x8, int_x8) * 1
  x9 ~ c(int_x9, int_x9) * 1
  
  # make covariances equal across groups
  
  # visual ~~ c(cov_vv, cov_vv) * verbal + c(cov_visp, cov_visp) * speed
  # verbal ~~ c(cov_vesp, cov_vesp) * speed
  
  # make variances equal
  
  # visual ~~ c(vvar, vvar) * visual
  # verbal ~~ c(tvar, tvar) * verbal
  # speed  ~~ c(svar, svar) * speed
  
  # x1 ~~ c(x1var, x1var) * x1
  # x2 ~~ c(x2var, x2var) * x2
  # x3 ~~ c(x3var, x3var) * x3
  # x4 ~~ c(x4var, x4var) * x4
  # x5 ~~ c(x5var, x5var) * x5
  # x6 ~~ c(x6var, x6var) * x6
  # x7 ~~ c(x7var, x7var) * x7
  # x8 ~~ c(x8var, x8var) * x8
  # x9 ~~ c(x9var, x9var) * x9
  
  
  visual ~ c(vis_int_p, vis_int_gw)*1
  verbal ~ c(verb_int_p, verb_int_gw)*1
  speed  ~ c(speed_int_p, speed_int_gw)*1
  
  
   
  # comparisons
   diff := vis_int_p - vis_int_gw
&#39;

fit_test  = sem(hs_model_test, 
                data=HolzingerSwineford1939, 
                group = &#39;school&#39;,
                meanstructure=T)

summary(fit_test)</code></pre>
<pre><code>
lavaan 0.6-3 ended normally after 86 iterations

  Optimization method                           NLMINB
  Number of free parameters                         60
  Number of equality constraints                    12

  Number of observations per group         
  Pasteur                                          156
  Grant-White                                      145

  Estimator                                         ML
  Model Fit Test Statistic                     164.103
  Degrees of freedom                                60
  P-value (Chi-square)                           0.000

Chi-square for each group:

  Pasteur                                       90.210
  Grant-White                                   73.892

Parameter Estimates:

  Information                                 Expected
  Information saturated (h1) model          Structured
  Standard Errors                             Standard


Group 1 [Pasteur]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                1.000                           
    x2      (v_x2)    0.576    0.101    5.712    0.000
    x3      (v_x3)    0.798    0.112    7.146    0.000
  verbal =~                                           
    x4                1.000                           
    x5      (v_x5)    1.120    0.066   16.965    0.000
    x6      (v_x6)    0.932    0.056   16.608    0.000
  speed =~                                            
    x7                1.000                           
    x8      (v_x8)    1.130    0.145    7.786    0.000
    x9      (v_x9)    1.009    0.132    7.667    0.000

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~~                                           
    verbal            0.410    0.095    4.293    0.000
    speed             0.178    0.066    2.687    0.007
  verbal ~~                                           
    speed             0.180    0.062    2.900    0.004

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.000                           
   .x2      (in_2)    3.272    0.500    6.538    0.000
   .x3      (in_3)   -1.722    0.554   -3.111    0.002
   .x4                0.000                           
   .x5      (in_5)    0.924    0.212    4.364    0.000
   .x6      (in_6)   -0.663    0.177   -3.748    0.000
   .x7                0.000                           
   .x8      (in_8)    0.839    0.605    1.387    0.166
   .x9      (in_9)    1.185    0.549    2.156    0.031
    visual  (vs__)    5.001    0.090   55.760    0.000
    verbal  (vr__)    2.778    0.087   31.953    0.000
    speed   (sp__)    4.242    0.073   57.975    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.555    0.139    3.983    0.000
   .x2                1.296    0.158    8.186    0.000
   .x3                0.944    0.136    6.929    0.000
   .x4                0.445    0.069    6.430    0.000
   .x5                0.502    0.082    6.136    0.000
   .x6                0.263    0.050    5.264    0.000
   .x7                0.888    0.120    7.416    0.000
   .x8                0.541    0.095    5.706    0.000
   .x9                0.654    0.096    6.805    0.000
    visual            0.796    0.172    4.641    0.000
    verbal            0.879    0.131    6.694    0.000
    speed             0.322    0.082    3.914    0.000


Group 2 [Grant-White]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                1.000                           
    x2      (v_x2)    0.576    0.101    5.712    0.000
    x3      (v_x3)    0.798    0.112    7.146    0.000
  verbal =~                                           
    x4                1.000                           
    x5      (v_x5)    1.120    0.066   16.965    0.000
    x6      (v_x6)    0.932    0.056   16.608    0.000
  speed =~                                            
    x7                1.000                           
    x8      (v_x8)    1.130    0.145    7.786    0.000
    x9      (v_x9)    1.009    0.132    7.667    0.000

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~~                                           
    verbal            0.427    0.097    4.417    0.000
    speed             0.329    0.082    4.006    0.000
  verbal ~~                                           
    speed             0.236    0.073    3.224    0.001

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.000                           
   .x2      (in_2)    3.272    0.500    6.538    0.000
   .x3      (in_3)   -1.722    0.554   -3.111    0.002
   .x4                0.000                           
   .x5      (in_5)    0.924    0.212    4.364    0.000
   .x6      (in_6)   -0.663    0.177   -3.748    0.000
   .x7                0.000                           
   .x8      (in_8)    0.839    0.605    1.387    0.166
   .x9      (in_9)    1.185    0.549    2.156    0.031
    visual  (vs__)    4.854    0.092   52.963    0.000
    verbal  (vr__)    3.354    0.088   38.164    0.000
    speed   (sp__)    4.065    0.080   50.753    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.654    0.128    5.094    0.000
   .x2                0.964    0.123    7.812    0.000
   .x3                0.641    0.101    6.316    0.000
   .x4                0.343    0.062    5.534    0.000
   .x5                0.376    0.073    5.133    0.000
   .x6                0.437    0.067    6.559    0.000
   .x7                0.625    0.095    6.574    0.000
   .x8                0.434    0.088    4.914    0.000
   .x9                0.522    0.086    6.102    0.000
    visual            0.708    0.160    4.417    0.000
    verbal            0.870    0.131    6.659    0.000
    speed             0.505    0.115    4.379    0.000

Defined Parameters:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
    diff              0.148    0.122    1.211    0.226</code></pre>
<pre class="r"><code>
lavaanPlot::lavaanPlot(model = fit_test, coefs=T, covs=T)</code></pre>
<div id="htmlwidget-d77947349a0ae153dc5c" style="width:624px;height:384px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-d77947349a0ae153dc5c">{"x":{"diagram":" digraph plot { \n graph [ overlap = true, fontsize = 10 ] \n node [ shape = box ] \n node [shape = box] \n x1; x2; x3; x4; x5; x6; x7; x8; x9 \n node [shape = oval] \n visual; verbal; speed \n \n edge [ color = black ] \n  visual->x1 [label = \"1\"] visual->x2 [label = \"0.58\"] visual->x3 [label = \"0.8\"] verbal->x4 [label = \"1\"] verbal->x5 [label = \"1.12\"] verbal->x6 [label = \"0.93\"] speed->x7 [label = \"1\"] speed->x8 [label = \"1.13\"] speed->x9 [label = \"1.01\"] visual->x1 [label = \"1\"] visual->x2 [label = \"0.58\"] visual->x3 [label = \"0.8\"] verbal->x4 [label = \"1\"] verbal->x5 [label = \"1.12\"] verbal->x6 [label = \"0.93\"] speed->x7 [label = \"1\"] speed->x8 [label = \"1.13\"] speed->x9 [label = \"1.01\"] verbal -> visual [label = \"0.41\", dir = \"both\"] speed -> visual [label = \"0.18\", dir = \"both\"] speed -> verbal [label = \"0.18\", dir = \"both\"] verbal -> visual [label = \"0.43\", dir = \"both\"] speed -> visual [label = \"0.33\", dir = \"both\"] speed -> verbal [label = \"0.24\", dir = \"both\"]\n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
<p>The more simple and obvious way to do it.</p>
<div class="layout-chunk" data-layout="l-body">
<pre><code>
lavaan 0.6-3 ended normally after 59 iterations

  Optimization method                           NLMINB
  Number of free parameters                         33

  Number of observations                           301

  Estimator                                         ML
  Model Fit Test Statistic                     127.524
  Degrees of freedom                                30
  P-value (Chi-square)                           0.000

Parameter Estimates:

  Information                                 Expected
  Information saturated (h1) model          Structured
  Standard Errors                             Standard

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                1.000                           
    x2                0.570    0.102    5.577    0.000
    x3                0.797    0.115    6.960    0.000
  verbal =~                                           
    x4                1.000                           
    x5                1.124    0.066   17.117    0.000
    x6                0.934    0.056   16.771    0.000
  speed =~                                            
    x7                1.000                           
    x8                1.112    0.151    7.376    0.000
    x9                1.024    0.140    7.327    0.000

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~                                            
    school  (diff)    0.147    0.122    1.207    0.228
  verbal ~                                            
    school           -0.575    0.118   -4.885    0.000
  speed ~                                             
    school            0.178    0.090    1.980    0.048

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
 .visual ~~                                           
   .verbal            0.406    0.070    5.781    0.000
   .speed             0.256    0.056    4.584    0.000
 .verbal ~~                                           
   .speed             0.206    0.050    4.100    0.000

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                4.712    0.197   23.926    0.000
   .x2                5.961    0.127   47.056    0.000
   .x3                2.072    0.162   12.792    0.000
   .x4                3.933    0.190   20.698    0.000
   .x5                5.321    0.213   24.996    0.000
   .x6                3.001    0.178   16.872    0.000
   .x7                3.915    0.150   26.038    0.000
   .x8                5.226    0.162   32.343    0.000
   .x9                5.097    0.151   33.773    0.000
   .visual            0.000                           
   .verbal            0.000                           
   .speed             0.000                           

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.604    0.107    5.654    0.000
   .x2                1.137    0.102   11.154    0.000
   .x3                0.795    0.090    8.799    0.000
   .x4                0.383    0.047    8.093    0.000
   .x5                0.438    0.057    7.654    0.000
   .x6                0.352    0.042    8.310    0.000
   .x7                0.765    0.081    9.485    0.000
   .x8                0.505    0.072    6.999    0.000
   .x9                0.577    0.070    8.285    0.000
   .visual            0.749    0.137    5.484    0.000
   .verbal            0.885    0.103    8.624    0.000
   .speed             0.410    0.088    4.661    0.000</code></pre>
<pre><code>
# A tibble: 5 x 5
  model estimate std.error conf.low conf.high
  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 1       0.0114     0.134  -0.252      0.275
2 2       0.0114     0.134  -0.252      0.275
3 3       0.0114     0.134  -0.252      0.275
4 4b      0.0113     0.134  -0.252      0.275
5 4d      0.147      0.122  -0.0919     0.386</code></pre>
</div>
<h2 id="sumfactor-score">Sum/Factor score</h2>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
hs_model_5 &lt;- &#39; 
  visual =~ x1 + l1*x2 + l1*x3
  verbal =~ x4 + l2*x5 + l2*x6
  speed  =~ x7 + l3*x8 + l3*x9 
  
  # x1 ~~ a*x1
  # x2 ~~ a*x2
  # x3 ~~ a*x3
  # x4 ~~ a*x4
  # x5 ~~ a*x5
  # x6 ~~ a*x6
  # x7 ~~ a*x7
  # x8 ~~ a*x8
  # x9 ~~ a*x9
&#39;


fit_5 = cfa(hs_model_5, data = HolzingerSwineford1939, meanstructure=T)


HolzingerSwineford1939 = HolzingerSwineford1939 %&gt;% 
  mutate(visual = lavPredict(fit_5)[,&#39;visual&#39;],
         verbal = lavPredict(fit_5)[,&#39;verbal&#39;],
         speed  = lavPredict(fit_5)[,&#39;speed&#39;])
ttest1 = lm(visual ~ school, data = HolzingerSwineford1939)
coef(ttest1)  # same as x1 diffs</code></pre>
<pre><code>
  (Intercept) schoolPasteur 
 -0.005790171   0.011172061 </code></pre>
<pre class="r"><code>
hs_model_fsr &lt;- &#39; 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
  
  visual ~ school
&#39;

# fsr function now hidden and evidently broken? even naive method doesn&#39;t work;
# tried all methods for scores and approach
# ttest1b = lavaan:::fsr(hs_model_fsr,
#                        data = HolzingerSwineford1939)
# coef(ttest1b)


ttest2 = lm(rowSums(HolzingerSwineford1939 %&gt;% select(x1:x3)) ~ HolzingerSwineford1939$school)
coef(ttest2)  # same as structural diffs</code></pre>
<pre><code>
                         (Intercept) HolzingerSwineford1939$schoolPasteur 
                          13.1255747                            0.2868184 </code></pre>
</div>
<p>What should be apparent at this point is that the multigroup approach is an interaction of everything with the grouping variable. Honestly I think this is rarely desirable theoretically, or at least we rarely do this in other modeling contexts.</p>
<h2 id="measurement-invariance">Measurement invariance</h2>
<p>In some cases we are instead looking for similarities across groups among the latent constructs, rather than differences. This is especially the case in scale development, where one would like a measure to be consistent across groups of individuals (e.g. sex, age, race, etc.).</p>
<p>Aside from general problems of ‘accepting the null hypothesis’, the basic idea is to test a restricted model vs. the less restrictive one that assumes the differences across groups exist, and if they are not appreciably different, then one can claim equivalence across groups. As a starting point, we assume <span class="emph">configural</span> equivalence, or in other words, that the factor structure is the same. There is no point in testing measurement equivalence if there is not a similar factor structure. The first restricted model is that the loadings are equivalent. The next is that observed variable intercepts are equivalent, followed by latent variable means, and finally residual variances/covariances.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
hs_model_4 &lt;- &#39; 
  visual  =~ x1 + x2 + x3
  verbal  =~ x4 + x5 + x6
  speed   =~ x7 + x8 + x9 
&#39;

semTools::measurementInvariance(
  model = hs_model_4, 
  data = HolzingerSwineford1939, 
  group = &quot;school&quot;
)</code></pre>
<pre><code>
Measurement invariance models:

Model 1 : fit.configural
Model 2 : fit.loadings
Model 3 : fit.intercepts
Model 4 : fit.means

Chi Square Difference Test

               Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)    
fit.configural 48 7484.4 7706.8 115.85                                  
fit.loadings   54 7480.6 7680.8 124.04      8.192       6     0.2244    
fit.intercepts 60 7508.6 7686.6 164.10     40.059       6  4.435e-07 ***
fit.means      63 7543.1 7710.0 204.61     40.502       3  8.338e-09 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1


Fit measures:

                 cfi rmsea cfi.delta rmsea.delta
fit.configural 0.923 0.097        NA          NA
fit.loadings   0.921 0.093     0.002       0.004
fit.intercepts 0.882 0.107     0.038       0.015
fit.means      0.840 0.122     0.042       0.015</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# wow, from one line to this. this is an awful choice for an alternative
test.seq &lt;- c(&quot;loadings&quot;,&quot;intercepts&quot;,&quot;means&quot;,&quot;residuals&quot;)
meq.list &lt;- list()
for (i in 0:length(test.seq)) {
  if (i == 0L) {
    meq.label &lt;- &quot;configural&quot;
    group.equal &lt;- &quot;&quot;
    # long.equal &lt;- &quot;&quot;
  } else {
    meq.label &lt;- test.seq[i]
    group.equal &lt;- test.seq[1:i]
    # long.equal &lt;- test.seq[1:i]
  }
  meq.list[[meq.label]] &lt;- semTools::measEq.syntax(
    configural.model = hs_model_baseline,
    data = HolzingerSwineford1939,
    ID.fac = &quot;auto.fix.first&quot;,
    group = &quot;school&quot;,
    group.equal = group.equal,
    # longFacNames = longFacNames,
    # long.equal = long.equal,
    return.fit = TRUE
  )
}

# and of course, this is still a borked function
semTools::compareFit(meq.list)</code></pre>
<pre><code>
################### Nested Model Comparison #########################
Chi Square Difference Test

           Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)    
configural 48 7484.4 7706.8 115.85                                  
loadings   54 7480.6 7680.8 124.04      8.192       6    0.22436    
intercepts 60 7508.6 7686.6 164.10     40.059       6  4.435e-07 ***
means      63 7543.1 7710.0 204.61     40.502       3  8.338e-09 ***
residuals  72 7541.9 7675.3 221.34     16.730       9    0.05312 .  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

####################### Model Fit Indices ###########################
              chisq df pvalue   cfi   tli       aic       bic rmsea  srmr
configural 115.851† 48   .000 .923† .885  7484.395  7706.822  .097  .068†
loadings   124.044  54   .000 .921  .895† 7480.587† 7680.771  .093† .072 
intercepts 164.103  60   .000 .882  .859  7508.647  7686.588  .107  .082 
means      204.605  63   .000 .840  .817  7543.149  7709.969  .122  .109 
residuals  221.335  72   .000 .831  .831  7541.879  7675.335† .117  .114 

################## Differences in Fit Indices #######################
                      df    cfi    tli    aic     bic  rmsea  srmr
loadings - configural  6 -0.002  0.009 -3.808 -26.050 -0.004 0.004
intercepts - loadings  6 -0.038 -0.036 28.059   5.817  0.015 0.011
means - intercepts     3 -0.042 -0.042 34.502  23.381  0.015 0.026
residuals - residuals  9 -0.009  0.014 -1.270 -34.634 -0.005 0.005</code></pre>
<pre class="r"><code>
# means_only
test.seq &lt;- c(&quot;means&quot;)
meq.list &lt;- list()
for (i in 0:length(test.seq)) {
  if (i == 0L) {
    meq.label &lt;- &quot;configural&quot;
    group.equal &lt;- &quot;&quot;
    # long.equal &lt;- &quot;&quot;
  } else {
    meq.label &lt;- test.seq[i]
    group.equal &lt;- test.seq[1:i]
    # long.equal &lt;- test.seq[1:i]
  }
  meq.list[[meq.label]] &lt;- semTools::measEq.syntax(
    configural.model = hs_model_baseline,
    data = HolzingerSwineford1939,
    ID.fac = &quot;auto.fix.first&quot;,
    group = &quot;school&quot;,
    group.equal = group.equal,
    # longFacNames = longFacNames,
    # long.equal = long.equal,
    return.fit = TRUE
  )
}

semTools::compareFit(meq.list)</code></pre>
<pre><code>
################### Nested Model Comparison #########################
Chi Square Difference Test

           Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)    
configural 48 7484.4 7706.8 115.85                                  
means      51 7515.7 7727.0 153.19     37.343       3  3.893e-08 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

####################### Model Fit Indices ###########################
              chisq df pvalue   cfi   tli       aic       bic rmsea  srmr
configural 115.851† 48   .000 .923† .885† 7484.395† 7706.822† .097† .068†
means      153.195  51   .000 .885  .837  7515.738  7727.044  .115  .089 

################## Differences in Fit Indices #######################
              df    cfi    tli    aic    bic rmsea  srmr
means - means  3 -0.039 -0.048 31.343 20.222 0.018 0.021</code></pre>
</div>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
