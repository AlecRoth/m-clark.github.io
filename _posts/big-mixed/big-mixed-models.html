<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
  <title>Mixed Models for Big Data</title>
  
  <meta property="description" itemprop="description" content="Explorations of a fast penalized regression approach with bam in mgcv"/>
  
  
  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2019-09-29"/>
  <meta property="article:created" itemprop="dateCreated" content="2019-09-29"/>
  <meta name="article:author" content="Michael Clark"/>
  
  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Mixed Models for Big Data"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="Explorations of a fast penalized regression approach with bam in mgcv"/>
  <meta property="og:locale" content="en_US"/>
  
  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Mixed Models for Big Data"/>
  <meta property="twitter:description" content="Explorations of a fast penalized regression approach with bam in mgcv"/>
  
  <!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Generalized additive models : An introduction with r, second edition;citation_publication_date=2017;citation_publisher=Chapman; Hall/CRC;citation_doi=10.1201/9781315370279;citation_author=Simon N. Wood"/>
  <!--radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","preview","output","draft","bibliography","nocite","tags"]}},"value":[{"type":"character","attributes":{},"value":["Mixed Models for Big Data"]},{"type":"character","attributes":{},"value":["Explorations of a fast penalized regression approach with bam in mgcv\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Michael Clark"]},{"type":"character","attributes":{},"value":["https://m-clark.github.io"]}]}]},{"type":"character","attributes":{},"value":["September 29, 2019"]},{"type":"character","attributes":{},"value":["../../img/gam_sim.png"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc","css"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["../../styles.css"]}]}]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["gam_references.bib"]},{"type":"character","attributes":{},"value":["@li_faster_2019, @wood_mgcv:_2012, @wood_generalized_2015, @wood_generalized_2015-1, @wood_generalized_2017-1\n"]},{"type":"character","attributes":{},"value":["bayesian","empirical bayes","shrinkage","random effects","mixed models"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["big-mixed-models_files/bowser-1.9.3/bowser.min.js","big-mixed-models_files/distill-2.2.21/template.v2.js","big-mixed-models_files/jquery-1.11.3/jquery.min.js","big-mixed-models_files/kePrint-0.0.1/kePrint.js","big-mixed-models_files/webcomponents-2.0.0/webcomponents.js","gam_references.bib"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->
  
  <style type="text/css">
  
  body {
    background-color: white;
  }
  
  .pandoc-table {
    width: 100%;
  }
  
  .pandoc-table>caption {
    margin-bottom: 10px;
  }
  
  .pandoc-table th:not([align]) {
    text-align: left;
  }
  
  .pagedtable-footer {
    font-size: 15px;
  }
  
  .html-widget {
    margin-bottom: 2.0em;
  }
  
  .l-screen-inset {
    padding-right: 16px;
  }
  
  .l-screen .caption {
    margin-left: 10px;
  }
  
  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .shaded-content {
    background: white;
  }
  
  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }
  
  .hidden {
    display: none !important;
  }
  
  d-article {
    padding-bottom: 30px;
  }
  
  d-appendix {
    padding-top: 30px;
  }
  
  d-article>p>img {
    width: 100%;
  }
  
  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }
  
  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  /* CSS for table of contents */
  
  .d-toc {
    color: rgba(0,0,0,0.8);
    font-size: 0.8em;
    line-height: 1em;
  }
  
  .d-toc-header {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    text-transform: uppercase;
    margin-top: 0;
    margin-bottom: 1.3em;
  }
  
  .d-toc a {
    border-bottom: none;
  }
  
  .d-toc ul {
    padding-left: 0;
  }
  
  .d-toc li>ul {
    padding-top: 0.8em;
    padding-left: 16px;
    margin-bottom: 0.6em;
  }
  
  .d-toc ul,
  .d-toc li {
    list-style-type: none;
  }
  
  .d-toc li {
    margin-bottom: 0.9em;
  }
  
  .d-toc-separator {
    margin-top: 20px;
    margin-bottom: 2em;
  }
  
  .d-article-with-toc {
    border-top: none;
    padding-top: 0;
  }
  
  
  
  /* Tweak code blocks (note that this CSS is repeated above in an injection
     into the d-code shadow dom) */
  
  d-code {
    overflow-x: auto !important;
  }
  
  pre.d-code code.d-code {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }
  
  pre.text-output {
  
    font-size: 12px;
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  @media(min-width: 768px) {
  
  d-code {
    overflow-x: visible !important;
  }
  
  pre.d-code code.d-code  {
      padding-left: 18px;
      font-size: 14px;
  }
  pre.text-output {
    font-size: 14px;
  }
  }
  
  /* Figure */
  
  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }
  
  .figure img {
    width: 100%;
  }
  
  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }
  
  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }
  
  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }
  
  
  
  /* Tweak 1000px media break to show more text */
  
  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }
  
    .grid {
      grid-column-gap: 16px;
    }
  
    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }
  
  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }
  
    .grid {
      grid-column-gap: 32px;
    }
  }
  
  
  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */
  
  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  
  
  /* Social footer */
  
  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }
  
  .disqus-comments {
    margin-right: 30px;
  }
  
  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }
  
  #disqus_thread {
    margin-top: 30px;
  }
  
  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }
  
  .article-sharing a:hover {
    border-bottom: none;
  }
  
  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .subscribe p {
    margin-bottom: 0.5em;
  }
  
  
  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }
  
  
  /* Improve display for browsers without grid (IE/Edge <= 15) */
  
  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }
  
  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }
  
  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }
  
  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }
  
  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }
  
  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }
  
  
  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }
  
  .downlevel .footnotes ol {
    padding-left: 13px;
  }
  
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }
  
  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }
  
  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }
  
  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  </style>
  
  <script type="application/javascript">
  
  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }
  
  // show body when load is complete
  function on_load_complete() {
  
    // set body to visible
    document.body.style.visibility = 'visible';
  
    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }
  
    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }
  
  function init_distill() {
  
    init_common();
  
    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);
  
    // create d-title
    $('.d-title').changeElementType('d-title');
  
    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);
  
    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();
  
    // move posts container into article
    $('.posts-container').appendTo($('d-article'));
  
    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');
  
    // create d-bibliography
    var bibliography = $('<d-bibliography></d-bibliography>');
    $('#distill-bibliography').wrap(bibliography);
  
    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;
  
    // replace citations with <d-cite>
    $('.citation').each(function(i, val) {
      appendix = true;
      var cites = $(this).attr('data-cites').split(" ");
      var dt_cite = $('<d-cite></d-cite>');
      dt_cite.attr('key', cites.join());
      $(this).replaceWith(dt_cite);
    });
    // remove refs
    $('#refs').remove();
  
    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();
  
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-toc a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });
  
    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');
  
    // replace code blocks with d-code
    $('pre>code').each(function(i, val) {
      var code = $(this);
      var pre = code.parent();
      var clz = "";
      var language = pre.attr('class');
      if (language) {
        // map unknown languages to "clike" (without this they just dissapear)
        if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                                 "javascript", "js", "julia", "lua", "markdown",
                                 "markup", "mathml", "python", "svg", "xml"]) == -1)
          language = "clike";
        language = ' language="' + language + '"';
        var dt_code = $('<d-code block' + language + clz + '></d-code>');
        dt_code.text(code.text());
        pre.replaceWith(dt_code);
      } else {
        code.addClass('text-output').unwrap().changeElementType('pre');
      }
    });
  
    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {
  
      // capture layout
      var layout = $(this).attr('data-layout');
  
      // apply layout to markdown level block elements
      var elements = $(this).children().not('d-code, pre.text-output, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });
  
  
      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });
  
    // load distill framework
    load_distill_framework();
  
    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {
  
      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;
  
      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');
  
      // table of contents
      if (have_authors) // adjust border if we are in authors
        $('.d-toc').parent().addClass('d-article-with-toc');
  
      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');
  
      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }
  
      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');
  
      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");
  
      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }
  
       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }
  
      // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
      $('d-code').each(function(i, val) {
        var style = document.createElement('style');
        style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                          '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
        if (this.shadowRoot)
          this.shadowRoot.appendChild(style);
      });
  
      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();
  
      // clear polling timer
      clearInterval(tid);
  
      // show body now that everything is ready
      on_load_complete();
    }
  
    var tid = setInterval(distill_post_process, 50);
    distill_post_process();
  
  }
  
  function init_downlevel() {
  
    init_common();
  
     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));
  
    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
  
    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();
  
    // remove toc
    $('.d-toc-header').remove();
    $('.d-toc').remove();
    $('.d-toc-separator').remove();
  
    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });
  
  
    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);
  
    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);
  
    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();
  
    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();
  
    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));
  
    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });
  
    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));
  
    $('body').addClass('downlevel');
  
    on_load_complete();
  }
  
  
  function init_common() {
  
    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};
  
        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });
  
        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);
  
    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});
  
    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });
  
      }
    });
  
    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });
  
    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }
  
    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');
  
    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");
  
    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();
  
    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }
  
  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });
  
  </script>
  
  <!--/radix_placeholder_distill-->
  <script src="big-mixed-models_files/kePrint-0.0.1/kePrint.js"></script>
  <script src="big-mixed-models_files/jquery-1.11.3/jquery.min.js"></script>
  <script src="big-mixed-models_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="big-mixed-models_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="big-mixed-models_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->

  <link rel="stylesheet" href="../../styles.css" type="text/css"/>

</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Mixed Models for Big Data","description":"Explorations of a fast penalized regression approach with bam in mgcv","authors":[{"author":"Michael Clark","authorURL":"https://m-clark.github.io","affiliation":"&nbsp;","affiliationURL":"#"}],"publishedDate":"2019-09-29T00:00:00.000-04:00","citationText":"Clark, 2019"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Mixed Models for Big Data</h1>
<p>Explorations of a fast penalized regression approach with bam in mgcv</p>
</div>

<div class="d-byline">
  Michael Clark <a href="https://m-clark.github.io" class="uri">https://m-clark.github.io</a> 
  
<br/>September 29, 2019
</div>

<div class="d-article">
<h3 class="d-toc-header">Table of Contents</h3>
<nav class="d-toc" id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#r-packages-for-mixed-models">R Packages for Mixed Models</a></li>
<li><a href="#additive-model-example">Additive Model Example</a><ul>
<li><a href="#summary-comparison">Summary comparison</a></li>
<li><a href="#the-bam-approach">The bam approach</a></li>
<li><a href="#fixed-effects-comparison">Fixed effects comparison</a></li>
<li><a href="#variance-components-comparison">Variance components comparison</a></li>
<li><a href="#estimated-random-effects">Estimated random effects</a></li>
<li><a href="#comparisons-to-bayesian-estimates">Comparisons to Bayesian Estimates</a></li>
</ul></li>
<li><a href="#back-to-the-initial-problem">Back to the initial problem</a></li>
<li><a href="#limitations">Limitations</a></li>
<li><a href="#other-options">Other options</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
</nav>
<hr class="d-toc-separator"/>
<h2 id="introduction">Introduction</h2>
<p>With mixed models, it is easy to run into data that is larger in size than some more typical data scenarios. Consider a cross-sectional data set with 200 individuals. This is fairly small data. Now, if we observe them each five times as in a longitudinal setting, we suddenly have 1000 observations. There may be less than 200 countries in the world, but if we survey 100s or 1000s of people in many of them, we suddenly have a notable data set size, and still would potentially like to model a country-level random effect.</p>
<h2 id="r-packages-for-mixed-models">R Packages for Mixed Models</h2>
<p>While many tools abound to conduct mixed models for larger data sizes, their limitations can be found pretty quickly. R’s lme4 is a standard, but powerful mixed model tool. More to the point, it is very computationally effecient, such that it can handle very large sample sizes. For linear mixed models this can include hundreds of thousands of observations with possibly multiple random effects, still running on a basic laptop. For standard linear mixed models, it’s still largely the tool of choice, and its approach has even been copied/ported into other statistical tools.</p>
<p>We’ll first create some data to model. This is just a simple random intercepts setting.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
set.seed(12358)
N = 1e6
n_groups = 1000
g = rep(1:n_groups, e = N/n_groups)

x = rnorm(N)
b = rbinom(n_groups, size = 1, prob=.5)  # a cluster level categorical variable
b = rep(b, e = N/n_groups)

sd_g = .5     # standard deviation for the random effect
sigma = 1     # standard deviation for the observation

re = rnorm(n_groups, sd = sd_g)[g]  # random effects

lp = 0 + .5*x + .25*b + re  # linear predictor 
y = rnorm(N, mean = lp, sd = sigma)               # create a continuous target variable
y_bin = rbinom(N, size = 1, prob = plogis(lp))    # create a binary target variable

d = tibble(x, b, y, y_bin, g = factor(g))</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">

<pre class="r"><code>
kable_df(head_tail(d))</code></pre>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
index
</th>
<th style="text-align:right;">
x
</th>
<th style="text-align:right;">
b
</th>
<th style="text-align:right;">
y
</th>
<th style="text-align:right;">
y_bin
</th>
<th style="text-align:right;">
g
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-1.207
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-1.687
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
0.277
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.156
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
1.084
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.834
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
-2.346
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-2.325
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0.429
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.554
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
0.506
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.054
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
999995
</td>
<td style="text-align:right;">
-0.233
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.723
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1000
</td>
</tr>
<tr>
<td style="text-align:right;">
999996
</td>
<td style="text-align:right;">
0.302
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.970
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1000
</td>
</tr>
<tr>
<td style="text-align:right;">
999997
</td>
<td style="text-align:right;">
-2.439
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-1.954
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1000
</td>
</tr>
<tr>
<td style="text-align:right;">
999998
</td>
<td style="text-align:right;">
0.330
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.204
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1000
</td>
</tr>
<tr>
<td style="text-align:right;">
999999
</td>
<td style="text-align:right;">
-0.839
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.020
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1000
</td>
</tr>
<tr>
<td style="text-align:right;">
1000000
</td>
<td style="text-align:right;">
-0.043
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.139
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1000
</td>
</tr>
</tbody>
</table>
</div>
<p>So, for even a million observations and a single random effect, lme4 could possibly run a model in a few seconds.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(lme4)

system.time({
  mixed_big = lmer(y ~ x + b + (1|g))
})</code></pre>
<pre><code>
   user  system elapsed 
  5.283   0.474   5.769 </code></pre>
<pre class="r"><code>
summary(mixed_big, cor = FALSE)</code></pre>
<pre><code>
Linear mixed model fit by REML [&#39;lmerMod&#39;]
Formula: y ~ x + b + (1 | g)

REML criterion at convergence: 2841256

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-4.6066 -0.6743 -0.0004  0.6744  5.0367 

Random effects:
 Groups   Name        Variance Std.Dev.
 g        (Intercept) 0.2509   0.5009  
 Residual             0.9978   0.9989  
Number of obs: 1000000, groups:  g, 1000

Fixed effects:
             Estimate Std. Error t value
(Intercept) 0.0364754  0.0223332   1.633
x           0.5017616  0.0009987 502.409
b           0.1904534  0.0317430   6.000</code></pre>
</div>
<p>This is great. We just ran a mixed model for 1,000,000 observations and 1,000 groups for our random effect in just a few seconds.</p>
<p>But the problem comes as soon as you move to the generalized mixed model, e.g. having a binary outcome, or multiple random effects, unbalanced data, or you want a tool that does other things while still dealing with large data. The following is essentially the same model, but for a binary outcome.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
system.time({
  mixed_big_glmm = glmer(y_bin ~ x + b + (1|g), family = binomial)
})</code></pre>
<pre><code>
   user  system elapsed 
 82.237  17.679 100.038 </code></pre>
</div>
<p>For starters, you shouldn’t be worried about models taking a few minutes to run, or even a couple hours. Once you have your model/s squared away, much of which can be done on a smaller data set, there is no need to repeatedly run it. But in this case we had a greater than 15 fold increase in time for very standard data scenario. So it’s good to have options when you need them.</p>
<h2 id="additive-model-example">Additive Model Example</h2>
<p>Simon Wood’s wonderful work on generalized additive models (GAM) and the mgcv package make it one of the better modeling tools in the R kingdom. As his text<span class="citation" data-cites="wood_generalized_2017">(S. N. Wood <a href="#ref-wood_generalized_2017">2017</a>)</span> and other work shows, additive models can be seen as random effects models, and he exploits this by providing numerous ways to include random effects in the GAM approach.</p>
<p>The following demonstrates the link by showing a model that includes a random intercept and slope. We will use the standard mgcv approach for specifying a smooth term, but one could use the <span class="func" style="">gamm</span> function for the <span class="pack" style="">nlme</span> style, or Wood’s <span class="pack" style="">gamm4</span> package to use the lme4 syntax. These alternate approaches allow for more flexibility in some ways, but will not be useful to us for big data.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(lme4)
library(mgcv)

mixed_model = lmer(
  Reaction ~ Days + (1 | Subject) + (0 + Days | Subject),
  data = sleepstudy
)

ga_model = gam(
  Reaction ~  Days + s(Subject, bs = &#39;re&#39;) + s(Days, Subject, bs = &#39;re&#39;),
  data = sleepstudy,
  method = &#39;REML&#39;
)

# Using gamm and gamm4 for the same model
# ga_model = gamm(
#   Reaction ~  Days ,
#   data = sleepstudy,
#   random = list(Subject = ~ 0 + Days),
#   method = &#39;REML&#39;
# )
# 
# ga_model = gamm4::gamm4(
#   Reaction ~  Days,
#   random =  ~ (Days||Subject),
#   data = sleepstudy,
#   REML = TRUE
# )</code></pre>
</div>
<h3 id="summary-comparison">Summary comparison</h3>
<p>In the following we will see that the same results are obtained for both lme4 and mgcv. Note, I’ve been using mgcv a lot for mixed models lately, so created a package called <span class="pack" style="">gammit</span> to provide tidier output and output that is more similar to lme4. I note the corresponding mgcv function where appropriate.</p>
<aside>
The <span class="pack" style="">gammit</span> package is available on <a href="https://github.com/m-clark/gammit">GitHub</a>.
</aside>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(gammit)
summary(mixed_model)</code></pre>
<pre><code>
Linear mixed model fit by REML [&#39;lmerMod&#39;]
Formula: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
   Data: sleepstudy

REML criterion at convergence: 1743.7

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.9626 -0.4626  0.0204  0.4653  5.1860 

Random effects:
 Groups    Name        Variance Std.Dev.
 Subject   (Intercept) 627.50   25.050  
 Subject.1 Days         35.86    5.989  
 Residual              653.58   25.565  
Number of obs: 180, groups:  Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.885  36.514
Days          10.467      1.560   6.711

Correlation of Fixed Effects:
     (Intr)
Days -0.184</code></pre>
<pre class="r"><code>
summary(ga_model)</code></pre>
<pre><code>
Family: gaussian 
Link function: identity 

Formula:
Reaction ~ Days + s(Subject, bs = &quot;re&quot;) + s(Days, Subject, bs = &quot;re&quot;)

Parametric coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  251.405      6.885  36.513  &lt; 2e-16 ***
Days          10.467      1.560   6.712 3.67e-10 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Approximate significance of smooth terms:
                  edf Ref.df      F  p-value    
s(Subject)      12.94     17  89.29 4.56e-07 ***
s(Days,Subject) 14.41     17 104.56 1.82e-12 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

R-sq.(adj) =  0.794   Deviance explained = 82.7%
-REML = 871.83  Scale est. = 653.58    n = 180</code></pre>
</div>
<p>Let’s compare the variance components specifically. For now we will merely extract them for comparison later, but feel free to take a look.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# extract just the fixed effects for later.
mixed_fe = fixef(mixed_model)
gam_fe   = extract_fixed(ga_model)

# variance components
lmer_vcov = data.frame(VarCorr(mixed_model))
gam_vcov  = extract_vc(ga_model)  # cleaner gam.vcomp</code></pre>
</div>
<h3 id="the-bam-approach">The bam approach</h3>
<p>For large data, mgcv provides the bam function. For this small data setting we don’t really need bam, but we can establish that we would get similar results using it. We will see the benefits when we apply it to large data later.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
ba_model = bam(Reaction ~  Days + s(Subject, bs=&#39;re&#39;) + s(Days, Subject, bs=&#39;re&#39;), 
               data = sleepstudy)

bam_fe   = extract_fixed(ba_model)
bam_vcov = extract_vc(ba_model)</code></pre>
</div>
<p>How does it work? The function uses a parallelized approach where possible, essentially working on subsets of the model matrices simultaneously. Details can be found in the references, but basically mgcv parallelizes the parts that can be, and adds an additional option to discretize the data to work with the minimal information necessary to produce viable estimates.</p>
<p>The following uses the discrete option. There isn’t really anything to discretize with so little data, so the result is the same. This is just to demonstrate the syntax</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
ba_d_model = bam(Reaction ~  Days + s(Subject, bs=&#39;re&#39;) + s(Days, Subject, bs=&#39;re&#39;), 
                 data = sleepstudy,
                 discrete = T)

bam_d_fe   = extract_fixed(ba_d_model)
bam_d_vcov = extract_vc(ba_d_model)</code></pre>
</div>
<h3 id="fixed-effects-comparison">Fixed effects comparison</h3>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
mixed
</th>
<th style="text-align:right;">
gam
</th>
<th style="text-align:right;">
bam
</th>
<th style="text-align:right;">
bam_d
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
251.405
</td>
<td style="text-align:right;">
251.405
</td>
<td style="text-align:right;">
251.405
</td>
<td style="text-align:right;">
251.405
</td>
</tr>
<tr>
<td style="text-align:right;">
10.467
</td>
<td style="text-align:right;">
10.467
</td>
<td style="text-align:right;">
10.467
</td>
<td style="text-align:right;">
10.467
</td>
</tr>
</tbody>
</table>
</div>
<p>Note there are options for the gam models for standard error estimation, including a Bayesian one. For more details, see <code>?gamObject</code>, but I will offer the summary:</p>
<h5 id="ve">Ve</h5>
<p>frequentist estimated covariance matrix for the parameter estimators. Particularly useful for testing whether terms are zero. Not so useful for CI’s as smooths are usually biased.</p>
<h5 id="vp">Vp</h5>
<p>estimated covariance matrix for the parameters. This is a Bayesian posterior covariance matrix that results from adopting a particular Bayesian model of the smoothing process. Paricularly useful for creating credible/confidence intervals.</p>
<h5 id="vc">Vc</h5>
<p>Under ML or REML smoothing parameter estimation it is possible to correct the covariance matrix Vp for smoothing parameter uncertainty. This is the corrected version.</p>
<p>We will use the Bayesian estimates (<code>Vp</code>), but for this setting there are no differences.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
mixed
</th>
<th style="text-align:right;">
gam
</th>
<th style="text-align:right;">
bam
</th>
<th style="text-align:right;">
bam_d
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
6.885
</td>
<td style="text-align:right;">
6.885
</td>
<td style="text-align:right;">
6.885
</td>
<td style="text-align:right;">
6.885
</td>
</tr>
<tr>
<td style="text-align:right;">
1.560
</td>
<td style="text-align:right;">
1.560
</td>
<td style="text-align:right;">
1.560
</td>
<td style="text-align:right;">
1.560
</td>
</tr>
</tbody>
</table>
</div>
<h3 id="variance-components-comparison">Variance components comparison</h3>
<p>Reported are sd for subject level random effects for intercept, <code>Days</code> coefficient, and residual.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
mixed
</th>
<th style="text-align:left;">
gam
</th>
<th style="text-align:left;">
bam
</th>
<th style="text-align:left;">
bam_d
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
25.050
</td>
<td style="text-align:left;">
25.051370
</td>
<td style="text-align:left;">
25.051328
</td>
<td style="text-align:left;">
25.051329
</td>
</tr>
<tr>
<td style="text-align:right;">
5.989
</td>
<td style="text-align:left;">
5.988153
</td>
<td style="text-align:left;">
5.988172
</td>
<td style="text-align:left;">
5.988172
</td>
</tr>
<tr>
<td style="text-align:right;">
25.565
</td>
<td style="text-align:left;">
25.565254
</td>
<td style="text-align:left;">
25.565285
</td>
<td style="text-align:left;">
25.565285
</td>
</tr>
</tbody>
</table>
</div>
<p>Interval estimates for the above. Using profile likelihood for mixed model.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
component
</th>
<th style="text-align:right;">
lower
</th>
<th style="text-align:right;">
upper
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;vertical-align: top !important;" rowspan="3">
mixed
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
15.259
</td>
<td style="text-align:right;">
37.786
</td>
</tr>
<tr>
<td style="text-align:left;">
Days
</td>
<td style="text-align:right;">
3.964
</td>
<td style="text-align:right;">
8.769
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:right;">
22.881
</td>
<td style="text-align:right;">
28.788
</td>
</tr>
<tr>
<td style="text-align:left;vertical-align: top !important;" rowspan="3">
gam
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
16.085
</td>
<td style="text-align:right;">
39.015
</td>
</tr>
<tr>
<td style="text-align:left;">
Days|Subject
</td>
<td style="text-align:right;">
4.025
</td>
<td style="text-align:right;">
8.908
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:right;">
22.792
</td>
<td style="text-align:right;">
28.676
</td>
</tr>
<tr>
<td style="text-align:left;vertical-align: top !important;" rowspan="3">
bam
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
16.085
</td>
<td style="text-align:right;">
39.015
</td>
</tr>
<tr>
<td style="text-align:left;">
Days|Subject
</td>
<td style="text-align:right;">
4.025
</td>
<td style="text-align:right;">
8.908
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:right;">
22.792
</td>
<td style="text-align:right;">
28.676
</td>
</tr>
<tr>
<td style="text-align:left;vertical-align: top !important;" rowspan="3">
bam_d
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
16.085
</td>
<td style="text-align:right;">
39.015
</td>
</tr>
<tr>
<td style="text-align:left;">
Days|Subject
</td>
<td style="text-align:right;">
4.025
</td>
<td style="text-align:right;">
8.908
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:right;">
22.792
</td>
<td style="text-align:right;">
28.676
</td>
</tr>
</tbody>
</table>
</div>
<h3 id="estimated-random-effects">Estimated random effects</h3>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
mixed_re = ranef(mixed_model)[[1]] %&gt;% 
  rename(mixed_Subject = `(Intercept)`, `mixed_Days|Subject` = Days)

gam_re_init   = extract_ranef(ga_model)
bam_re_init   = extract_ranef(ba_model)
bam_d_re_init = extract_ranef(ba_d_model)</code></pre>
</div>
<p>Random effects for the intercept.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
bam_d_Subject
</th>
<th style="text-align:right;">
bam_Subject
</th>
<th style="text-align:right;">
gam_Subject
</th>
<th style="text-align:right;">
mixed_Subject
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1.51270
</td>
<td style="text-align:right;">
1.51270
</td>
<td style="text-align:right;">
1.51272
</td>
<td style="text-align:right;">
1.51170
</td>
</tr>
<tr>
<td style="text-align:right;">
-40.37390
</td>
<td style="text-align:right;">
-40.37390
</td>
<td style="text-align:right;">
-40.37397
</td>
<td style="text-align:right;">
-40.37201
</td>
</tr>
<tr>
<td style="text-align:right;">
-39.18104
</td>
<td style="text-align:right;">
-39.18104
</td>
<td style="text-align:right;">
-39.18111
</td>
<td style="text-align:right;">
-39.17951
</td>
</tr>
<tr>
<td style="text-align:right;">
24.51890
</td>
<td style="text-align:right;">
24.51890
</td>
<td style="text-align:right;">
24.51893
</td>
<td style="text-align:right;">
24.51881
</td>
</tr>
<tr>
<td style="text-align:right;">
22.91443
</td>
<td style="text-align:right;">
22.91443
</td>
<td style="text-align:right;">
22.91446
</td>
<td style="text-align:right;">
22.91419
</td>
</tr>
<tr>
<td style="text-align:right;">
9.22197
</td>
<td style="text-align:right;">
9.22197
</td>
<td style="text-align:right;">
9.22199
</td>
<td style="text-align:right;">
9.22178
</td>
</tr>
<tr>
<td style="text-align:right;">
17.15612
</td>
<td style="text-align:right;">
17.15612
</td>
<td style="text-align:right;">
17.15614
</td>
<td style="text-align:right;">
17.15572
</td>
</tr>
<tr>
<td style="text-align:right;">
-7.45173
</td>
<td style="text-align:right;">
-7.45173
</td>
<td style="text-align:right;">
-7.45174
</td>
<td style="text-align:right;">
-7.45166
</td>
</tr>
<tr>
<td style="text-align:right;">
0.57872
</td>
<td style="text-align:right;">
0.57872
</td>
<td style="text-align:right;">
0.57870
</td>
<td style="text-align:right;">
0.57984
</td>
</tr>
<tr>
<td style="text-align:right;">
34.76793
</td>
<td style="text-align:right;">
34.76793
</td>
<td style="text-align:right;">
34.76800
</td>
<td style="text-align:right;">
34.76617
</td>
</tr>
<tr>
<td style="text-align:right;">
-25.75432
</td>
<td style="text-align:right;">
-25.75432
</td>
<td style="text-align:right;">
-25.75436
</td>
<td style="text-align:right;">
-25.75382
</td>
</tr>
<tr>
<td style="text-align:right;">
-13.86504
</td>
<td style="text-align:right;">
-13.86504
</td>
<td style="text-align:right;">
-13.86504
</td>
<td style="text-align:right;">
-13.86539
</td>
</tr>
<tr>
<td style="text-align:right;">
4.91598
</td>
<td style="text-align:right;">
4.91598
</td>
<td style="text-align:right;">
4.91598
</td>
<td style="text-align:right;">
4.91618
</td>
</tr>
<tr>
<td style="text-align:right;">
20.92904
</td>
<td style="text-align:right;">
20.92904
</td>
<td style="text-align:right;">
20.92908
</td>
<td style="text-align:right;">
20.92816
</td>
</tr>
<tr>
<td style="text-align:right;">
3.25865
</td>
<td style="text-align:right;">
3.25865
</td>
<td style="text-align:right;">
3.25865
</td>
<td style="text-align:right;">
3.25848
</td>
</tr>
<tr>
<td style="text-align:right;">
-26.47583
</td>
<td style="text-align:right;">
-26.47583
</td>
<td style="text-align:right;">
-26.47585
</td>
<td style="text-align:right;">
-26.47568
</td>
</tr>
<tr>
<td style="text-align:right;">
0.90565
</td>
<td style="text-align:right;">
0.90565
</td>
<td style="text-align:right;">
0.90565
</td>
<td style="text-align:right;">
0.90573
</td>
</tr>
<tr>
<td style="text-align:right;">
12.42176
</td>
<td style="text-align:right;">
12.42176
</td>
<td style="text-align:right;">
12.42178
</td>
<td style="text-align:right;">
12.42132
</td>
</tr>
</tbody>
</table>
</div>
<p>Random effects for the Days effect.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
bam_d_days
</th>
<th style="text-align:right;">
bam_days
</th>
<th style="text-align:right;">
gam_days
</th>
<th style="text-align:right;">
mixed_days
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
9.32349
</td>
<td style="text-align:right;">
9.32349
</td>
<td style="text-align:right;">
9.32348
</td>
<td style="text-align:right;">
9.32373
</td>
</tr>
<tr>
<td style="text-align:right;">
-8.59917
</td>
<td style="text-align:right;">
-8.59917
</td>
<td style="text-align:right;">
-8.59916
</td>
<td style="text-align:right;">
-8.59954
</td>
</tr>
<tr>
<td style="text-align:right;">
-5.38779
</td>
<td style="text-align:right;">
-5.38779
</td>
<td style="text-align:right;">
-5.38778
</td>
<td style="text-align:right;">
-5.38807
</td>
</tr>
<tr>
<td style="text-align:right;">
-4.96865
</td>
<td style="text-align:right;">
-4.96865
</td>
<td style="text-align:right;">
-4.96865
</td>
<td style="text-align:right;">
-4.96868
</td>
</tr>
<tr>
<td style="text-align:right;">
-3.19393
</td>
<td style="text-align:right;">
-3.19393
</td>
<td style="text-align:right;">
-3.19394
</td>
<td style="text-align:right;">
-3.19393
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.30849
</td>
<td style="text-align:right;">
-0.30849
</td>
<td style="text-align:right;">
-0.30850
</td>
<td style="text-align:right;">
-0.30847
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.28721
</td>
<td style="text-align:right;">
-0.28721
</td>
<td style="text-align:right;">
-0.28721
</td>
<td style="text-align:right;">
-0.28715
</td>
</tr>
<tr>
<td style="text-align:right;">
1.11599
</td>
<td style="text-align:right;">
1.11599
</td>
<td style="text-align:right;">
1.11599
</td>
<td style="text-align:right;">
1.11599
</td>
</tr>
<tr>
<td style="text-align:right;">
-10.90597
</td>
<td style="text-align:right;">
-10.90597
</td>
<td style="text-align:right;">
-10.90596
</td>
<td style="text-align:right;">
-10.90624
</td>
</tr>
<tr>
<td style="text-align:right;">
8.62762
</td>
<td style="text-align:right;">
8.62762
</td>
<td style="text-align:right;">
8.62760
</td>
<td style="text-align:right;">
8.62796
</td>
</tr>
<tr>
<td style="text-align:right;">
1.28069
</td>
<td style="text-align:right;">
1.28069
</td>
<td style="text-align:right;">
1.28069
</td>
<td style="text-align:right;">
1.28063
</td>
</tr>
<tr>
<td style="text-align:right;">
6.75640
</td>
<td style="text-align:right;">
6.75640
</td>
<td style="text-align:right;">
6.75640
</td>
<td style="text-align:right;">
6.75652
</td>
</tr>
<tr>
<td style="text-align:right;">
-3.07513
</td>
<td style="text-align:right;">
-3.07513
</td>
<td style="text-align:right;">
-3.07513
</td>
<td style="text-align:right;">
-3.07519
</td>
</tr>
<tr>
<td style="text-align:right;">
3.51221
</td>
<td style="text-align:right;">
3.51221
</td>
<td style="text-align:right;">
3.51220
</td>
<td style="text-align:right;">
3.51238
</td>
</tr>
<tr>
<td style="text-align:right;">
0.87305
</td>
<td style="text-align:right;">
0.87305
</td>
<td style="text-align:right;">
0.87305
</td>
<td style="text-align:right;">
0.87308
</td>
</tr>
<tr>
<td style="text-align:right;">
4.98379
</td>
<td style="text-align:right;">
4.98379
</td>
<td style="text-align:right;">
4.98379
</td>
<td style="text-align:right;">
4.98381
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.00529
</td>
<td style="text-align:right;">
-1.00529
</td>
<td style="text-align:right;">
-1.00529
</td>
<td style="text-align:right;">
-1.00532
</td>
</tr>
<tr>
<td style="text-align:right;">
1.25840
</td>
<td style="text-align:right;">
1.25840
</td>
<td style="text-align:right;">
1.25840
</td>
<td style="text-align:right;">
1.25848
</td>
</tr>
</tbody>
</table>
</div>
<p>Standard errors.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:right;">
Intercepts
</th>
<th style="text-align:right;">
Days
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
mixed_re_se
</td>
<td style="text-align:right;">
12.240
</td>
<td style="text-align:right;">
2.340
</td>
</tr>
<tr>
<td style="text-align:left;">
gam_re_se
</td>
<td style="text-align:right;">
13.279
</td>
<td style="text-align:right;">
2.673
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_re_se
</td>
<td style="text-align:right;">
13.279
</td>
<td style="text-align:right;">
2.673
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_d_re_se
</td>
<td style="text-align:right;">
13.279
</td>
<td style="text-align:right;">
2.673
</td>
</tr>
</tbody>
</table>
</div>
<h3 id="comparisons-to-bayesian-estimates">Comparisons to Bayesian Estimates</h3>
<p>One of the differences between lme4 and mgcv output is that the default uncertainty estimates for the GAM are Bayesian. As such we can compare the estimate to a fully Bayes approach.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<h2 id="back-to-the-initial-problem">Back to the initial problem</h2>
<p>So we’ve established that both default gam and bam output are providing what we want. The reason for d Let’s return to the binary outcome example that took over a minute for lme4 to run.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
system.time({
  bam_big &lt;- bam(
    y_bin ~ x + b + s(g, bs=&#39;re&#39;), 
    data = d,
    nthreads = 8,
    family = binomial
  )
})</code></pre>
<pre><code>
    user   system  elapsed 
8150.149  123.900 1295.475 </code></pre>
</div>
<p>That didn’t actually improve our situation, and actually was much worse in time- 20 minutes! In practice however, with additional complexities bam would win out eventually<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>. However, even here we haven’t used all our secret weapons. Another option with bam works on a modified dataset using binned values for continuous covariates<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>. With large enough data, as would be the case here, the estimated parameters might not be different at all, while the efficiency gains could be tremendous. Let’s add <code>discrete = TRUE</code> and see what happens.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
system.time({
  bam_big_d &lt;- bam(
    y_bin ~ x + b + s(g, bs=&#39;re&#39;), 
    data = d,
    nthreads = 8,
    family = binomial, 
    discrete = TRUE
  )
})</code></pre>
<pre><code>
   user  system elapsed 
 43.811   1.788  10.897 </code></pre>
</div>
<p><strong>Wow!</strong> That was as fast as lme4 with the linear mixed model! Let’s check the results.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
Term
</th>
<th style="text-align:right;">
Estimate
</th>
<th style="text-align:right;">
SE
</th>
<th style="text-align:right;">
LL
</th>
<th style="text-align:right;">
UL
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
bam_big
</td>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
0.037
</td>
<td style="text-align:right;">
0.023
</td>
<td style="text-align:right;">
-0.007
</td>
<td style="text-align:right;">
0.082
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_big
</td>
<td style="text-align:left;">
x
</td>
<td style="text-align:right;">
0.501
</td>
<td style="text-align:right;">
0.002
</td>
<td style="text-align:right;">
0.496
</td>
<td style="text-align:right;">
0.505
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_big
</td>
<td style="text-align:left;">
b
</td>
<td style="text-align:right;">
0.191
</td>
<td style="text-align:right;">
0.032
</td>
<td style="text-align:right;">
0.128
</td>
<td style="text-align:right;">
0.254
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_big_d
</td>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
0.037
</td>
<td style="text-align:right;">
0.023
</td>
<td style="text-align:right;">
-0.007
</td>
<td style="text-align:right;">
0.082
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_big_d
</td>
<td style="text-align:left;">
x
</td>
<td style="text-align:right;">
0.501
</td>
<td style="text-align:right;">
0.002
</td>
<td style="text-align:right;">
0.496
</td>
<td style="text-align:right;">
0.505
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_big_d
</td>
<td style="text-align:left;">
b
</td>
<td style="text-align:right;">
0.191
</td>
<td style="text-align:right;">
0.032
</td>
<td style="text-align:right;">
0.128
</td>
<td style="text-align:right;">
0.254
</td>
</tr>
<tr>
<td style="text-align:left;">
lme4
</td>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
-0.004
</td>
<td style="text-align:right;">
0.023
</td>
<td style="text-align:right;">
-0.048
</td>
<td style="text-align:right;">
0.041
</td>
</tr>
<tr>
<td style="text-align:left;">
lme4
</td>
<td style="text-align:left;">
x
</td>
<td style="text-align:right;">
0.498
</td>
<td style="text-align:right;">
0.002
</td>
<td style="text-align:right;">
0.493
</td>
<td style="text-align:right;">
0.502
</td>
</tr>
<tr>
<td style="text-align:left;">
lme4
</td>
<td style="text-align:left;">
b
</td>
<td style="text-align:right;">
0.244
</td>
<td style="text-align:right;">
0.032
</td>
<td style="text-align:right;">
0.182
</td>
<td style="text-align:right;">
0.306
</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<h2 id="limitations">Limitations</h2>
<ul>
<li>No estimation of random effect correlations, e.g. slopes and intercepts</li>
<li>When <code>discrete = TRUE</code>, some <span class="func" style="">predict.gam</span> functionality may be lost</li>
</ul>
<h2 id="other-options">Other options</h2>
<p>When looking into mixed models for big data, you typically won’t find much. I’ve seen some packages or offereings for some machine learning approaches like random forests<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>, but this doesn’t address the issue of large data. A Spark module is available, <a href="https://github.com/linkedin/photon-ml">photonML</a>, provided by LinkedIn, but it’s not clear how easy it is to implement. Julia has recently made multithreading a viable option for any function. This is notable since Doug Bates, one of the lme4 authors, develops the <a href="https://github.com/dmbates/MixedModels.jl">MixedModels</a> module for Julia. Should multithreading functionality be added, it could be a very powerful tool.</p>
<h2 id="summary" class="unnumbered">Summary</h2>
<div id="refs" class="references">
<div id="ref-li_faster_2019">
<p>Li, Zheyuan, and Simon N. Wood. 2019. “Faster Model Matrix Crossproducts for Large Generalized Linear Models with Discretized Covariates.” <em>Statistics and Computing</em>, March. <a href="https://doi.org/10.1007/s11222-019-09864-2">https://doi.org/10.1007/s11222-019-09864-2</a>.</p>
</div>
<div id="ref-wood_mgcv:_2012">
<p>Wood, Simon. 2012. “Mgcv: Mixed GAM Computation Vehicle with GCV/AIC/REML Smoothness Estimation,” October. <a href="https://researchportal.bath.ac.uk/en/publications/mgcv-mixed-gam-computation-vehicle-with-gcvaicreml-smoothness-est">https://researchportal.bath.ac.uk/en/publications/mgcv-mixed-gam-computation-vehicle-with-gcvaicreml-smoothness-est</a>.</p>
</div>
<div id="ref-wood_generalized_2017">
<p>Wood, Simon N. 2017. <em>Generalized Additive Models : An Introduction with R, Second Edition</em>. Chapman; Hall/CRC. <a href="https://doi.org/10.1201/9781315370279">https://doi.org/10.1201/9781315370279</a>.</p>
</div>
<div id="ref-wood_generalized_2015">
<p>Wood, Simon N., Yannig Goude, and Simon Shaw. 2015a. “Generalized Additive Models for Large Data Sets.” <em>Journal of the Royal Statistical Society: Series C (Applied Statistics)</em> 64 (1): 139–55. <a href="https://doi.org/10.1111/rssc.12068">https://doi.org/10.1111/rssc.12068</a>.</p>
</div>
<div id="ref-wood_generalized_2015-1">
<p>———. 2015b. “Generalized Additive Models for Large Data Sets.” <em>Journal of the Royal Statistical Society: Series C (Applied Statistics)</em> 64 (1): 139–55. <a href="https://doi.org/10.1111/rssc.12068">https://doi.org/10.1111/rssc.12068</a>.</p>
</div>
<div id="ref-wood_generalized_2017-1">
<p>Wood, Simon N., Zheyuan Li, Gavin Shaddick, and Nicole H. Augustin. 2017. “Generalized Additive Models for Gigadata: Modeling the U.k. Black Smoke Network Daily Data.” <em>Journal of the American Statistical Association</em> 112 (519): 1199–1210. <a href="https://doi.org/10.1080/01621459.2016.1195744">https://doi.org/10.1080/01621459.2016.1195744</a>.</p>
</div>
</div>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Even just adding an additional random effect would possibly be enough for this data example.<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p><a href="https://rss.onlinelibrary.wiley.com/doi/full/10.1111/rssc.12068">Wood, Goude and Shaw (2015)</a>.<a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>See <a href="https://cran.r-project.org/web/packages/REEMtree/">REEMtree</a>, <a href="https://cran.r-project.org/web/packages/MixRF/">mixRF</a> for example.<a href="#fnref3" class="footnote-back">↩</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<script id="distill-bibliography" type="text/bibtex">

@book{wood_generalized_2006,
	title = {Generalized additive models: an introduction with {R}},
	volume = {66},
	shorttitle = {Generalized additive models},
	publisher = {CRC Press},
	author = {Wood, S. N},
	year = {2006},
	file = {[PDF] from bath.ac.uk:/Users/micl/Zotero/storage/N99I9S57/Wood - 2006 - Generalized additive models an introduction with .pdf:application/pdf;Snapshot:/Users/micl/Zotero/storage/AVVZHAIN/Wood - 2006 - Generalized additive models an introduction with .html:text/html}
}

@article{wood_mgcv:_2012,
	title = {mgcv: {Mixed} {GAM} {Computation} {Vehicle} with {GCV}/{AIC}/{REML} smoothness estimation},
	shorttitle = {mgcv},
	url = {https://researchportal.bath.ac.uk/en/publications/mgcv-mixed-gam-computation-vehicle-with-gcvaicreml-smoothness-est},
	language = {English},
	urldate = {2019-09-29},
	author = {Wood, Simon},
	month = oct,
	year = {2012},
	file = {Snapshot:/Users/micl/Zotero/storage/V7NYNZR8/mgcv-mixed-gam-computation-vehicle-with-gcvaicreml-smoothness-est.html:text/html}
}

@book{wood_generalized_2017,
	title = {Generalized Additive Models : An Introduction with R, Second Edition},
	isbn = {978-1-315-37027-9},
	shorttitle = {Generalized {Additive} {Models}},
	url = {https://www.taylorfrancis.com/books/9781315370279},
	abstract = {The first edition of this book has established itself as one of the leading references on generalized additive models (GAMs), and the only book on the topic to},
	language = {en},
	urldate = {2019-09-29},
	publisher = {Chapman and Hall/CRC},
	author = {Wood, Simon N.},
	month = may,
	year = {2017},
	doi = {10.1201/9781315370279},
	file = {Full Text PDF:/Users/micl/Zotero/storage/CUH9EAKX/Wood - 2017 - Generalized Additive Models  An Introduction with.pdf:application/pdf;Snapshot:/Users/micl/Zotero/storage/VQ2HCD9B/9781315370279.html:text/html}
}

@article{li_faster_2019,
	title = {Faster model matrix crossproducts for large generalized linear models with discretized covariates},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/s11222-019-09864-2},
	doi = {10.1007/s11222-019-09864-2},
	abstract = {Wood et al. (J Am Stat Assoc 112(519):1199–1210, 2017) developed methods for fitting penalized regression spline based generalized additive models, with of the order of 10410410{\textasciicircum}4 coefficients, to up to 10810810{\textasciicircum}8 data. The methods offered two to three orders of magnitude reduction in computational cost relative to the most efficient previous methods. Part of the gain resulted from the development of a set of methods for efficiently computing model matrix products when model covariates each take only a discrete set of values substantially smaller than the sample size [generalizing an idea first appearing in Lang et al. (Stat Comput 24(2):223–238, 2014)]. Covariates can always be rounded to achieve such discretization, and it should be noted that the covariate discretization is marginal. That is we do not rely on discretizing covariates jointly, which would typically require the use of very coarse discretization. The most expensive computation in model estimation is the formation of the matrix cross product 𝐗𝖳𝐖𝐗XTWX{\textbackslash}mathbf\{X\}{\textasciicircum}\{{\textbackslash}mathsf\{T\}\}\{{\textbackslash}mathbf\{WX\}\} where 𝐗X{\textbackslash}mathbf\{X\} is a model matrix and 𝐖W\{{\textbackslash}mathbf\{W\}\} a diagonal or tri-diagonal matrix. The purpose of this paper is to present a simple, novel and substantially more efficient approach to the computation of this cross product. The new method offers, for example, a 30 fold reduction in cross product computation time for the Black Smoke model dataset motivating Wood et al. (2017). Given this reduction in computational cost, the subsequent Cholesky decomposition of 𝐗𝖳𝐖𝐗XTWX{\textbackslash}mathbf\{X\}{\textasciicircum}\{{\textbackslash}mathsf\{T\}\}\{{\textbackslash}mathbf\{WX\}\} and follow on computation of (𝐗𝖳𝐖𝐗)−1(XTWX)−1({\textbackslash}mathbf\{X\}{\textasciicircum}\{{\textbackslash}mathsf\{T\}\}\{{\textbackslash}mathbf\{WX\}\}){\textasciicircum}\{-1\} become a more significant part of the computational burden, and we also discuss the choice of methods for improving their speed.},
	language = {en},
	urldate = {2019-09-29},
	journal = {Statistics and Computing},
	author = {Li, Zheyuan and Wood, Simon N.},
	month = mar,
	year = {2019},
	keywords = {BLAS, Fast regression, Generalized additive model},
	file = {Springer Full Text PDF:/Users/micl/Zotero/storage/7KC4ZXMP/Li and Wood - 2019 - Faster model matrix crossproducts for large genera.pdf:application/pdf}
}

@article{wood_generalized_2015,
	title = {Generalized additive models for large data sets},
	volume = {64},
	copyright = {© 2014 The Authors. Journal of the Royal Statistical Society: Series C Applied Statistics Published by John Wiley \& Sons Ltd on behalf of the Royal Statistical Society.},
	issn = {1467-9876},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssc.12068},
	doi = {10.1111/rssc.12068},
	abstract = {We consider an application in electricity grid load prediction, where generalized additive models are appropriate, but where the data set's size can make their use practically intractable with existing methods. We therefore develop practical generalized additive model fitting methods for large data sets in the case in which the smooth terms in the model are represented by using penalized regression splines. The methods use iterative update schemes to obtain factors of the model matrix while requiring only subblocks of the model matrix to be computed at any one time. We show that efficient smoothing parameter estimation can be carried out in a well-justified manner. The grid load prediction problem requires updates of the model fit, as new data become available, and some means for dealing with residual auto-correlation in grid load. Methods are provided for these problems and parallel implementation is covered. The methods allow estimation of generalized additive models for large data sets by using modest computer hardware, and the grid load prediction problem illustrates the utility of reduced rank spline smoothing methods for dealing with complex modelling problems.},
	language = {en},
	number = {1},
	urldate = {2019-09-29},
	journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
	author = {Wood, Simon N. and Goude, Yannig and Shaw, Simon},
	year = {2015},
	keywords = {Correlated additive model, Electricity load prediction, Generalized additive model estimation},
	pages = {139--155},
	file = {Snapshot:/Users/micl/Zotero/storage/8LYQID9I/rssc.html:text/html}
}

@article{wood_generalized_2017-1,
	title = {Generalized Additive Models for Gigadata: Modeling the U.K. Black Smoke Network Daily Data},
	volume = {112},
	issn = {0162-1459},
	shorttitle = {Generalized Additive Models for Gigadata},
	url = {https://amstat.tandfonline.com/doi/full/10.1080/01621459.2016.1195744},
	doi = {10.1080/01621459.2016.1195744},
	abstract = {We develop scalable methods for fitting penalized regression spline based generalized additive models with of the order of 104 coefficients to up to 108 data. Computational feasibility rests on: (i) a new iteration scheme for estimation of model coefficients and smoothing parameters, avoiding poorly scaling matrix operations; (ii) parallelization of the iteration’s pivoted block Cholesky and basic matrix operations; (iii) the marginal discretization of model covariates to reduce memory footprint, with efficient scalable methods for computing required crossproducts directly from the discrete representation. Marginal discretization enables much finer discretization than joint discretization would permit. We were motivated by the need to model four decades worth of daily particulate data from the U.K. Black Smoke and Sulphur Dioxide Monitoring Network. Although reduced in size recently, over 2000 stations have at some time been part of the network, resulting in some 10 million measurements. Modeling at a daily scale is desirable for accurate trend estimation and mapping, and to provide daily exposure estimates for epidemiological cohort studies. Because of the dataset size, previous work has focused on modeling time or space averaged pollution levels, but this is unsatisfactory from a health perspective, since it is often acute exposure locally and on the time scale of days that is of most importance in driving adverse health outcomes. If computed by conventional means our black smoke model would require a half terabyte of storage just for the model matrix, whereas we are able to compute with it on a desktop workstation. The best previously available reduced memory footprint method would have required three orders of magnitude more computing time than our new method. Supplementary materials for this article are available online.},
	number = {519},
	urldate = {2019-09-29},
	journal = {Journal of the American Statistical Association},
	author = {Wood, Simon N. and Li, Zheyuan and Shaddick, Gavin and Augustin, Nicole H.},
	month = jul,
	year = {2017},
	pages = {1199--1210},
	file = {Full Text:/Users/micl/Zotero/storage/2N4Z5LJ3/Wood et al. - 2017 - Generalized Additive Models for Gigadata Modeling.pdf:application/pdf;Snapshot:/Users/micl/Zotero/storage/73X423H7/01621459.2016.html:text/html}
}

@article{wood_generalized_2015-1,
	title = {Generalized additive models for large data sets},
	volume = {64},
	copyright = {© 2014 The Authors. Journal of the Royal Statistical Society: Series C Applied Statistics Published by John Wiley \& Sons Ltd on behalf of the Royal Statistical Society.},
	issn = {1467-9876},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssc.12068},
	doi = {10.1111/rssc.12068},
	abstract = {We consider an application in electricity grid load prediction, where generalized additive models are appropriate, but where the data set's size can make their use practically intractable with existing methods. We therefore develop practical generalized additive model fitting methods for large data sets in the case in which the smooth terms in the model are represented by using penalized regression splines. The methods use iterative update schemes to obtain factors of the model matrix while requiring only subblocks of the model matrix to be computed at any one time. We show that efficient smoothing parameter estimation can be carried out in a well-justified manner. The grid load prediction problem requires updates of the model fit, as new data become available, and some means for dealing with residual auto-correlation in grid load. Methods are provided for these problems and parallel implementation is covered. The methods allow estimation of generalized additive models for large data sets by using modest computer hardware, and the grid load prediction problem illustrates the utility of reduced rank spline smoothing methods for dealing with complex modelling problems.},
	language = {en},
	number = {1},
	urldate = {2019-09-29},
	journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
	author = {Wood, Simon N. and Goude, Yannig and Shaw, Simon},
	year = {2015},
	keywords = {Correlated additive model, Electricity load prediction, Generalized additive model estimation},
	pages = {139--155},
	file = {Snapshot:/Users/micl/Zotero/storage/66YDF5ZT/rssc.html:text/html}
}
</script>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
