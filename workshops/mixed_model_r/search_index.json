[
["index.html", "Mixed Models in R", " Mixed Models in R Michael Clark 2017-06-01 "],
["introduction.html", "Introduction Overview Terminology", " Introduction Overview Mixed models are an extremely useful modeling tool for clustered data situations. It is quite common to have data in which we have repeated measurements for the units of observation, or in which the units of observation are otherwise clustered (e.g. students within school, cities within geographic region). While there are different ways to approach such a situation, mixed models are far and away a common and powerful tool to do so. Goals The goal of this workshop is primarily to provide a sense of when one would use mixed models and a variety of standard techniques. Additionally, we’ll have exercises to practice. The document is very applied in nature, and only assumes a basic understanding of standard regression models. Terminology For the uninitiated, the terminology surrounding mixed models, especially across disciplines, can be a bit daunting. Some terms you might come across regarding mixed models: Variance components Random intercepts and slopes Random effects Random coefficients Varying coefficients Intercepts and slopes-as-outcomes Hierarchical linear models Multilevel models (implies multiple levels of hierarchically clustered data) Growth curve models (possibly Latent GCM) Mixed effects models All describe types of mixed models. Some might be more historical, others are more often seen in a specific discipline, others might refer to a certain data structure (e.g. multilevel clustering), and still others are special cases. Mixed effects, or simply mixed, models generally refer to a mixture of fixed and random effects. I prefer the term mixed models because it is simple and no specific structure is implied[^mixmeth]. Fixed effects, is perhaps a poor but nonetheless stubborn term for the typical main effects one would see in a linear regression model, i.e. the non-random part of a mixed model, and in some contexts they are referred to as the population average effect. Kinds of clustering Data might have one or multiple sources of clustering, and that clustering may be hierarchical, such that clusters are nested within other clusters. An example would be scholastic aptitude tests given multiple times to students (repeated observations nested within students, students nested within schools, schools nested within districts). In other cases, there is no nesting structure. An example would be a reaction time experiment where participants perform the same set of tasks. While observations are nested within individual, observations are also clustered according to task type. Some use the terms nested and crossed to distinguish between these scenarios. "],
["clustered-data.html", "Clustered Data Random Intercepts model Example: student GPA The standard regression model The mixed model Application Cluster level covariate Summary Exercises", " Clustered Data Random Intercepts model For the following we’ll demonstrate the simplest1 and most common case of a mixed model, that in which we have a single random effect added to the standard regression situation. We’ll start with some data to get our bearings. Example: student GPA For the following we’ll assess factors predicting college grade point average (GPA). Each of the 200 students is assessed for six occasions (each semester for the first three years), so we have observations nested within students. We have other variables such as job status, sex, high school gpa. Some will be in both labeled and numeric form. See the appendix for details. The standard regression model Now for the underlying model. We can show the underlying model in a couple different ways. First we start with just a standard regression. \\[gpa = b_{\\mathrm{intercept}} + b_{\\mathrm{occ}}\\cdot occasion + \\epsilon\\] We have coefficients for the intercept and the effect of time. The error \\(\\epsilon\\) is assumed to be normally distributed with mean 0 and some standard deviation \\(\\sigma\\). \\[\\epsilon \\sim \\mathscr{N}(0, \\sigma)\\] The mixed model Initial depiction Now we show one way of showing it as a mixed model that includes an effect of student. This depiction shows that students are an additional source of variance. \\[gpa = b_{\\mathrm{intercept}} + b_{\\mathrm{occ}}\\cdot occasion + (\\mathrm{effect}_{\\mathscr{student}} + \\epsilon)\\] As a multi-level model This next depcition is commonly seen in the multilevel modeling picture. It is shown into two parts, one at the observation level and one at the student level. After ‘plugging in’, it is identical to the previous. \\[gpa = b_{\\mathrm{int\\_student}} + b_{\\mathrm{occ}}\\cdot \\mathrm{occasion} + \\epsilon\\] \\[b_{\\mathrm{int\\_student}} = b_{\\mathrm{intercept}} + \\mathrm{effect}_{\\mathrm{student}}\\] In either case, we (usually) assume the following for the student effects. \\[\\mathrm{effect}_{\\mathrm{student}} \\sim \\mathscr{N}(0, \\tau)\\] Both are normally distributed with mean of zero and some estimated standard deviation. In other words, conceptually the only difference between the mixed model and a standard regression is the student effect, which is on average no effect, but specifically varies from student to student with some standard deviation (\\(\\tau\\)). Application Initial visualization It always helps to look before we leap, so let’s do so. Here we plot GPA vs. occasion (i.e. semester) to get a sense of the variability in starting points and trends. All student paths are shown in blue, with a sample of 10 shown in orange. The overall trend as estimated by the regression we’ll do later is shown in red. Two things stand out. One is that students have a lot of variability in starting out. Secondly, while the general trend in gpa is upward over time as we’d expect, individual students may vary in that trajectory. Standard regression So let’s get started. First, we’ll look at the regression and only the time trend. Note that I present a cleaner version of the summarized objects for the purposes of this document. load(&#39;data/gpa.RData&#39;) gpa_lm = lm(gpa ~ occasion, data=gpa) ## summary(gpa_lm) Estimate Std. Error t value Pr(&gt;|t|) occasion 0.1063 0.005894 18.04 1.574e-64 (Intercept) 2.599 0.01785 145.7 0 Fitting linear model: gpa ~ occasion Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 1200 0.3487 0.2136 0.2129 The above tells us that as we move from semester to semester, we can expect GPA to increase by about 0.11 points. This would be fine except that we are ignoring the clustering. A side effect of doing so is that our standard errors are incorrect, and thus claims about statistical significance based on them would be off. More importantly however is that we simply don’t get to explore the student effect, which would be of interest by itself. Regression by cluster An alternative approach would be to run separate regressions for every student. However, there are many drawbacks to this- it’s not easily summarized when there are many groups, typically there would be very little data to do so, and the models are overcontextualized, meaning they ignore what students have in common. We’ll compare this result to the mixed model later. Mixed model Next we run a mixed model that will allow for a student specific effect. Such a model is easily conducted in R, specifically with the package lme4. In the following, the code will look just like what you used for regression with lm, but with an additional component specifying the group effect. The (1|student) means that we are allowing the intercept, represented by 1, to vary by student. With the mixed model, we get the same results as the regression, but with more to talk about. library(lme4) gpa_mixed = lmer(gpa ~ occasion + (1|student), data=gpa) ## summary(gpa_mixed) term estimate std.error statistic (Intercept) 2.60 0.02 119.80 occasion 0.11 0.00 26.10 grp variance sd student 0.064 0.252 Residual 0.058 0.241 First we see that the coefficients for the intercept and time are the same2, as would be their interpretation. The standard errors, on the other hand are different here, though in the end our conclusion as far as stistical significance goes would be the same. However, the lme4 does not provide p-values. There is a reason for this, namely that with mixed models we are essentialy dealing with two sample sizes, the N cluster and N observations, the effective degrees of freedom lies somewhere in between. Other programs provide p-values as if there is no issue, and without telling you which approach they use to calculate them (there are several). However, it’s easy enough to get confidence intervals with lme4 as follows. confint(gpa_mixed) term estimate std.error statistic conf.low conf.high group (Intercept) 2.60 0.02 119.80 2.56 2.64 fixed occasion 0.11 0.00 26.10 0.10 0.11 fixed sd_(Intercept).student 0.25 student sd_Observation.Residual 0.24 Residual One thing that’s new compared to the standard regression output is the estimated variance/standard deviation of the student effect (\\(\\tau\\) in our formula depiction from before). This tells us how much, on average, gpa bounces around as we move from student to student. In other words, even after making a prediction based on time point, each student has their own unique deviation, and that value is the estimated average deviation. Note that scores move due to the student more than double what they move based on a semester change. What’s more, we can actually get estimates of the student effects. I show two ways for the first five students, as random effect and as random intercept (i.e. effect + intercept). ranef(gpa_mixed)$student %&gt;% head(5) (Intercept) -0.071 -0.216 0.088 -0.187 0.030 coef(gpa_mixed)$student %&gt;% head(5) (Intercept) occasion 2.528 0.106 2.384 0.106 2.687 0.106 2.413 0.106 2.630 0.106 Note that we did not allow occasion to vary, so it is a constant, i.e. fixed, effect for all students. Another way to interpret the variance output is via the intraclass correlation, which tells us how much of the variance is due to the clustering. In this case it’s just the student variance out of the total, or 0.064 / 0.122 = 52.3%. Cluster level covariate Note our depiction of a mixed model as a multilevel model. \\[gpa = b_{\\mathrm{int\\_student}} + b_{\\mathrm{occ}}\\cdot \\mathrm{occasion} + \\epsilon\\] \\[b_{\\mathrm{int\\_student}} = b_{\\mathrm{intercept}} + \\mathrm{effect}_{\\mathrm{student}}\\] If we add student a student level covariate, e.g sex, to the model, we then have the following. \\[b_{\\mathrm{int\\_student}} = b_{\\mathrm{intercept}} + b_{sex}\\cdot \\mathrm{sex} + \\mathrm{effect}_{\\mathrm{student}}\\] Which, after plugging in we still have the same model as before, just with an additional predictor. \\[gpa = b_{\\mathrm{intercept}} + b_{\\mathrm{occ}}\\cdot occasion+ b_{sex}\\cdot \\mathrm{sex} + (\\mathrm{effect}_{\\mathscr{student}} + \\epsilon)\\] Thus, adding cluster level covariates doesn’t have any unusual effect on how we think about the model3. We simply add them to our set of predictor variables. Note also, that we can create cluster level covariates as means or some other summary of the observation level variables. This is especially common when the clusters represent geographical units and observations are people. Summary Mixed models allow for us to take into account clustering in the data. If this were all it was used for, we would have more accurate inference relative to what would be had if we ignored the structure in the data. However, we get much more. We better understand the sources of variability in the target variable. We also get group specific estimates of the parameters in the model, allowing us to understand exactly how the groups differ from one another. Furthermore, this in turn allows for group specific prediction, and much more accurate prediction. In short, there is much to be gained by mixed models, even in the simplest of settings. Exercises Sleep For this exercise, we’ll use the sleep study data from the lme4 package. The followin describes it. The average reaction time per day for subjects in a sleep deprivation study. On day 0 the subjects had their normal amount of sleep. Starting that night they were restricted to 3 hours of sleep per night. The observations represent the average reaction time (in milliseconds) on a series of tests given each day to each subject. After loading the package, the data can be loaded as follows. I show the first few observations. library(lme4) data(&quot;sleepstudy&quot;) Reaction Days Subject 249.6 0 308 258.7 1 308 250.8 2 308 321.4 3 308 356.9 4 308 414.7 5 308 Run a mixed model with Days as a covariate and a random intercept for Subject. Cluster level covariate Rerun the mixed model with the GPA data adding the cluster level covariate of sex, or high school gpa (highgpa), or both. Interpret all aspects of the results. What happened to the cluster level variance after adding cluster level covariates to the model? Actually, the simplest model would have no covariates at all, just variance components. Such a model can be interesting to look at while exploring your data, but would probably never suffice to tell the story you desire to.↩ This will not always be the case, e.g. with unbalanced data, but they should be fairly close.↩ This is why the multilevel depiction is subpar, and leads many to confusion at times. You have a target variable and predictor variables based on theory. Whether they are cluster level variables or if there are interactions doesn’t have anything to do with the data structure. However, if you depict the model in multilevel fashion, the final model must adhere to the ‘plugged in’ result.↩ "],
["random-slopes.html", "Random Slopes Application Exercises", " Random Slopes Previously we’ve looked at random intercepts, but any observation level covariate could be allowed to vary by cluster as well. Application Returning to the GPA data, recall the visualization from before. Let us now assume that the trends over time are worth allowing to vary by student. Using lme4, this is quite straightforward. gpa_mixed = lmer(gpa ~ occasion + (1 + occasion|student), data=gpa) summary(gpa_mixed) Pretty easy huh? Let’s look at the results. term estimate std.error statistic (Intercept) 2.60 0.02 141.59 occasion 0.11 0.01 18.07 grp var1 variance sd student (Intercept) 0.045 0.213 student occasion 0.005 0.067 Residual 0.042 0.206 Note that since we have 0 as our starting semester, the intercept tells us what the average GPA is in the first semester. The associated intercept variance tells us how much that starting GPA bounces around from student to student. The slope variance might not look like much in comparison, but slopes are on a notably different scale than the intercept. Note that the mean slope for the semester to semester effect, our fixed effect, is 0.11, but from student to student it bounces around half that, and we could effect most students to fall somewhere between a flat effect of zero to more than double the population average. Yet another point of interest is the correlation of the intercepts and slopes. In this case it’s -0.1. That’s pretty small, but the interpretation is the same as with any correlation. In this case specifically, it tells us that those with lower intercepts would be assocaited with increased time trajectories. This makes intuitive sense in that those at the bottom would have more room to improve. However, this is very slight, and practically speaking we might not put too much weight on it. Comparison to many regressions Let’s compare these results to the ones we would have gotten had we run a separate regression for each student. First the intercepts. Here we can see that the mixed model intercepts are generally not as extreme, i.e. the tails have been pulled toward the overall effect. Same goes for the slopes. In both cases the mixed model shrinks what otherwise would have been the by-group estimate, which would overfit. This regularizing effect is yet another bonus when using mixed models. Exercises Sleep revisited Run the sleep study model with random coefficient for the Days effect. library(lme4) data(&quot;sleepstudy&quot;) "],
["extensions.html", "Extensions Additional Grouping Structure Correlational Structure Generalized Linear Mixed Models Exercises", " Extensions Additional Grouping Structure Cross-classified models Oftentimes there will be additional sources of variance beyond one grouping factor. Consider as an example, a visual perception experiment where there are multiple trials for each individual along with specific images displayed. Such data might look like this. crossing(Person=1:20, Image=letters[1:10]) %&gt;% mutate(score=sample(1:10, 200, replace=T)) %&gt;% DT::datatable(options=list(dom=&#39;tp&#39;), rownames = F) In such a case we have observations clustered within both person and image, but person and image are not nested within one another. For example all participants see all 10 items. Such a situation is typically referred to as one in which there are crossed random effects. In such settings we have multiple sources variances to consider. Example: Student achievement For our own demonstration we’ll look at achievment scores for students. The sources of dependency are due to students having gone to the same primary or secondary schools. However, in this example, going to a primary school doesn’t necessarily mean you’ll go to a specific secondary school. Note also that there are no repeated measures, we see each student only one. Here’s a quick look a the data. load(&#39;data/pupils.RData&#39;) For our mixed model we’ll look at the effects for sex and socioeconomic status, ses, a six level variable from low to high on scholastic achievement. The range of achievement scores is roughly 4 to 10, with mean of 6.3 and standard deviation 0.9. We’ll take into account the clustering at primary school and secondary school. To incorporate the additional structure in lme4 syntax is very easy, we just do as we did before4. pupils_crossed = lmer(achievement ~ sex + ses + (1|primary_school_id) + (1|secondary_school_id), data = pupils) ## summary(pupils_crossed, correlation=F) term estimate std.error statistic conf.low conf.high (Intercept) 5.92 0.12 48.30 5.68 6.16 sexfemale 0.26 0.05 5.72 0.17 0.35 ses2 0.13 0.12 1.12 -0.10 0.36 ses3 0.10 0.11 0.89 -0.12 0.31 ses4 0.30 0.10 2.85 0.09 0.50 ses5 0.35 0.10 3.51 0.16 0.55 seshighest 0.62 0.11 5.60 0.40 0.83 The fixed effects tell us there is a positive effect of being female on achievement, and in general, relative to lowest SES category, being in the upper categories of SES also has a positive effect. grp var1 variance sd primary_school_id (Intercept) 0.173 0.416 secondary_school_id (Intercept) 0.066 0.257 Residual 0.473 0.688 When we look at the variance components we see that primary and secondary school does contribute about 34% of the total variance. Most of the variance attributable to school comes from the primary school. Note that we have the usual extensions here if desired. As an example, we could also do random slopes for student level characteristics. Hierarchical Structure Now that we have looked at cross-classified models, we can examine hierarchical Example: Nurses and Stress load(&#39;data/nurses.RData&#39;) nurses_hierarchical = lmer(stress ~ age + gender + experience + treatment + wardtype + hospsize + (1|hospital) + (1|hospital:ward), data = nurses) ## summary(nurses_hierarchical, correlation=F) term estimate std.error statistic conf.low conf.high (Intercept) 5.38 0.18 29.13 5.02 5.74 age 0.02 0.00 10.05 0.02 0.03 gender -0.45 0.03 -12.95 -0.52 -0.38 experience -0.06 0.00 -13.78 -0.07 -0.05 treatmentexperiment -0.70 0.12 -5.84 -0.93 -0.47 wardtypespecial care 0.05 0.12 0.42 -0.18 0.29 hospsizemedium 0.49 0.20 2.43 0.09 0.88 hospsizelarge 0.90 0.27 3.28 0.36 1.44 grp var1 variance sd hospital:ward (Intercept) 0.337 0.580 hospital (Intercept) 0.119 0.345 Residual 0.217 0.466 Correlational Structure Sometimes we will want to estimate the residual correlation structure. This especially the case in the longitudinal setting, where we think that observations closer in time would be more strongly correlated than those further apart. For reasons that defy my ability to parse, lme4 does not provide the ability to do this, though practically every other mixed model package does5. In fact, two packages that come with the basic R installation do so, mgcv and nlme. We’ll demonstrate with the latter. The following shows the same model we did before, but also includes an autocorrelation structure, of lag order one, for the residuals. What this means is that we assume the residuals at one time point apart correlate with some value \\(\\phi\\), observations at two time points apart correlate \\(\\phi^2\\), and so on. As such we only need to estimate \\(\\phi\\), while the rest are then automatically determined. In nlme we use the built in corAR1 function and correlation argument. Note also the different random effect specification (though not too different). library(nlme) corr_res = lme(gpa ~ occasion, data = gpa, random = ~1|student, correlation = corAR1(form = ~occasion)) summary(corr_res) Linear mixed-effects model fit by REML Data: gpa AIC BIC logLik 334.1208 359.5629 -162.0604 Random effects: Formula: ~1 | student (Intercept) Residual StdDev: 0.2145887 0.2732718 Correlation Structure: AR(1) Formula: ~occasion | student Parameter estimate(s): Phi 0.4182174 Fixed effects: gpa ~ occasion Value Std.Error DF t-value p-value (Intercept) 2.5969002 0.022951743 999 113.14610 0 occasion 0.1071433 0.005278835 999 20.29677 0 Correlation: (Intr) occasion -0.575 Standardized Within-Group Residuals: Min Q1 Med Q3 Max -3.053039561 -0.612466765 0.009312407 0.607759461 2.646750929 Number of Observations: 1200 Number of Groups: 200 While the output isn’t as pretty6, the fixed effect for occasion is the same as before. The variance estimates have changed slightly along with the variances of the parameters (i.e. the standard errors). The main thing is that we have a new paramter Phi, that represents our AR correlation with value of 0.418, suggesting at least some correlation among the residuals for observations next to each other in time, though it diminishes quickly. Generalized Linear Mixed Models Exercises I don’t show the formal model here as we did before, but this is why depicting mixed models solely as ‘multilevel’ becomes a bit problematic in my opinion. In the standard mixed model notation it’s straightforward though, you just add an addition random effect term, just as we do in the actual model syntax.↩ While I’m extremely grateful to the work put forth by those involved with lme4, making it probably the best mixed model package out there, this feature request has been made by its users for over a decade.↩ Nothing like randomly selected significant digits from 5 to 9 decimal places.↩ "],
["issues.html", "Issues Alternative approaches Sample sizes Crossed vs. Nested GLMM and beyond", " Issues Alternative approaches Alternative approaches used in clustered data situations include: Using cluster-robust standard errors Fixed effects models (also panel linear models with fixed, as opposed to random, effects) Generalized estimating equations The first two are commonly used by those trained with an econometrics perspective, while you might see GEE more with those of a biostatistics perspective. Growth curve models Sample sizes Small number of clusters Hard to estimate variance with small nclus Small N within cluster Mixed models work even with no more than two and some singletons Balanced/Missing values Crossed vs. Nested GLMM and beyond "],
["appendix.html", "Appendix Data Programming languages", " Appendix Data Note that I have converted these from their original SPSS format to R data.frames saved within RData files. I also cleaned them up with better names/labesl etc. GPA: The GPA data are a longitudinal data set, where 200 college students have been followed 6 consecutive semesters. In this data set, there are GPA measures on 6 consecutive occasions, with a JOB status variable (how many hours worked) for the same 6 occasions. There are two student-level explanatory variables: the gender (1= male, 2= female) and the high school GPA. There is also a dichotomous student-level outcome variable, which indicates whether a student has been admitted to the university of their choice. Since not every student applies to a university, this variable has many missing values. pupils: Assume that we have data from 1000 pupils who have attended 100 different primary schools, and subsequently went on to 30 secondary schools. Similar to the situation where we have pupils within schools and neighborhoods, we have a cross-classified structure. Pupils are nested within primary and within secondary schools, with primary and secondary schools crossed. In other words: pupils are nested within the cross-classification of primary and secondary schools. In our example, we have a response variable achievement which is measured in secondary school. We have two explanatory variables at the pupil level: pupil gender (0 = male, 1 = female) and a six-point scale for pupil socioeconomic status, pupil ses. We have at the school level a dichotom- ous variable that indicates if the school is public (denom = 0) or denominational (denom = 1). Since we have both primary and secondary schools, we have two such variables (named pdenom for the primary school and sdenom for the secondary school). nurses: The data in this example are from a hypothetical study on stress in hospitals. The data are from nurses working in wards nested within hospitals. In each of 25 hospitals, four wards are selected and randomly assigned to an experimental and control condition. In the experimental condition, a training program is offered to all nurses to cope with job- related stress. After the program is completed, a sample of about 10 nurses from each ward is given a test that measures job-related stress. Additional variables are: nurse age (years), nurse experience (years), nurse gender (0 = male, 1 = female), type of ward (0 = general care, 1 = special care), and hospital size (0 = small, 1 = medium, 2 = large). This is an example of an experiment where the experimental intervention is carried out at the group level. In biomedical research this design is known as a cluster randomized trial. They are quite common also in educational and organizational research, where entire classes or schools are assigned to experimental and control conditions. Since the design variable Experimental versus Control group (ExpCon) is manipulated at the second (ward) level, we can study whether the experimental effect is different in different hospitals, by defining the regression coefficient for the ExpCon variable as random at the hospital level. In this example, the variable ExpCon is of main interest, and the other variables are covariates. Their function is to control for differences between the groups, which should be small given that randomization is used, and to explain variance in the outcome variable stress. To the extent that they are successful in explaining variance, the power of the test for the effect of ExpCon will be increased. Therefore, although logically we can test if explanatory variables at the first level have random coefficients at the second or third level, and if explanatory variables at the second level have random coefficients at the third level, these possibilities are not pursued. We do test a model with a random coefficient for ExpCon at the third level, where there turns out to be significant slope variation. This varying slope can be predicted by adding a cross-level interaction between the variables ExpCon and HospSize. In view of this interaction, the variables ExpCon and HospSize have been centered on their overall mean. Programming languages R has more mixed modeling capabilities than anything else out there. However there are other options. lme4: generalized linear mixed models; extremely efficient nlme: non-linear mixed models but only for the gaussian case. mgcv: provides means to use both lme4 or nlme, extends distributional families, correlated residuals, and all that additive model stuff too rstanarm: Bayesian with lme4 level options brms: Bayesian with possibly the most extensive mixed model capabilities ordinal: for various types of ordinal models Python: the statsmodels module has basic capabilities for mixed models but not too many frills (e.g. no crossed random effects). Julia: one of the lme4 developers develops a MixedModels package for Julia Proprietary Among the standard stats packages, I can only recommend Stata for both ease of implementation and flexiblity in modeling. SAS and SPSS both have non-intuitive and needlessly verbose syntax, and SPSS consistently struggles with even simple models. Mplus has a lot of functionality both for standard mixed models and growth curve models, though between lavaan, mediation, and the rest of R, there is little need to use Mplus except for very complicated multilevel SEM, which you probably do not have the sample size for anyway. I will also say that there is zero reason to use mixed model specfic software like HLM. The day for such hijinks has long since passed. "]
]
