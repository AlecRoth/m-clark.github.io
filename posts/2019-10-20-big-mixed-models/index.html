<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
<title>Michael Clark: Mixed Models for Big Data</title>

<meta property="description" itemprop="description" content="Explorations of a fast penalized regression approach with mgcv"/>

<link rel="canonical" href="https://m-clark.github.io/posts/2019-10-20-big-mixed-models/"/>
<link rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/"/>
<link rel="icon" type="image/vnd.microsoft.icon" href="../../img/favicon.ico"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2019-10-20"/>
<meta property="article:created" itemprop="dateCreated" content="2019-10-20"/>
<meta name="article:author" content="Michael Clark"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="Michael Clark: Mixed Models for Big Data"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="Explorations of a fast penalized regression approach with mgcv"/>
<meta property="og:url" content="https://m-clark.github.io/posts/2019-10-20-big-mixed-models/"/>
<meta property="og:image" content="https://m-clark.github.io/posts/2019-10-20-big-mixed-models/../../img/gam_sim.png"/>
<meta property="og:image:width" content="1200"/>
<meta property="og:image:height" content="900"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="Michael Clark"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="Michael Clark: Mixed Models for Big Data"/>
<meta property="twitter:description" content="Explorations of a fast penalized regression approach with mgcv"/>
<meta property="twitter:url" content="https://m-clark.github.io/posts/2019-10-20-big-mixed-models/"/>
<meta property="twitter:image" content="https://m-clark.github.io/posts/2019-10-20-big-mixed-models/../../img/gam_sim.png"/>
<meta property="twitter:image:width" content="1200"/>
<meta property="twitter:image:height" content="900"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="Michael Clark: Mixed Models for Big Data"/>
<meta name="citation_fulltext_html_url" content="https://m-clark.github.io/posts/2019-10-20-big-mixed-models/"/>
<meta name="citation_fulltext_world_readable" content=""/>
<meta name="citation_online_date" content="2019/10/20"/>
<meta name="citation_publication_date" content="2019/10/20"/>
<meta name="citation_author" content="Michael Clark"/>
<!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Generalized additive models : An introduction with r, second edition;citation_publication_date=2017;citation_publisher=Chapman; Hall/CRC;citation_doi=10.1201/9781315370279;citation_author=Simon N. Wood"/>
  <meta name="citation_reference" content="citation_title=Generalized additive models for large data sets;citation_publication_date=2015;citation_volume=64;citation_doi=10.1111/rssc.12068;citation_issn=1467-9876;citation_author=Simon N. Wood;citation_author=Yannig Goude;citation_author=Simon Shaw"/>
  <meta name="citation_reference" content="citation_title=GlmmTMB balances speed and flexibility among packages for zero-inflated generalized linear mixed modeling;citation_publication_date=2017;citation_volume=9;citation_issn=2073-4859;citation_author=Mollie E. Brooks;citation_author=Kasper Kristensen;citation_author=Koen J. van Benthem;citation_author=Arni Magnusson;citation_author=Casper W. Berg;citation_author=Anders Nielsen;citation_author=Hans J. Skaug;citation_author=Martin MÃ¤chler;citation_author=Benjamin M. Bolker"/>
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["creative_commons","title","description","author","date","preview","output","draft","bibliography","nocite","tags","categories","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["CC BY-SA"]},{"type":"character","attributes":{},"value":["Mixed Models for Big Data"]},{"type":"character","attributes":{},"value":["Explorations of a fast penalized regression approach with mgcv"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Michael Clark"]},{"type":"character","attributes":{},"value":["https://m-clark.github.io"]}]}]},{"type":"character","attributes":{},"value":["2019-10-20"]},{"type":"character","attributes":{},"value":["../../img/gam_sim.png"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc","css"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["../../styles.css"]}]}]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["gam_references.bib"]},{"type":"character","attributes":{},"value":["@li_faster_2019, @wood_mgcv:_2012, @wood_generalized_2015, @wood_generalized_2015-1, @wood_generalized_2017-1\n"]},{"type":"character","attributes":{},"value":["mixed models","big data","generalized linear mixed models","additive models","random effects","lme4","glmmTMB","mgcv","lmer","glmer"]},{"type":"character","attributes":{},"value":["GAM","mixed models","big data","bayesian"]},{"type":"character","attributes":{},"value":["https://m-clark.github.io/posts/2019-10-20-big-mixed-models/"]},{"type":"character","attributes":{},"value":["https://m-clark.github.io/posts/2019-10-20-big-mixed-models/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["big-mixed-models_files/bowser-1.9.3/bowser.min.js","big-mixed-models_files/distill-2.2.21/template.v2.js","big-mixed-models_files/figure-html5/gmm-timings-1.svg","big-mixed-models_files/figure-html5/lme-timings-1.svg","big-mixed-models_files/figure-html5/lme-timings-2.svg","big-mixed-models_files/jquery-1.11.3/jquery.min.js","big-mixed-models_files/kePrint-0.0.1/kePrint.js","big-mixed-models_files/webcomponents-2.0.0/webcomponents.js","gam_references.bib","mccoach.pdf"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #455a64;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative;}
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

</style>

<link href="../../site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for table of contents */

.d-toc {
  color: rgba(0,0,0,0.8);
  font-size: 0.8em;
  line-height: 1em;
}

.d-toc-header {
  font-size: 0.6rem;
  font-weight: 400;
  color: rgba(0, 0, 0, 0.5);
  text-transform: uppercase;
  margin-top: 0;
  margin-bottom: 1.3em;
}

.d-toc a {
  border-bottom: none;
}

.d-toc ul {
  padding-left: 0;
}

.d-toc li>ul {
  padding-top: 0.8em;
  padding-left: 16px;
  margin-bottom: 0.6em;
}

.d-toc ul,
.d-toc li {
  list-style-type: none;
}

.d-toc li {
  margin-bottom: 0.9em;
}

.d-toc-separator {
  margin-top: 20px;
  margin-bottom: 2em;
}

.d-article-with-toc {
  border-top: none;
  padding-top: 0;
}



/* Tweak code blocks (note that this CSS is repeated above in an injection
   into the d-code shadow dom) */

d-code {
  overflow-x: auto !important;
}

pre.d-code code.d-code {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

pre.text-output {

  font-size: 12px;
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

@media(min-width: 768px) {

d-code {
  overflow-x: visible !important;
}

pre.d-code code.d-code  {
    padding-left: 18px;
    font-size: 14px;
}
pre.text-output {
  font-size: 14px;
}
}

/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure img {
  width: 100%;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}



/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}


/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // create d-bibliography
  var bibliography = $('<d-bibliography></d-bibliography>');
  $('#distill-bibliography').wrap(bibliography);

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace citations with <d-cite>
  $('.citation').each(function(i, val) {
    appendix = true;
    var cites = $(this).attr('data-cites').split(" ");
    var dt_cite = $('<d-cite></d-cite>');
    dt_cite.attr('key', cites.join());
    $(this).replaceWith(dt_cite);
  });
  // remove refs
  $('#refs').remove();

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-toc a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // replace code blocks with d-code
  $('pre>code').each(function(i, val) {
    var code = $(this);
    var pre = code.parent();
    var clz = "";
    var language = pre.attr('class');
    if (language) {
      // map unknown languages to "clike" (without this they just dissapear)
      if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                               "javascript", "js", "julia", "lua", "markdown",
                               "markup", "mathml", "python", "svg", "xml"]) == -1)
        language = "clike";
      language = ' language="' + language + '"';
      var dt_code = $('<d-code block' + language + clz + '></d-code>');
      dt_code.text(code.text());
      pre.replaceWith(dt_code);
    } else {
      code.addClass('text-output').unwrap().changeElementType('pre');
    }
  });

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('d-code, pre.text-output, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // table of contents
    if (have_authors) // adjust border if we are in authors
      $('.d-toc').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
    $('d-code').each(function(i, val) {
      var style = document.createElement('style');
      style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                        '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
      if (this.shadowRoot)
        this.shadowRoot.appendChild(style);
    });

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-toc-header').remove();
  $('.d-toc').remove();
  $('.d-toc-separator').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/kePrint-0.0.1/kePrint.js"></script>
  <script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-79528685-1"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-79528685-1');
</script>
<style type="text/css">
@import url("pygment_highlights.css");
@import url(https://fonts.googleapis.com/css?family=Roboto:400,400italic,500,500italic,700,700italic,900,900italic,300italic,300,100italic,100);
@import url("https://fonts.googleapis.com/css?family=Roboto|Roboto+Mono|Roboto+Condensed|Lato|Lora|Fira+Sans");

/* latin-ext */
@font-face {
  font-family: 'Open Sans Condensed';
  font-style: normal;
  font-weight: 300;
  src: local('Open Sans Cond Light'), local('OpenSans-CondensedLight'), url(https://fonts.gstatic.com/s/opensanscondensed/v10/gk5FxslNkTTHtojXrkp-xC8hAQ4ocbp44gFQt8tMfcH3rGVtsTkPsbDajuO5ueQw.woff2) format('woff2');
  unicode-range: U+0100-024F, U+1E00-1EFF, U+20A0-20AB, U+20AD-20CF, U+2C60-2C7F, U+A720-A7FF;
}
/* latin */
@font-face {
  font-family: 'Open Sans Condensed';
  font-style: normal;
  font-weight: 300;
  src: local('Open Sans Cond Light'), local('OpenSans-CondensedLight'), url(https://fonts.gstatic.com/s/opensanscondensed/v10/gk5FxslNkTTHtojXrkp-xBEur64QvLD-0IbiAdTUNXE.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215;
}


body {
  font-family: Roboto, 'Libre Baskerville', sans-serif; /*, et-book, "Palatino Linotype", "Palatino LT STD", 'Lora', serif*/
  font-size: 15px;
  font-weight: 300;
  color: #404040;        /* #404040*/
  position: relative;
  background: #FFFFF8;      /* {{ site.page-col }}; */
  {% if site.page-img %}
  background-image: url({{ site.page-img }});
  background-attachment: fixed;
  {% endif %}
}

p {
  font-family: Roboto, 'Libre Baskerville', 'Helvetica Neue' ; /*, et-book, "Palatino Linotype", "Palatino LT STD", 'Lora', serif*/
  line-height: 1.5;
  font-weight: 300;
  margin: 30px 0;
}

p a {
  /* text-decoration: underline */
  color: #03b3ff;
}



/* link effects; possibly change to p a */
p a {
    color: #03b3ff;
    background-image: linear-gradient(180deg,transparent 90%, #FF4F03 0);
    background-size: 0 100%;
    background-repeat: no-repeat;
    text-decoration: none;
    -webkit-transition: background-size .4s ease;
    -moz-transition: background-size .4s ease;
    -ms-transition: background-size .4s ease;
    -o-transition: background-size .4s ease;
    transition: background-size .4s ease;
    border-bottom: 0px solid;
}

/* for twitter etc icon links */
.social-icon {
  color: #03b3ff;
  background-image: none;  /* remove hover line*/
  background-size: 0 100%;
  background-repeat: no-repeat;
  text-decoration: none;
  -webkit-transition: background-size .4s ease;
  -moz-transition: background-size .4s ease;
  -ms-transition: background-size .4s ease;
  -o-transition: background-size .4s ease;
  transition: background-size .4s ease;
  border-bottom: 0px solid;
}

li a {
    color: #03b3ff;
    background-image: linear-gradient(180deg,transparent 90%, #FF4F03 0);
    background-size: 0 100%;
    background-repeat: no-repeat;
    text-decoration: none;
    -webkit-transition: background-size .4s ease;
    -moz-transition: background-size .4s ease;
    -ms-transition: background-size .4s ease;
    -o-transition: background-size .4s ease;
    transition: background-size .4s ease;
    border-bottom: 0px solid;
}

.categories li > a:hover {
  border-bottom: none !important;
}

d-appendix a, d-appendix a:hover {
    color: #03b3ff !important;
    background-image: linear-gradient(180deg,transparent 90%, #FF4F03 0);
    background-size: 0 100%;
    background-repeat: no-repeat;
    text-decoration: none;
    -webkit-transition: background-size .4s ease;
    -moz-transition: background-size .4s ease;
    -ms-transition: background-size .4s ease;
    -o-transition: background-size .4s ease;
    transition: background-size .4s ease;
    border-bottom: 0px solid;  
}

d-article aside a, d-article aside a:hover {
    color: #03b3ff !important;
    background-image: linear-gradient(180deg,transparent 90%, #FF4F03 0);
    background-size: 0 100%;
    background-repeat: no-repeat;
    text-decoration: none;
    -webkit-transition: background-size .4s ease;
    -moz-transition: background-size .4s ease;
    -ms-transition: background-size .4s ease;
    -o-transition: background-size .4s ease;
    transition: background-size .4s ease;
    border-bottom: 0px solid;  
}



.img-cscar {
  width: 10%;
}


/* text highlights */
.emph {
  color: #E32D00 ;  /*#ff5500 #D14300*/
  font-weight: 450;
}

/* pack func and objclass colors initially come from hcl(seq(90,360, length.out=4), c=80, l=80); redone for contrast*/
.pack {
  color: #990071; /*#AC9CFF #e41a1c*/
  font-weight: 450;
}

.func {
  color: #007020;   /*#007199 #00CBB6; #984ea3; can just use `` instead*/
  font-weight: 450;
}

.objclass {
  color:  #947100;  /*#AAB400 #4daf4a; #FFC5D0*/
  font-weight: 450;
}

/* radix specific */

d-title h1 {
  font-family: 'Open Sans Condensed';
  font-weight: 200;
  font-size: 50px;
  color: #ff5500;
  margin-top: 4rem;
  margin-bottom: 1.5rem;
  line-height: 1;
}

d-article h1 {
  font-family: 'Open Sans Condensed';
  font-style: normal;
  font-weight: 400;
  font-size: 50px;
  color: #ff5500;
  margin-top: 2.1rem;
  margin-bottom: 1.2rem;
  line-height: 1;
}

d-article h2 {
  font-family: 'Open Sans Condensed';
  font-style: normal;
  font-weight: 400;
  font-size: 150%;
  color: #ff5500;
  margin-top: 2.1rem;
  margin-bottom: 1.2rem;
  line-height: 1;
}


.posts-list .post-preview h2 {
  font-family: 'Open Sans Condensed', -apple-system, BlinkMacSystemFont, Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  font-style: normal;
  font-weight: 400;
  font-size: 150%;
  color: #ff5500;
  margin-top: 2.1rem;
  margin-bottom: 1.2rem;
  line-height: 1;
}

.posts-list .description h2 {
  font-family: 'Open Sans Condensed', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  font-style: normal;
  font-weight: 400;
  font-size: 150%;
  color: #ff5500;
  margin-top: 2.1rem;
  margin-bottom: 1.2rem;
  line-height: 1;
}



d-article h3 {
  font-family: 'Open Sans Condensed';
  font-style: normal;
  font-weight: 400;
  font-size: 125%;
  color: #ff5500;
  opacity: .9;
  margin-top: 2rem;
  margin-bottom: 1.2rem;
  line-height: 1;
}

d-article  h4 {
  font-family: 'Open Sans Condensed';
  font-variant: normal;
  font-weight: 400;
  font-size: 110%;
  color: #ff5500;
  opacity: .9;
  margin-top: 1.9rem;
  margin-bottom: 1.2rem;
  line-height: 1;
}

d-article  h5 {
  font-family: 'Open Sans Condensed';
  font-variant: normal;
  font-weight: 400;
  font-size: 100%;
  color: #ff5500;
  opacity: .9;
  margin-top: 1.9rem;
  margin-bottom: 1.2rem;
  line-height: 1;
}



d-article a:hover {
  text-decoration: none;
  border-bottom: none;
  background-size: 100% 100%;
  cursor: pointer;
}

/* changing this will bork the phone; revisit later
.base-grid, distill-header, d-title, d-abstract, d-article, d-appendix, distill-appendix, d-byline, d-footnote-list, d-citation-list, distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 80px [text-start kicker-end] 80px 80px 80px 80px 80px 80px 80px 80px [text-end gutter-start] 80px [middle-end] 80px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
}
*/

.distill-site-nav {
  color: #404040;
  background-color: #d9edf7;
  font-size: 20px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: #0085a1;
}

.distill-site-header {
}

.distill-site-footer {
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.posts-list .post-preview .thumbnail img {
    width: 100%;
    background: transparent;
    display: block;
}

/* latex */
.math {
  color: #404040;  
  font-weight: normal;
  font-size: 90%;
}

/* code */

/* this is the code from selector for a code block, but doesn't do anything */

code #code-container .language-clike {
  font-family: 'Roboto Mono', Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}

code[class*="language-"], pre[class*="language-"] {
    color: black;
    background: none;
    text-shadow: 0 1px white;
    font-family: 'Roboto Mono', Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    font-size: 50%;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
}


/* will only affect inline*/
code {
  font-family: 'Roboto Mono', Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  font-size: 90%;
}

/* code results/output */
pre.text-output {
  font-family: 'Roboto Mono', Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}


/* is read to a point, only the space before the code */
d-code {
  font-family: 'Roboto Mono', Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  font-size: 100%;
}



/* this is literally the css path copied from firefox dev tools, useless */
code#code-container.language-clike {
  font-size: 500%;
  color: red;
}

#shadowroot pre code#code-container.language-clike {
  font-size: 500%;
  color: red;
}

.token.function {
  font-size: 200%;
}

pre, xmp, plaintext, listing {
    display: block;
    font-family: 'Roboto Mono', Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    white-space: pre;
    margin: 1em 0px;
}

/* to fix aside; see issue #39 https://github.com/rstudio/distill/issues/39*/ 
@media(min-width:768px) {
  aside {
      margin-top: -00px;
      margin-bottom: -500px;
  }
}


/* images */
img {
  background: transparent;
}

/* list */

ul {
  list-style: none; /* Remove default bullets */
}

ul li::before {
  content: "\2022";  /* Add content: \2022 is the CSS Code/unicode for a bullet */
  color: #ff5500BF; /* Change the color */
  size: 5;
  font-weight: bold; /* If you want it to be bold */
  display: inline-block; /* Needed to add space between the bullet and the text */
  width: 1em; /* Also needed for space (tweak if needed) */
  /*margin-left: 0em;  Also needed for space (tweak if needed) */
}



/* main part on front page with description */

/*

.posts-with-sidebar .posts-list {
  float: left;
  width: 72%;
}

.posts-list {
  margin-top: 60px;
  margin-bottom: 24px;
}

*/

/* sidebar on front page with category listing */

.posts-with-sidebar .posts-sidebar {
  float: right;
  width: 10%;    /* default 20, made narrow */
  margin-top: 60px;
  padding-top: 24px;
  padding-bottom: 24px;
}

/* attempt to make result not so wide/spacious */ 
.posts-with-sidebar .posts-list {
  width: 66% !important;
  margin-left: 11%;
}

.posts-sidebar {
  font-size: 16px;
}

</style>
<!--/radix_placeholder_site_in_header-->

  <link rel="stylesheet" href="..\..\styles.css" type="text/css"/>

</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Mixed Models for Big Data","description":"Explorations of a fast penalized regression approach with mgcv","authors":[{"author":"Michael Clark","authorURL":"https://m-clark.github.io","affiliation":"&nbsp;","affiliationURL":"#"}],"publishedDate":"2019-10-20T00:00:00.000-04:00","citationText":"Clark, 2019"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<span class="logo">
<img src="../../img/lcsq.png"/>
</span>
<a href="../../index.html" class="title">Michael Clark</a>
</div>
<div class="nav-right">
<a href="../../index.html">Home</a>
<a href="../../about.html">About</a>
<a href="../../documents.html">Documents</a>
<a href="../../workshops.html">Workshops</a>
<a href="../../code.html">Code</a>
<a href="../../misc.html">Odds/Ends</a>
<a href="../../projects.html">Projects</a>
<a href="../../resources.html">Resources</a>
<a href="https://github.com/m-clark">
<i class="fab fa-github-alt fa-1x"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Mixed Models for Big Data</h1>
<p><p>Explorations of a fast penalized regression approach with mgcv</p></p>
</div>

<div class="d-byline">
  Michael Clark <a href="https://m-clark.github.io" class="uri">https://m-clark.github.io</a> 
  
<br/>2019-10-20
</div>

<div class="d-article">
<h3 class="d-toc-header">Table of Contents</h3>
<nav class="d-toc" id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#r-packages-for-mixed-models-with-large-data">R Packages for Mixed Models with Large Data</a></li>
<li><a href="#additive-models-as-mixed-models">Additive Models as Mixed Models</a><ul>
<li><a href="#comparison-of-gam-to-the-mixed-model">Comparison of GAM to the Mixed Model</a></li>
<li><a href="#the-bam-approach">The bam approach</a></li>
<li><a href="#fixed-effects-comparison">Fixed effects comparison</a></li>
<li><a href="#variance-components-comparison">Variance components comparison</a></li>
<li><a href="#estimated-random-effects">Estimated random effects</a></li>
<li><a href="#comparisons-to-bayesian-estimates">Comparisons to Bayesian Estimates</a></li>
</ul></li>
<li><a href="#back-to-the-initial-problem">Back to the initial problem</a></li>
<li><a href="#when-to-use-bam">When to use bam</a><ul>
<li><a href="#linear-mixed-models">Linear Mixed Models</a></li>
<li><a href="#generalized-linear-mixed-models">Generalized Linear Mixed Models</a></li>
<li><a href="#other-options">Other options</a></li>
</ul></li>
<li><a href="#limitations">Limitations</a></li>
<li><a href="#summary">Summary</a></li>
<li><a href="#supplemental">Supplemental</a><ul>
<li><a href="#simulation-settings">Simulation Settings</a></li>
</ul></li>
</ul>
</nav>
<hr class="d-toc-separator"/>
<aside>
Last updated October 21, 2019.
</aside>
<h2 id="introduction">Introduction</h2>
<p>With mixed models, it is easy to run into data that is larger in size than some more typical data scenarios. Consider a cross-sectional data set with 200 individuals. This is fairly small data. Now, if we observe them each five times, as in a longitudinal setting, we suddenly have 1000 observations. There may be less than 200 countries in the world, but if we survey 100s or 1000s of people in many of them, we suddenly have a notable data set size, and still would potentially like to model a country-level random effect. What are our options when dealing with possibly gigabytes of data?</p>
<p>This post will demonstrate an approach that can be used with potentially millions of data points, multiple random effects, and possibly other complexities. First we’ll demonstrate how to get typical mixed model results using the approach used for generalized additive models. We’ll compare the output of the GAM, lme4, and even fully Bayesian mixed models. Then we’ll show some timings to compare the speed of the different approaches of common tools, and summarize some findings from other places.</p>
<aside>
<p>Background required:</p>
For the following you should have familiarity with <a href="https://m-clark.github.io/mixed-models-with-R/">mixed models</a>. Knowledge of the <span class="pack" style="">lme4</span> package would be useful but isn’t required. Likewise, knowledge of <a href="https://m-clark.github.io/generalized-additive-models/">generalized additive models</a> and <span class="pack" style="">mgcv</span> would be helpful, but I don’t think it’s required to follow the demonstration.
</aside>
<h2 id="r-packages-for-mixed-models-with-large-data">R Packages for Mixed Models with Large Data</h2>
<p>While many tools abound to conduct mixed models for larger data sizes, their limitations can be found pretty quickly. R’s <span class="pack" style="">lme4</span> is a standard, but powerful mixed model tool. More to the point, it is computationally efficient, such that it can handle very large sample sizes for simpler mixed models. For linear mixed models this can include hundreds of thousands of observations with possibly multiple random effects, still running on a basic laptop. For such models, it’s still largely the tool of choice, and its approach has even been copied/ported into other statistical packages.</p>
<p>We’ll first create some data to model. This is just a simple random intercepts setting.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
set.seed(12358)
N = 1e6                                  # total sample size
n_groups = 1000                          # number of groups
g = rep(1:n_groups, e = N/n_groups)      # the group identifier

x = rnorm(N)                             # an observation level continuous variable
b = rbinom(n_groups, size = 1, prob=.5)  # a cluster level categorical variable
b = b[g]

sd_g = .5     # standard deviation for the random effect
sigma = 1     # standard deviation for the observation

re0 = rnorm(n_groups, sd = sd_g)  # random effects
re  = re0[g]

lp = 0 + .5*x + .25*b + re        # linear predictor 

y = rnorm(N, mean = lp, sd = sigma)               # create a continuous target variable
y_bin = rbinom(N, size = 1, prob = plogis(lp))    # create a binary target variable

d = tibble(x, b, y, y_bin, g = factor(g))</code></pre>
</div>
<p><br></p>
<p>Let’s take a look at the data first.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
index
</th>
<th style="text-align:right;">
x
</th>
<th style="text-align:right;">
b
</th>
<th style="text-align:right;">
y
</th>
<th style="text-align:right;">
y_bin
</th>
<th style="text-align:left;">
g
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-0.378
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.278
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
-0.812
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.343
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0.218
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.810
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
1.529
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.465
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
-1.877
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-1.570
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
-0.427
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.047
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
999995
</td>
<td style="text-align:right;">
-1.181
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-1.111
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
1000
</td>
</tr>
<tr>
<td style="text-align:right;">
999996
</td>
<td style="text-align:right;">
-1.487
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.563
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
1000
</td>
</tr>
<tr>
<td style="text-align:right;">
999997
</td>
<td style="text-align:right;">
-1.236
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-0.603
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
1000
</td>
</tr>
<tr>
<td style="text-align:right;">
999998
</td>
<td style="text-align:right;">
0.412
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.736
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
1000
</td>
</tr>
<tr>
<td style="text-align:right;">
999999
</td>
<td style="text-align:right;">
-0.644
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-1.257
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
1000
</td>
</tr>
<tr>
<td style="text-align:right;">
1000000
</td>
<td style="text-align:right;">
0.409
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.520
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
1000
</td>
</tr>
</tbody>
</table>
</div>
<p>Now with the data in place, let’s try <span class="pack" style="">lme4</span> to model the continuous outcome.</p>
<aside>
The time to focus on is <code>elapsed</code>, which is the number of seconds the function took to run.
</aside>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(lme4)

system.time({
  mixed_big = lmer(y ~ x + b + (1|g))
})</code></pre>
<pre><code>
   user  system elapsed 
   8.35    1.25    9.64 </code></pre>
<pre class="r"><code>
summary(mixed_big, cor = FALSE)</code></pre>
<pre><code>
Linear mixed model fit by REML [&#39;lmerMod&#39;]
Formula: y ~ x + b + (1 | g)

REML criterion at convergence: 2841256

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-4.6066 -0.6743 -0.0004  0.6744  5.0367 

Random effects:
 Groups   Name        Variance Std.Dev.
 g        (Intercept) 0.2509   0.5009  
 Residual             0.9978   0.9989  
Number of obs: 1000000, groups:  g, 1000

Fixed effects:
             Estimate Std. Error t value
(Intercept) 0.0364754  0.0223332   1.633
x           0.5017616  0.0009987 502.409
b           0.1904534  0.0317430   6.000</code></pre>
</div>
<p>This is great! We just ran a mixed model for 1,000,000 observations and 1,000 groups for our random effect in just a few seconds.</p>
<p>But one problem comes as soon as you move to the generalized mixed model, e.g. having a binary outcome, or include additional complexity while still dealing with large data. The following is essentially the same model, but for a binary outcome.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
system.time({
  mixed_big_glmm = glmer(y_bin ~ x + b + (1|g), family = binomial)
})</code></pre>
<pre><code>
   user  system elapsed 
 235.84   44.18  280.60 </code></pre>
</div>
<p>To begin with, you shouldn’t be worried about models taking a few minutes to run, or even a couple hours. Once you have your model(s) squared away, the testing of which can be done on a smaller sample of the data set, there is no need to repeatedly run it. But in this case we had a greater than 15 fold increase in time for a very simple data scenario. So it’s good to have options when you need them. Let’s turn to those.</p>
<h2 id="additive-models-as-mixed-models">Additive Models as Mixed Models</h2>
<p>Simon Wood’s wonderful work on generalized additive models (GAM) and the <span class="pack" style="">mgcv</span> package make it one of the better modeling tools in the R kingdom. As his text<span class="citation" data-cites="wood_generalized_2017">(S. N. Wood <a href="#ref-wood_generalized_2017" role="doc-biblioref">2017</a>)</span> and other work shows, additive models constructed be posited in a similar way as mixed models, and he exploits this by providing numerous ways to include and explore random effects in the GAM approach. One key difference between the GAM and a standard linear mixed model approach is the way parameters are estimated. For the GAM, the random effects are estimated as are other fixed effect coefficients. Those random effects are penalized, in a similar way as L2/ridge regression. The ‘fixed effects’ are not penalized, and so that part is basically just a generalized linear model. As we will see though, the results will be nearly the same between <span class="pack" style="">mgcv</span> and <span class="pack" style="">lme4</span>.</p>
<p>The following demonstrates the link between the approaches by showing a model that includes a random intercept and slope. We will use the standard <span class="pack" style="">mgcv</span> approach for specifying a smooth term, but alternatives are shown for those familiar with the package.</p>
<aside>
If you just use <span class="func" style="">coef</span> on the following gam objects, you will see that the random effects are lumped in with the other estimated coefficients.
</aside>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(lme4)
library(mgcv)

mixed_model = lmer(
  Reaction ~ Days + (1 | Subject) + (0 + Days | Subject),
  data = sleepstudy
)

ga_model = gam(
  Reaction ~  Days + s(Subject, bs = &#39;re&#39;) + s(Days, Subject, bs = &#39;re&#39;),
  data = sleepstudy,
  method = &#39;REML&#39;
)

# Using gamm and gamm4 for the same model
# ga_model = gamm(
#   Reaction ~  Days ,
#   random = list(Subject = ~ 0 + Days),
#   data = sleepstudy,
#   method = &#39;REML&#39;
# )
# 
# ga_model = gamm4::gamm4(
#   Reaction ~  Days,
#   random =  ~ (Days||Subject),
#   data = sleepstudy,
#   REML = TRUE
# )</code></pre>
</div>
<p>Note that we use <span class="func" style="">s</span> to denote a <span class="emph" style="">smooth term</span> in the parlance of additive models, and the <code>bs = 're'</code> specifies that we want it as a random effect (as opposed to a spline or other basis function). The second smooth term <code>s(Days, Subject, bs = 're')</code> denotes random coefficients for the <code>Days</code> covariate.</p>
<aside>
As shown, one could use the <span class="func" style="">gamm</span> function for the <span class="pack" style="">nlme</span> style, or Wood’s <span class="pack" style="">gamm4</span> package to use the <span class="pack" style="">lme4</span> syntax. These alternate approaches allow for more flexibility in some ways, but will not be useful to us for big data.
</aside>
<h3 id="comparison-of-gam-to-the-mixed-model">Comparison of GAM to the Mixed Model</h3>
<p>Aside from the syntax, the underlying model between the two is the same, and the following shows that we obtain the same results for both <span class="pack" style="">lme4</span> and <span class="pack" style="">mgcv</span>.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
summary(mixed_model, cor = FALSE)</code></pre>
<pre><code>
Linear mixed model fit by REML [&#39;lmerMod&#39;]
Formula: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
   Data: sleepstudy

REML criterion at convergence: 1743.7

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.9626 -0.4626  0.0204  0.4653  5.1860 

Random effects:
 Groups    Name        Variance Std.Dev.
 Subject   (Intercept) 627.50   25.050  
 Subject.1 Days         35.86    5.989  
 Residual              653.58   25.565  
Number of obs: 180, groups:  Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.885  36.514
Days          10.467      1.560   6.711</code></pre>
<pre class="r"><code>
summary(ga_model)</code></pre>
<pre><code>
Family: gaussian 
Link function: identity 

Formula:
Reaction ~ Days + s(Subject, bs = &quot;re&quot;) + s(Days, Subject, bs = &quot;re&quot;)

Parametric coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  251.405      6.885  36.513  &lt; 2e-16 ***
Days          10.467      1.560   6.712 3.67e-10 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Approximate significance of smooth terms:
                  edf Ref.df      F  p-value    
s(Subject)      12.94     17  89.29 4.56e-07 ***
s(Days,Subject) 14.41     17 104.56 1.82e-12 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

R-sq.(adj) =  0.794   Deviance explained = 82.7%
-REML = 871.83  Scale est. = 653.58    n = 180</code></pre>
</div>
<p>I don’t want to go into the details of the printout for <span class="pack" style="">mgcv</span>, but it is worth noting that the parametric part is equivalent to the fixed effects portion of the <span class="pack" style="">lme4</span> output. Likewise the smooth terms output is related to the random effects, but we’ll extract them in a manner more suited to typical mixed model output instead. So let’s compare the variance components, and get them ready for later comparison to <span class="func" style="">bam</span> results. Note, I’ve been using <span class="pack" style="">mgcv</span> a lot for mixed models lately, so I created a package called <span class="pack" style="">gammit</span> to provide tidier output in general, and which is more similar to <span class="pack" style="">lme4</span>. I note the corresponding <span class="pack" style="">mgcv</span> function where appropriate.</p>
<aside>
The <span class="pack" style="">gammit</span> package is available on <a href="https://github.com/m-clark/gammit">GitHub</a>.
</aside>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(gammit)

# extract just the fixed effects for later.
mixed_fe = fixef(mixed_model)
gam_fe   = extract_fixed(ga_model)  # coefs with se and confidence interval

# variance components
lmer_vcov = data.frame(VarCorr(mixed_model))
gam_vcov  = extract_vc(ga_model)    # cleaner gam.vcomp</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:initial-vc-show">Table 1: </span>LME Result
</caption>
<thead>
<tr>
<th style="text-align:left;">
grp
</th>
<th style="text-align:left;">
var1
</th>
<th style="text-align:right;">
vcov
</th>
<th style="text-align:right;">
sdcor
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
627.500
</td>
<td style="text-align:right;">
25.050
</td>
</tr>
<tr>
<td style="text-align:left;">
Subject.1
</td>
<td style="text-align:left;">
Days
</td>
<td style="text-align:right;">
35.864
</td>
<td style="text-align:right;">
5.989
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:right;">
653.580
</td>
<td style="text-align:right;">
25.565
</td>
</tr>
</tbody>
</table>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:initial-vc-show">Table 1: </span>GAM Result
</caption>
<thead>
<tr>
<th style="text-align:left;">
component
</th>
<th style="text-align:right;">
std.dev
</th>
<th style="text-align:right;">
lower
</th>
<th style="text-align:right;">
upper
</th>
<th style="text-align:right;">
variance
</th>
<th style="text-align:right;">
proportion
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
25.051
</td>
<td style="text-align:right;">
16.085
</td>
<td style="text-align:right;">
39.015
</td>
<td style="text-align:right;">
627.571
</td>
<td style="text-align:right;">
0.477
</td>
</tr>
<tr>
<td style="text-align:left;">
Days|Subject
</td>
<td style="text-align:right;">
5.988
</td>
<td style="text-align:right;">
4.025
</td>
<td style="text-align:right;">
8.908
</td>
<td style="text-align:right;">
35.858
</td>
<td style="text-align:right;">
0.027
</td>
</tr>
<tr>
<td style="text-align:left;">
scale
</td>
<td style="text-align:right;">
25.565
</td>
<td style="text-align:right;">
22.792
</td>
<td style="text-align:right;">
28.676
</td>
<td style="text-align:right;">
653.582
</td>
<td style="text-align:right;">
0.496
</td>
</tr>
</tbody>
</table>
</div>
<aside>
The penalty parameter in the GAM model is inversely related to the variance estimate of the random effects. See <a href="https://m-clark.github.io/generalized-additive-models/appendix.html#a-comparison-to-mixed-models">this demo</a>.
</aside>
<h3 id="the-bam-approach">The bam approach</h3>
<p>For large data, <span class="pack" style="">mgcv</span> provides the <span class="func" style="">bam</span> function. For this small data setting we don’t really need it, but we can establish that we would get similar results using it without having to wait. We will see the benefits when we apply <span class="func" style="">bam</span> to large data later. None of our syntax changes, just the function.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
ba_model = bam(
  Reaction ~  Days + s(Subject, bs=&#39;re&#39;) + s(Days, Subject, bs=&#39;re&#39;), 
  data = sleepstudy
)

bam_fe   = extract_fixed(ba_model)
bam_vcov = extract_vc(ba_model)</code></pre>
</div>
<p>How does it work? The function uses a parallelized approach where possible, essentially working on subsets of the model matrices simultaneously. Details can be found in the references<span class="citation" data-cites="li_faster_2019">(Li and Wood <a href="#ref-li_faster_2019" role="doc-biblioref">2019</a>)</span><span class="citation" data-cites="wood_generalized_2015">(S. N. Wood, Goude, and Shaw <a href="#ref-wood_generalized_2015" role="doc-biblioref">2015</a><a href="#ref-wood_generalized_2015" role="doc-biblioref">a</a>)</span><span class="citation" data-cites="wood_generalized_2017-1">(S. N. Wood et al. <a href="#ref-wood_generalized_2017-1" role="doc-biblioref">2017</a>)</span>, but basically <span class="pack" style="">mgcv</span> parallelizes the parts that can be, and additionally provides an option to discretize the data to work with the minimal information necessary to produce viable estimates. The following uses the discrete option. As there isn’t really anything to discretize with so little data, this is just to demonstrate the syntax.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
ba_d_model = bam(
  Reaction ~  Days + s(Subject, bs=&#39;re&#39;) + s(Days, Subject, bs=&#39;re&#39;), 
  data = sleepstudy,
  discrete = TRUE
)

bam_d_fe   = extract_fixed(ba_d_model)
bam_d_vcov = extract_vc(ba_d_model)</code></pre>
</div>
<h3 id="fixed-effects-comparison">Fixed effects comparison</h3>
<p>We start by comparing the fixed effects of all models run thus far. No surprises here, the results are the same.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:compare-fixef">Table 2: </span>Fixed Effects Estimates
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:right;">
Intercept
</th>
<th style="text-align:right;">
Days
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
mixed
</td>
<td style="text-align:right;">
251.405
</td>
<td style="text-align:right;">
10.467
</td>
</tr>
<tr>
<td style="text-align:left;">
gam
</td>
<td style="text-align:right;">
251.405
</td>
<td style="text-align:right;">
10.467
</td>
</tr>
<tr>
<td style="text-align:left;">
bam
</td>
<td style="text-align:right;">
251.405
</td>
<td style="text-align:right;">
10.467
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_d
</td>
<td style="text-align:right;">
251.405
</td>
<td style="text-align:right;">
10.467
</td>
</tr>
</tbody>
</table>
</div>
<p>Let’s examine the standard errors. Note that there are options for the GAM models for standard error estimation, including a Bayesian one. For more details, see <code>?gamObject</code>, but I will offer the summary:</p>
<h5 id="ve">Ve</h5>
<p>frequentist estimated covariance matrix for the parameter estimators. Particularly useful for testing whether terms are zero. Not so useful for CI’s as smooths are usually biased.</p>
<h5 id="vp">Vp</h5>
<p>estimated covariance matrix for the parameters. This is a Bayesian posterior covariance matrix that results from adopting a particular Bayesian model of the smoothing process. Particularly useful for creating credible/confidence intervals.</p>
<h5 id="vc">Vc</h5>
<p>Under ML or REML smoothing parameter estimation it is possible to correct the covariance matrix Vp for smoothing parameter uncertainty. This is the corrected version.</p>
<p>We will use the Bayesian estimates (<code>Vp</code>), but for this setting there are no appreciable differences. I expand the digits to show they are in fact different to some decimal place.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:compare-fixef-se">Table 3: </span>Fixed Effects Standard Errors
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:right;">
Intercept
</th>
<th style="text-align:right;">
Days
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
mixed
</td>
<td style="text-align:right;">
6.88510
</td>
<td style="text-align:right;">
1.55967
</td>
</tr>
<tr>
<td style="text-align:left;">
gam
</td>
<td style="text-align:right;">
6.88540
</td>
<td style="text-align:right;">
1.55956
</td>
</tr>
<tr>
<td style="text-align:left;">
bam
</td>
<td style="text-align:right;">
6.88538
</td>
<td style="text-align:right;">
1.55957
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_d
</td>
<td style="text-align:right;">
6.88538
</td>
<td style="text-align:right;">
1.55957
</td>
</tr>
</tbody>
</table>
</div>
<h3 id="variance-components-comparison">Variance components comparison</h3>
<p>Now we move to the variance component estimates. Reported are the standard deviations for subject level random effects for intercept, <code>Days</code> coefficient, and residual.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:compare-vc">Table 4: </span>Variance Components Estimates
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Intercept
</th>
<th style="text-align:right;">
Days
</th>
<th style="text-align:right;">
Residual
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
mixed
</td>
<td style="text-align:right;">
25.050
</td>
<td style="text-align:right;">
5.989
</td>
<td style="text-align:right;">
25.565
</td>
</tr>
<tr>
<td style="text-align:left;">
gam
</td>
<td style="text-align:right;">
25.051
</td>
<td style="text-align:right;">
5.988
</td>
<td style="text-align:right;">
25.565
</td>
</tr>
<tr>
<td style="text-align:left;">
bam
</td>
<td style="text-align:right;">
25.051
</td>
<td style="text-align:right;">
5.988
</td>
<td style="text-align:right;">
25.565
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_d
</td>
<td style="text-align:right;">
25.051
</td>
<td style="text-align:right;">
5.988
</td>
<td style="text-align:right;">
25.565
</td>
</tr>
</tbody>
</table>
</div>
<p>We can also look at their interval estimates. We use the profile likelihood for the <span class="pack" style="">lme4</span> mixed model. In this case we can see slightly wider and somewhat different boundary estimates for the variance components, but not too dissimilar.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:compare-vc-int-table">Table 5: </span>Interval Estimates for Variance Components
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
component
</th>
<th style="text-align:right;">
lower
</th>
<th style="text-align:right;">
upper
</th>
<th style="text-align:right;">
width
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;vertical-align: top !important;" rowspan="3">
mixed
</td>
<td style="text-align:left;">
Intercept
</td>
<td style="text-align:right;">
15.2587
</td>
<td style="text-align:right;">
37.7865
</td>
<td style="text-align:right;">
22.5279
</td>
</tr>
<tr>
<td style="text-align:left;">
Days
</td>
<td style="text-align:right;">
3.9641
</td>
<td style="text-align:right;">
8.7691
</td>
<td style="text-align:right;">
4.8051
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:right;">
22.8806
</td>
<td style="text-align:right;">
28.7876
</td>
<td style="text-align:right;">
5.9070
</td>
</tr>
<tr>
<td style="text-align:left;vertical-align: top !important;" rowspan="3">
gam
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
16.0854
</td>
<td style="text-align:right;">
39.0150
</td>
<td style="text-align:right;">
22.9297
</td>
</tr>
<tr>
<td style="text-align:left;">
Days|Subject
</td>
<td style="text-align:right;">
4.0252
</td>
<td style="text-align:right;">
8.9083
</td>
<td style="text-align:right;">
4.8830
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:right;">
22.7917
</td>
<td style="text-align:right;">
28.6763
</td>
<td style="text-align:right;">
5.8845
</td>
</tr>
<tr>
<td style="text-align:left;vertical-align: top !important;" rowspan="3">
bam
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
16.0853
</td>
<td style="text-align:right;">
39.0150
</td>
<td style="text-align:right;">
22.9297
</td>
</tr>
<tr>
<td style="text-align:left;">
Days|Subject
</td>
<td style="text-align:right;">
4.0253
</td>
<td style="text-align:right;">
8.9083
</td>
<td style="text-align:right;">
4.8830
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:right;">
22.7918
</td>
<td style="text-align:right;">
28.6763
</td>
<td style="text-align:right;">
5.8845
</td>
</tr>
<tr>
<td style="text-align:left;vertical-align: top !important;" rowspan="3">
bam_d
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
16.0853
</td>
<td style="text-align:right;">
39.0150
</td>
<td style="text-align:right;">
22.9297
</td>
</tr>
<tr>
<td style="text-align:left;">
Days|Subject
</td>
<td style="text-align:right;">
4.0253
</td>
<td style="text-align:right;">
8.9083
</td>
<td style="text-align:right;">
4.8830
</td>
</tr>
<tr>
<td style="text-align:left;">
Residual
</td>
<td style="text-align:right;">
22.7918
</td>
<td style="text-align:right;">
28.6763
</td>
<td style="text-align:right;">
5.8845
</td>
</tr>
</tbody>
</table>
</div>
<h3 id="estimated-random-effects">Estimated random effects</h3>
<p>Now let’s look at the random effect estimates.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
mixed_re = ranef(mixed_model)[[1]] %&gt;% 
  rename(mixed_Subject = `(Intercept)`, `mixed_Days|Subject` = Days)

gam_re_init   = extract_ranef(ga_model)
bam_re_init   = extract_ranef(ba_model)
bam_d_re_init = extract_ranef(ba_d_model)</code></pre>
</div>
<p>We’ll start with the random effects for the intercept. To several decimal places, we start to see differences, so again we know they aren’t doing exactly the same thing, but they are coming to the same conclusion.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:re-int">Table 6: </span>Estimated Random Intercepts
</caption>
<thead>
<tr>
<th style="text-align:right;">
mixed_Subject
</th>
<th style="text-align:right;">
gam_Subject
</th>
<th style="text-align:right;">
bam_Subject
</th>
<th style="text-align:right;">
bam_d_Subject
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1.51170
</td>
<td style="text-align:right;">
1.51272
</td>
<td style="text-align:right;">
1.51270
</td>
<td style="text-align:right;">
1.51270
</td>
</tr>
<tr>
<td style="text-align:right;">
-40.37201
</td>
<td style="text-align:right;">
-40.37397
</td>
<td style="text-align:right;">
-40.37390
</td>
<td style="text-align:right;">
-40.37390
</td>
</tr>
<tr>
<td style="text-align:right;">
-39.17951
</td>
<td style="text-align:right;">
-39.18111
</td>
<td style="text-align:right;">
-39.18104
</td>
<td style="text-align:right;">
-39.18104
</td>
</tr>
<tr>
<td style="text-align:right;">
24.51881
</td>
<td style="text-align:right;">
24.51893
</td>
<td style="text-align:right;">
24.51890
</td>
<td style="text-align:right;">
24.51890
</td>
</tr>
<tr>
<td style="text-align:right;">
22.91419
</td>
<td style="text-align:right;">
22.91446
</td>
<td style="text-align:right;">
22.91443
</td>
<td style="text-align:right;">
22.91443
</td>
</tr>
<tr>
<td style="text-align:right;">
9.22178
</td>
<td style="text-align:right;">
9.22199
</td>
<td style="text-align:right;">
9.22197
</td>
<td style="text-align:right;">
9.22197
</td>
</tr>
<tr>
<td style="text-align:right;">
17.15572
</td>
<td style="text-align:right;">
17.15614
</td>
<td style="text-align:right;">
17.15612
</td>
<td style="text-align:right;">
17.15612
</td>
</tr>
<tr>
<td style="text-align:right;">
-7.45166
</td>
<td style="text-align:right;">
-7.45174
</td>
<td style="text-align:right;">
-7.45173
</td>
<td style="text-align:right;">
-7.45173
</td>
</tr>
<tr>
<td style="text-align:right;">
0.57984
</td>
<td style="text-align:right;">
0.57870
</td>
<td style="text-align:right;">
0.57872
</td>
<td style="text-align:right;">
0.57872
</td>
</tr>
<tr>
<td style="text-align:right;">
34.76617
</td>
<td style="text-align:right;">
34.76800
</td>
<td style="text-align:right;">
34.76793
</td>
<td style="text-align:right;">
34.76793
</td>
</tr>
<tr>
<td style="text-align:right;">
-25.75382
</td>
<td style="text-align:right;">
-25.75436
</td>
<td style="text-align:right;">
-25.75432
</td>
<td style="text-align:right;">
-25.75432
</td>
</tr>
<tr>
<td style="text-align:right;">
-13.86539
</td>
<td style="text-align:right;">
-13.86504
</td>
<td style="text-align:right;">
-13.86504
</td>
<td style="text-align:right;">
-13.86504
</td>
</tr>
<tr>
<td style="text-align:right;">
4.91618
</td>
<td style="text-align:right;">
4.91598
</td>
<td style="text-align:right;">
4.91598
</td>
<td style="text-align:right;">
4.91598
</td>
</tr>
<tr>
<td style="text-align:right;">
20.92816
</td>
<td style="text-align:right;">
20.92908
</td>
<td style="text-align:right;">
20.92904
</td>
<td style="text-align:right;">
20.92904
</td>
</tr>
<tr>
<td style="text-align:right;">
3.25848
</td>
<td style="text-align:right;">
3.25865
</td>
<td style="text-align:right;">
3.25865
</td>
<td style="text-align:right;">
3.25865
</td>
</tr>
<tr>
<td style="text-align:right;">
-26.47568
</td>
<td style="text-align:right;">
-26.47585
</td>
<td style="text-align:right;">
-26.47583
</td>
<td style="text-align:right;">
-26.47583
</td>
</tr>
<tr>
<td style="text-align:right;">
0.90573
</td>
<td style="text-align:right;">
0.90565
</td>
<td style="text-align:right;">
0.90565
</td>
<td style="text-align:right;">
0.90565
</td>
</tr>
<tr>
<td style="text-align:right;">
12.42132
</td>
<td style="text-align:right;">
12.42178
</td>
<td style="text-align:right;">
12.42176
</td>
<td style="text-align:right;">
12.42176
</td>
</tr>
</tbody>
</table>
</div>
<p>Random effects for the Days coefficient.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:re-days">Table 7: </span>Estimated Random Effects
</caption>
<thead>
<tr>
<th style="text-align:right;">
mixed_Days|Subject
</th>
<th style="text-align:right;">
gam_Days|Subject
</th>
<th style="text-align:right;">
bam_Days|Subject
</th>
<th style="text-align:right;">
bam_d_Days|Subject
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
9.32373
</td>
<td style="text-align:right;">
9.32348
</td>
<td style="text-align:right;">
9.32349
</td>
<td style="text-align:right;">
9.32349
</td>
</tr>
<tr>
<td style="text-align:right;">
-8.59954
</td>
<td style="text-align:right;">
-8.59916
</td>
<td style="text-align:right;">
-8.59917
</td>
<td style="text-align:right;">
-8.59917
</td>
</tr>
<tr>
<td style="text-align:right;">
-5.38807
</td>
<td style="text-align:right;">
-5.38778
</td>
<td style="text-align:right;">
-5.38779
</td>
<td style="text-align:right;">
-5.38779
</td>
</tr>
<tr>
<td style="text-align:right;">
-4.96868
</td>
<td style="text-align:right;">
-4.96865
</td>
<td style="text-align:right;">
-4.96865
</td>
<td style="text-align:right;">
-4.96865
</td>
</tr>
<tr>
<td style="text-align:right;">
-3.19393
</td>
<td style="text-align:right;">
-3.19394
</td>
<td style="text-align:right;">
-3.19393
</td>
<td style="text-align:right;">
-3.19393
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.30847
</td>
<td style="text-align:right;">
-0.30850
</td>
<td style="text-align:right;">
-0.30849
</td>
<td style="text-align:right;">
-0.30849
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.28715
</td>
<td style="text-align:right;">
-0.28721
</td>
<td style="text-align:right;">
-0.28721
</td>
<td style="text-align:right;">
-0.28721
</td>
</tr>
<tr>
<td style="text-align:right;">
1.11599
</td>
<td style="text-align:right;">
1.11599
</td>
<td style="text-align:right;">
1.11599
</td>
<td style="text-align:right;">
1.11599
</td>
</tr>
<tr>
<td style="text-align:right;">
-10.90624
</td>
<td style="text-align:right;">
-10.90596
</td>
<td style="text-align:right;">
-10.90597
</td>
<td style="text-align:right;">
-10.90597
</td>
</tr>
<tr>
<td style="text-align:right;">
8.62796
</td>
<td style="text-align:right;">
8.62760
</td>
<td style="text-align:right;">
8.62762
</td>
<td style="text-align:right;">
8.62762
</td>
</tr>
<tr>
<td style="text-align:right;">
1.28063
</td>
<td style="text-align:right;">
1.28069
</td>
<td style="text-align:right;">
1.28069
</td>
<td style="text-align:right;">
1.28069
</td>
</tr>
<tr>
<td style="text-align:right;">
6.75652
</td>
<td style="text-align:right;">
6.75640
</td>
<td style="text-align:right;">
6.75640
</td>
<td style="text-align:right;">
6.75640
</td>
</tr>
<tr>
<td style="text-align:right;">
-3.07519
</td>
<td style="text-align:right;">
-3.07513
</td>
<td style="text-align:right;">
-3.07513
</td>
<td style="text-align:right;">
-3.07513
</td>
</tr>
<tr>
<td style="text-align:right;">
3.51238
</td>
<td style="text-align:right;">
3.51220
</td>
<td style="text-align:right;">
3.51221
</td>
<td style="text-align:right;">
3.51221
</td>
</tr>
<tr>
<td style="text-align:right;">
0.87308
</td>
<td style="text-align:right;">
0.87305
</td>
<td style="text-align:right;">
0.87305
</td>
<td style="text-align:right;">
0.87305
</td>
</tr>
<tr>
<td style="text-align:right;">
4.98381
</td>
<td style="text-align:right;">
4.98379
</td>
<td style="text-align:right;">
4.98379
</td>
<td style="text-align:right;">
4.98379
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.00532
</td>
<td style="text-align:right;">
-1.00529
</td>
<td style="text-align:right;">
-1.00529
</td>
<td style="text-align:right;">
-1.00529
</td>
</tr>
<tr>
<td style="text-align:right;">
1.25848
</td>
<td style="text-align:right;">
1.25840
</td>
<td style="text-align:right;">
1.25840
</td>
<td style="text-align:right;">
1.25840
</td>
</tr>
</tbody>
</table>
</div>
<p>Standard errors for the random effects. In the balanced design these are essentially constant across clusters. We can see that the Bayesian estimates from <span class="pack" style="">mgcv</span> reflect greater uncertainty.</p>
<aside>
The <span class="func" style="">bam</span> results may actually be slightly different for some clusters.
</aside>
<p><br></p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:re-int-se">Table 8: </span>Standard Errors of the Random Coefficients
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:right;">
Intercepts
</th>
<th style="text-align:right;">
Days
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
mixed
</td>
<td style="text-align:right;">
12.239
</td>
<td style="text-align:right;">
2.335
</td>
</tr>
<tr>
<td style="text-align:left;">
gam
</td>
<td style="text-align:right;">
13.279
</td>
<td style="text-align:right;">
2.673
</td>
</tr>
<tr>
<td style="text-align:left;">
bam
</td>
<td style="text-align:right;">
13.279
</td>
<td style="text-align:right;">
2.673
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_discrete
</td>
<td style="text-align:right;">
13.279
</td>
<td style="text-align:right;">
2.673
</td>
</tr>
</tbody>
</table>
</div>
<h3 id="comparisons-to-bayesian-estimates">Comparisons to Bayesian Estimates</h3>
<p>As we have noted, one of the differences between <span class="pack" style="">lme4</span> and <span class="pack" style="">mgcv</span> output is that the default uncertainty estimates for the GAM are Bayesian. As such, it might be interesting to compare these to a fully Bayes approach. We’ll use <span class="pack" style="">rstanarm</span>, which uses the <span class="pack" style="">lme4</span> style syntax.</p>
<aside>
For those familiar with Bayesian models, the Stan group provides a vignette with information about the <a href="http://mc-stan.org/rstanarm/articles/glmer.html">priors in this model and comparisons to lme4 and gamm4</a>.
</aside>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(rstanarm)
bayes = stan_lmer(Reaction ~ Days + (1|Subject) + (0 + Days|Subject), 
                  data = sleepstudy,
                  cores = 4)

bayes_fe = broom::tidy(bayes)
bayes_vc = broom::tidy(bayes, &#39;hierarchical&#39;)
bayes_re = broom::tidy(bayes, &#39;varying&#39;)</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:bayes-compare">Table 9: </span>Bayesian fixed effects and variance components
</caption>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:left;">
group
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
251.769
</td>
<td style="text-align:right;">
7.029
</td>
<td style="text-align:left;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
Days
</td>
<td style="text-align:right;">
10.444
</td>
<td style="text-align:right;">
1.614
</td>
<td style="text-align:left;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
sd_(Intercept).Subject
</td>
<td style="text-align:right;">
26.431
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
Subject
</td>
</tr>
<tr>
<td style="text-align:left;">
sd_Days.Subject
</td>
<td style="text-align:right;">
6.530
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
Subject
</td>
</tr>
<tr>
<td style="text-align:left;">
sd_Observation.Residual
</td>
<td style="text-align:right;">
25.729
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
Residual
</td>
</tr>
</tbody>
</table>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:bayes-compare">Table 9: </span>Bayesian random effects
</caption>
<thead>
<tr>
<th style="text-align:left;">
level
</th>
<th style="text-align:left;">
group
</th>
<th style="text-align:right;">
(Intercept)
</th>
<th style="text-align:right;">
Days
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
308
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
1.150
</td>
<td style="text-align:right;">
9.315
</td>
</tr>
<tr>
<td style="text-align:left;">
309
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
-39.238
</td>
<td style="text-align:right;">
-8.741
</td>
</tr>
<tr>
<td style="text-align:left;">
310
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
-38.448
</td>
<td style="text-align:right;">
-5.523
</td>
</tr>
<tr>
<td style="text-align:left;">
330
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
23.642
</td>
<td style="text-align:right;">
-4.903
</td>
</tr>
<tr>
<td style="text-align:left;">
331
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
21.952
</td>
<td style="text-align:right;">
-3.088
</td>
</tr>
<tr>
<td style="text-align:left;">
332
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
9.405
</td>
<td style="text-align:right;">
-0.319
</td>
</tr>
<tr>
<td style="text-align:left;">
333
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
16.564
</td>
<td style="text-align:right;">
-0.201
</td>
</tr>
<tr>
<td style="text-align:left;">
334
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
-7.567
</td>
<td style="text-align:right;">
1.136
</td>
</tr>
<tr>
<td style="text-align:left;">
335
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
0.451
</td>
<td style="text-align:right;">
-10.840
</td>
</tr>
<tr>
<td style="text-align:left;">
337
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
33.265
</td>
<td style="text-align:right;">
8.691
</td>
</tr>
<tr>
<td style="text-align:left;">
349
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
-25.412
</td>
<td style="text-align:right;">
1.262
</td>
</tr>
<tr>
<td style="text-align:left;">
350
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
-14.119
</td>
<td style="text-align:right;">
6.778
</td>
</tr>
<tr>
<td style="text-align:left;">
351
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
4.724
</td>
<td style="text-align:right;">
-3.001
</td>
</tr>
<tr>
<td style="text-align:left;">
352
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
20.065
</td>
<td style="text-align:right;">
3.553
</td>
</tr>
<tr>
<td style="text-align:left;">
369
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
2.971
</td>
<td style="text-align:right;">
0.861
</td>
</tr>
<tr>
<td style="text-align:left;">
370
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
-26.045
</td>
<td style="text-align:right;">
4.955
</td>
</tr>
<tr>
<td style="text-align:left;">
371
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
0.267
</td>
<td style="text-align:right;">
-0.960
</td>
</tr>
<tr>
<td style="text-align:left;">
372
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
12.250
</td>
<td style="text-align:right;">
1.146
</td>
</tr>
</tbody>
</table>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:bayes-compare">Table 9: </span>Random effect standard errors
</caption>
<thead>
<tr>
<th style="text-align:left;">
level
</th>
<th style="text-align:left;">
group
</th>
<th style="text-align:right;">
(Intercept)
</th>
<th style="text-align:right;">
Days
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
308
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
13.227
</td>
<td style="text-align:right;">
2.866
</td>
</tr>
<tr>
<td style="text-align:left;">
309
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
14.583
</td>
<td style="text-align:right;">
2.921
</td>
</tr>
<tr>
<td style="text-align:left;">
310
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
14.397
</td>
<td style="text-align:right;">
2.782
</td>
</tr>
<tr>
<td style="text-align:left;">
330
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
13.749
</td>
<td style="text-align:right;">
2.736
</td>
</tr>
<tr>
<td style="text-align:left;">
331
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
13.875
</td>
<td style="text-align:right;">
2.786
</td>
</tr>
<tr>
<td style="text-align:left;">
332
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
13.092
</td>
<td style="text-align:right;">
2.648
</td>
</tr>
<tr>
<td style="text-align:left;">
333
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
13.267
</td>
<td style="text-align:right;">
2.782
</td>
</tr>
<tr>
<td style="text-align:left;">
334
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
13.481
</td>
<td style="text-align:right;">
2.760
</td>
</tr>
<tr>
<td style="text-align:left;">
335
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
13.945
</td>
<td style="text-align:right;">
2.825
</td>
</tr>
<tr>
<td style="text-align:left;">
337
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
14.473
</td>
<td style="text-align:right;">
2.901
</td>
</tr>
<tr>
<td style="text-align:left;">
349
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
13.957
</td>
<td style="text-align:right;">
2.692
</td>
</tr>
<tr>
<td style="text-align:left;">
350
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
13.285
</td>
<td style="text-align:right;">
2.740
</td>
</tr>
<tr>
<td style="text-align:left;">
351
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
13.694
</td>
<td style="text-align:right;">
2.821
</td>
</tr>
<tr>
<td style="text-align:left;">
352
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
13.643
</td>
<td style="text-align:right;">
2.801
</td>
</tr>
<tr>
<td style="text-align:left;">
369
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
13.832
</td>
<td style="text-align:right;">
2.765
</td>
</tr>
<tr>
<td style="text-align:left;">
370
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
13.673
</td>
<td style="text-align:right;">
2.825
</td>
</tr>
<tr>
<td style="text-align:left;">
371
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
13.806
</td>
<td style="text-align:right;">
2.733
</td>
</tr>
<tr>
<td style="text-align:left;">
372
</td>
<td style="text-align:left;">
Subject
</td>
<td style="text-align:right;">
13.445
</td>
<td style="text-align:right;">
2.713
</td>
</tr>
</tbody>
</table>
</div>
<p>We can see that the <span class="pack" style="">mgcv</span> estimates for standard errors of the random effects are close to the average standard errors from the fully Bayesian approach. For the Bayesian result we have (13.746 and 2.783 for Intercept and Days coefficient respectively, while for <span class="pack" style="">mgcv</span> this is 13.279 and 2.673.</p>
<h2 id="back-to-the-initial-problem">Back to the initial problem</h2>
<p>So we’ve established that both default <span class="func" style="">gam</span> and <span class="func" style="">bam</span> functions are providing what we want. However, the reason we’re here is to use demonstrate the speed gain we’ll get with big data using <span class="pack" style="">mgcv</span> for mixed models. So let’s return to the binary outcome example that took over a minute for <span class="pack" style="">lme4</span> to run.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
system.time({
  bam_big &lt;- bam(
    y_bin ~ x + b + s(g, bs=&#39;re&#39;), 
    data = d,
    nthreads = 8,
    family = binomial
  )
})</code></pre>
<pre><code>
   user  system elapsed 
5803.00  442.72 1572.52 </code></pre>
</div>
<p>That didn’t actually improve our situation, and was much worse in time- more than 20 minutes! Remember though, that the <span class="pack" style="">mgcv</span> approach has to estimate all those random effect coefficients, while <span class="pack" style="">lme4</span> is able to take advantage of design for mixed models among other things.</p>
<p>However, even here we haven’t used all our secret weapons. Another option with <span class="func" style="">bam</span> works on a modified data set using binned/rounded values for continuous covariates, and working with only the minimum data necessary to estimate the coefficients<span class="citation" data-cites="wood_generalized_2015">(S. N. Wood, Goude, and Shaw <a href="#ref-wood_generalized_2015" role="doc-biblioref">2015</a><a href="#ref-wood_generalized_2015" role="doc-biblioref">a</a>)</span>. With large enough data, as is the case here, the estimated parameters might not be different at all, while the efficiency gains could be tremendous. Let’s add <code>discrete = TRUE</code> and see what happens.</p>
<aside>
We just need the distinct set of values after rounding.
</aside>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
system.time({
  bam_big_d &lt;- bam(
    y_bin ~ x + b + s(g, bs=&#39;re&#39;), 
    data = d,
    nthreads = 8,
    family = binomial, 
    discrete = TRUE
  )
})</code></pre>
<pre><code>
   user  system elapsed 
  16.63    4.34   17.27 </code></pre>
</div>
<p><strong>Wow!</strong> That was as fast almost as <span class="pack" style="">lme4</span> with the linear mixed model! Let’s check the results. We’ll start with the fixed effects. I add some digits to the result so we can see the very slight differences.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:bam-fe-results">Table 10: </span>Fixed Effects
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
Term
</th>
<th style="text-align:right;">
Estimate
</th>
<th style="text-align:right;">
SE
</th>
<th style="text-align:right;">
LL
</th>
<th style="text-align:right;">
UL
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
True
</td>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
0.00000000
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
True
</td>
<td style="text-align:left;">
x
</td>
<td style="text-align:right;">
0.50000000
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
True
</td>
<td style="text-align:left;">
b
</td>
<td style="text-align:right;">
0.25000000
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_big
</td>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
0.03730496
</td>
<td style="text-align:right;">
0.02257804
</td>
<td style="text-align:right;">
-0.00694801
</td>
<td style="text-align:right;">
0.08155792
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_big
</td>
<td style="text-align:left;">
x
</td>
<td style="text-align:right;">
0.50087021
</td>
<td style="text-align:right;">
0.00223195
</td>
<td style="text-align:right;">
0.49649558
</td>
<td style="text-align:right;">
0.50524483
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_big
</td>
<td style="text-align:left;">
b
</td>
<td style="text-align:right;">
0.19083417
</td>
<td style="text-align:right;">
0.03209232
</td>
<td style="text-align:right;">
0.12793322
</td>
<td style="text-align:right;">
0.25373513
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_big_d
</td>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
0.03730496
</td>
<td style="text-align:right;">
0.02257845
</td>
<td style="text-align:right;">
-0.00694880
</td>
<td style="text-align:right;">
0.08155872
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_big_d
</td>
<td style="text-align:left;">
x
</td>
<td style="text-align:right;">
0.50087024
</td>
<td style="text-align:right;">
0.00223195
</td>
<td style="text-align:right;">
0.49649561
</td>
<td style="text-align:right;">
0.50524487
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_big_d
</td>
<td style="text-align:left;">
b
</td>
<td style="text-align:right;">
0.19083419
</td>
<td style="text-align:right;">
0.03209290
</td>
<td style="text-align:right;">
0.12793212
</td>
<td style="text-align:right;">
0.25373627
</td>
</tr>
<tr>
<td style="text-align:left;">
lme4
</td>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
0.03734586
</td>
<td style="text-align:right;">
0.02249230
</td>
<td style="text-align:right;">
-0.00673823
</td>
<td style="text-align:right;">
0.08142996
</td>
</tr>
<tr>
<td style="text-align:left;">
lme4
</td>
<td style="text-align:left;">
x
</td>
<td style="text-align:right;">
0.50136890
</td>
<td style="text-align:right;">
0.00223338
</td>
<td style="text-align:right;">
0.49699155
</td>
<td style="text-align:right;">
0.50574624
</td>
</tr>
<tr>
<td style="text-align:left;">
lme4
</td>
<td style="text-align:left;">
b
</td>
<td style="text-align:right;">
0.19104414
</td>
<td style="text-align:right;">
0.03195267
</td>
<td style="text-align:right;">
0.12841806
</td>
<td style="text-align:right;">
0.25367021
</td>
</tr>
</tbody>
</table>
</div>
<p>Now for the variance components.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:big-vc-results">Table 11: </span>Variance Components
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:right;">
std.dev
</th>
<th style="text-align:right;">
variance
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
true
</td>
<td style="text-align:right;">
0.500000
</td>
<td style="text-align:right;">
0.250000
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_big
</td>
<td style="text-align:right;">
0.502942
</td>
<td style="text-align:right;">
0.252950
</td>
</tr>
<tr>
<td style="text-align:left;">
bam_big_d
</td>
<td style="text-align:right;">
0.502951
</td>
<td style="text-align:right;">
0.252959
</td>
</tr>
<tr>
<td style="text-align:left;">
lme4
</td>
<td style="text-align:right;">
0.502994
</td>
<td style="text-align:right;">
0.253003
</td>
</tr>
</tbody>
</table>
</div>
<p>And finally, let’s look at the estimated random effects for the first 5 clusters.</p>
<aside>
Just a note, unless you have very many observations per cluster, you should not expect to get very close to the true values of the random effects except on average, which should serve as a caution for any 2-step approach one might undertake using the estimates. The rank correlations of the estimates vs. the true values in this example are 1.0.
</aside>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:big-re-results">Table 12: </span>Estimated Random Effects
</caption>
<thead>
<tr>
<th style="text-align:left;">
cluster
</th>
<th style="text-align:right;">
true
</th>
<th style="text-align:right;">
bam_big
</th>
<th style="text-align:right;">
bam_big_d
</th>
<th style="text-align:right;">
lme4
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:right;">
0.0912404
</td>
<td style="text-align:right;">
-0.0361639
</td>
<td style="text-align:right;">
-0.0361640
</td>
<td style="text-align:right;">
-0.0362103
</td>
</tr>
<tr>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
0.1310768
</td>
<td style="text-align:right;">
0.1483554
</td>
<td style="text-align:right;">
0.1483554
</td>
<td style="text-align:right;">
0.1481565
</td>
</tr>
<tr>
<td style="text-align:left;">
3
</td>
<td style="text-align:right;">
-0.0562572
</td>
<td style="text-align:right;">
-0.1424477
</td>
<td style="text-align:right;">
-0.1424478
</td>
<td style="text-align:right;">
-0.1426766
</td>
</tr>
<tr>
<td style="text-align:left;">
4
</td>
<td style="text-align:right;">
0.6194238
</td>
<td style="text-align:right;">
0.5563464
</td>
<td style="text-align:right;">
0.5563468
</td>
<td style="text-align:right;">
0.5561718
</td>
</tr>
<tr>
<td style="text-align:left;">
5
</td>
<td style="text-align:right;">
-0.5022289
</td>
<td style="text-align:right;">
-0.4145603
</td>
<td style="text-align:right;">
-0.4145606
</td>
<td style="text-align:right;">
-0.4148342
</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<p>So we’re getting what we should in general.</p>
<h2 id="when-to-use-bam">When to use bam</h2>
<p>The following are some guidelines for when <span class="func" style="">bam</span> might be preferable compared to other mixed modeling tools. To help with this, I’ve conducted my own examinations on very large data sets of up to <a href="#simulation-settings">one million observations</a>, and included timing results from other relevant studies, which will be presented here.</p>
<h3 id="linear-mixed-models">Linear Mixed Models</h3>
<p>As we’ll see, in general you’ll probably need very large data for <span class="func" style="">bam</span> to be preferred to <span class="pack" style="">lme4</span> for linear mixed models unless:</p>
<ul>
<li>You have complicated structure that begins to bog down lme4</li>
<li>You want to add smooth terms<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></li>
<li>You have memory issues</li>
<li>You have a computing setup that can take advantage of <span class="func" style="">bam</span></li>
</ul>
<p>The following shows some timings for <span class="pack" style="">lme4</span>, <span class="pack" style="">glmmTMB</span>, and <span class="pack" style="">mgcv</span> for the linear mixed model case under a variety of settings with large data. In some sense, this is not exactly a fair comparison as <span class="pack" style="">mgcv</span> parallelizes computations while <span class="pack" style="">lme4</span> and <span class="pack" style="">glmmTMB</span> do not. However, this is also exactly the point of the demonstration - those who can, do. In general though, the <span class="pack" style="">lme4</span> advantage holds until around 500k observations. We can see that the main issue for <span class="func" style="">bam</span> is not so much the sample size, but the number of parameters to estimate.</p>
<aside>
For <span class="pack" style="">lme4</span>, I set at least one argument to possibly improve speed/performance for both lme and glmm models, though this only shaved a few seconds for the largest sample size settings for the linear mixed model. For <span class="pack" style="">mgcv</span> I only used 12 cores for parallelization so as to be similar to what is common on modern machines (8-12), but anyone with access to a better machine or cluster computing environment would see even more speed gain by utilizing additional cores, so I also looked at 16 cores. For <span class="pack" style="">glmmTMB</span>, settings were left at defaults, as I’ve not come across any specific speed recommendations. See Brooks et al.<span class="citation" data-cites="brooks_glmmtmb_2017">(Brooks et al. <a href="#ref-brooks_glmmtmb_2017" role="doc-biblioref">2017</a>)</span> (<span class="citation" data-cites="brooks_glmmtmb_2017">Brooks et al. (<a href="#ref-brooks_glmmtmb_2017" role="doc-biblioref">2017</a>)</span>) for more speed comparisons of <span class="pack" style="">glmmTMB</span>, <span class="pack" style="">mgcv</span>, <span class="pack" style="">lme4</span>, and others, as well as the <a href="https://cran.r-project.org/web/packages/glmmTMB/vignettes/glmmTMB.pdf">glmmTMB vignette</a>.
</aside>
<div class="layout-chunk" data-layout="l-body">
<p><img src="big-mixed-models_files/figure-html5/lme-timings-1.svg" width="624" style="display: block; margin: auto;" /></p>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<h3 id="generalized-linear-mixed-models">Generalized Linear Mixed Models</h3>
<p>For the generalized setting with binary, count, and other outcomes:</p>
<ul>
<li><span class="pack" style="">lme4</span>, at least at the time of this writing, will almost certainly start giving convergence warnings even in well-behaved data settings, and as such, will require tweaking to mitigate.</li>
<li><span class="pack" style="">glmmTMB</span> is probably viable up to 100k and one or two random effects, but may generally be a slower option.</li>
<li>Use <span class="pack" style="">mgcv</span> for same reasons as with linear mixed models, but here it potentially becomes an advantage with as few as 100k.</li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<p><img src="big-mixed-models_files/figure-html5/gmm-timings-1.svg" width="624" style="display: block; margin: auto;" /></p>
</div>
<aside>
I have also done some timings on a local machine with as many as 10000 levels for one of the random effects, 1000 for the other, and 5 million observations. Depending on the computational setup, this could take 30 minutes for a linear mixed model and 24 cores, to 2-3 hours for a logistic mixed model using 12 cores.
</aside>
<h3 id="other-options">Other options</h3>
<p>When looking into mixed models for big data, you typically won’t find much in the way of options. I’ve seen some packages or offerings for some machine learning approaches like random forests<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, but this doesn’t address the issue of large data. A Spark module provided by LinkedIn is available, <a href="https://github.com/linkedin/photon-ml">photonML</a>, but it’s not clear how easy it is to implement. Julia has recently made multithreading a viable option for any function. This is notable since Doug Bates, one of the <span class="pack" style="">lme4</span> authors, develops the <a href="https://github.com/dmbates/MixedModels.jl">MixedModels</a> module for Julia. Should multithreading functionality be added, it could be a very powerful tool<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p>
<p>Among proprietary options, SAS and Stata are the more commonly used tools. SAS PROC HPMIXED essentially uses the <span class="pack" style="">lme4</span> approach, but can be faster for well-behaved data. Stata, while commonly used for mixed models, is generally slower than the <span class="pack" style="">lme4</span> even for standard settings, and is likely prohibitively slow for settings above<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
<aside>
SAS uses disk rather than RAM for processing, so may be preferred for low RAM devices.
</aside>
<p>Here is a summary of other timings of various tools for mixed models.</p>
<h5 id="mccoach-et-al.-2018">McCoach et al. 2018</h5>
<p>These are the results from McCoach et al.<span class="citation" data-cites="mccoach2018">(McCoach et al. <a href="#ref-mccoach2018" role="doc-biblioref">2018</a>)</span> with a standard linear mixed model. Sample size fixed at 10000, with a single grouping factor with only 50 levels. Models included five covariates each with a random slope. In the first five cases, a true variance parameter was set to zero, a situation <span class="pack" style="">lme4</span> handles well<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. SAS is very speedy for such settings if data is well-behaved.</p>
<div class="layout-chunk" data-layout="l-body">
<p><img src="../../img/bam/mccoach.png" width="618" style="display: block; margin: auto;" /></p>
</div>
<h5 id="brooks-et-al.-2018-timing-as-a-function-of-sample-size">Brooks et al. 2018 timing as a function of sample size</h5>
<p>Brooks et al. uses the Salamander data from the <span class="pack" style="">glmmTMB</span> package. It has a single grouping factor for the random effect with 23 levels. Starting sample size is 644, which is then replicated to produce larger data. This is a negative binomial count model. In this particular setting <span class="pack" style="">glmmTMB</span> has an advantage.</p>
<div class="layout-chunk" data-layout="l-body">
<p><img src="../../img/bam/brooks_n.png" width="453" style="display: block; margin: auto;" /></p>
</div>
<h5 id="brooks-et-al.-2018-timing-as-a-function-of-number-of-levels">Brooks et al. 2018 timing as a function of number of levels</h5>
<p>This data is simulated based on models from the previous, and adds increasing numbers of (balanced) levels to the random effect. This shows a similar effect of the number of levels on <span class="pack" style="">mgcv</span> as the simulation presented in this post, though they are not using the functionality of <span class="func" style="">bam</span>.</p>
<div class="layout-chunk" data-layout="l-body">
<p><img src="../../img/bam/brooks_nlevels.png" width="451" style="display: block; margin: auto;" /></p>
</div>
<h5 id="glmmtmb-timings">glmmTMB timings</h5>
<p>As previously noted, depending on the data, and whether the target is assumed gaussian or not, <span class="pack" style="">glmmTMB</span> might be preferable. For the following, in the first case a small data set was replicated to create larger data, and in the second, a larger data set was sub-sampled<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>. The advantage is to <span class="pack" style="">glmmTMB</span> in the first case, and <span class="pack" style="">lme4</span> in the second.</p>
<div class="layout-chunk" data-layout="l-body">
<p><img src="../../img/bam/tmb_vignette_larger_contra.png" width="329" style="display: block; margin: auto;" /><img src="../../img/bam/tmb_vignette_larger_insteval.png" width="333" style="display: block; margin: auto;" /></p>
</div>
<h2 id="limitations">Limitations</h2>
<p>There are limitations to the use of the <span class="pack" style="">mgcv</span> approach.</p>
<ul>
<li>The number of parameters to estimate increases with the number of random effect levels, which may void any gains until very large data with complex models</li>
<li>No estimation of random effect correlations, e.g. between slopes and intercepts</li>
<li>When <code>discrete = TRUE</code>, some <span class="func" style="">predict.gam</span> functionality may be lost</li>
</ul>
<p>All in all, these are pretty minor, and the last one likely will be remedied in a future release.</p>
<h2 id="summary">Summary</h2>
<p>The take home point here is that you now have viable tools to run mixed models on even very large data with millions of observations. This doesn’t mean you won’t have to wait for it, especially for more complicated models, but you may even be able to run some of these on standard machines in reasonable times. The alternative estimation procedures may even make otherwise problematic models more feasible in smaller data settings. Good luck!</p>
<h2 id="supplemental">Supplemental</h2>
<h3 id="simulation-settings">Simulation Settings</h3>
<p>I will set up a repo with the simulation code at some point and link it here. But the settings for the timings can be summarized as follows.</p>
<h4 id="linear-mixed-model">Linear mixed model</h4>
<p>The following are for the linear mixed model. <code>N</code> is the sample size, balanced refers to whether a random 75% sample was taken with proportion equivalent to the group index (first grouping variable for both 1 and 2 random effect settings), and <code>tau_2</code> is zero if there is only one random effect, or refers to the standard deviation of the second random effect. Each of these settings was run 5 times, and the previous visualizations display the average timing of those.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
N
</th>
<th style="text-align:right;">
balanced
</th>
<th style="text-align:right;">
tau_2
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1e+04
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.0
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+04
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.5
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+04
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.0
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+04
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.5
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+04
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.0
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+04
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.5
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+04
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.0
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+04
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.5
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+05
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.0
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+05
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.5
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+05
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.0
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+05
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.5
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+05
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.0
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+05
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.5
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+05
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.0
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+05
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.5
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+06
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.0
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+06
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.5
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+06
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.0
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+06
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.5
</td>
</tr>
</tbody>
</table>
</div>
<p>Held constant are:</p>
<ul>
<li>The number of covariates: 20, all drawn from a standardized normal distribution</li>
<li>Fixed effect coefficients: drawn from a random uniform (-1, 1)</li>
<li>Residual standard deviation: 1</li>
<li>The number of levels in each factor: 1000 for the first, 100 for the second</li>
<li>The standard deviations of the random effects: .5 for both</li>
</ul>
<h4 id="generalized-linear-mixed-model">Generalized linear mixed model</h4>
<p>For the generalized linear mixed model, the settings are the same but we also add a case where the outcome is rare or not in this binary setting (~ 10% prevalence or less).</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
N
</th>
<th style="text-align:right;">
balanced
</th>
<th style="text-align:right;">
tau_2
</th>
<th style="text-align:left;">
rare
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1e+04
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+04
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+04
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+04
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+04
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+04
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+04
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+04
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+04
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+04
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+04
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+04
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+04
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+04
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+04
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+04
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+05
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+05
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+05
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+05
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+05
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+05
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+05
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+05
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+05
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+05
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+05
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+05
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+05
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+05
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+05
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
5e+05
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+06
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+06
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+06
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+06
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+06
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+06
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+06
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:right;">
1e+06
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
</tbody>
</table>
</div>
<h4 id="function-arguments">Function arguments</h4>
<p>For <span class="func" style="">g/lmer</span> I set <code>check.derivatives = FALSE</code> and for the GLMM I additionally set <code>nAGQ = 0</code>, as this is precisely the setting one would do so<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>. I did not mess with the optimizers but it is possible to get a speed gain there in some settings. See performance tips <a href="https://cran.r-project.org/web/packages/lme4/vignettes/lmerperf.html">here</a> and demonstrated <a href="http://svmiller.com/blog/2018/06/mixed-effects-models-optimizer-checks/">here</a>.</p>
<p>For <span class="func" style="">bam</span> I set the following.</p>
<ul>
<li><code>gc.level = 0</code></li>
<li><code>use.chol = TRUE</code></li>
<li><code>nthreads = 12/16</code></li>
<li><code>chunk.size = 1000</code></li>
<li><code>samfrac = .1</code></li>
</ul>
<p><span class="func" style="">glmmTMB</span> was left at defaults as I’m not aware of a specific approach for speed gain.</p>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-brooks_glmmtmb_2017">
<p>Brooks, Mollie E., Kasper Kristensen, Koen J. van Benthem, Arni Magnusson, Casper W. Berg, Anders Nielsen, Hans J. Skaug, Martin Mächler, and Benjamin M. Bolker. 2017. “GlmmTMB Balances Speed and Flexibility Among Packages for Zero-Inflated Generalized Linear Mixed Modeling.” <em>The R Journal</em> 9 (2): 378–400. <a href="https://journal.r-project.org/archive/2017/RJ-2017-066">https://journal.r-project.org/archive/2017/RJ-2017-066</a>.</p>
</div>
<div id="ref-li_faster_2019">
<p>Li, Zheyuan, and Simon N. Wood. 2019. “Faster Model Matrix Crossproducts for Large Generalized Linear Models with Discretized Covariates.” <em>Statistics and Computing</em>, March. <a href="https://doi.org/10.1007/s11222-019-09864-2">https://doi.org/10.1007/s11222-019-09864-2</a>.</p>
</div>
<div id="ref-mccoach2018">
<p>McCoach, D Betsy, Graham G Rifenbark, Sarah D Newton, Xiaoran Li, Janice Kooken, Dani Yomtov, Anthony J Gambino, and Aarti Bellara. 2018. “Does the Package Matter? A Comparison of Five Common Multilevel Modeling Software Packages.” <em>Journal of Educational and Behavioral Statistics</em> 43 (5): 594–627. <a href="https://journals.sagepub.com/doi/10.3102/1076998618776348">https://journals.sagepub.com/doi/10.3102/1076998618776348</a>.</p>
</div>
<div id="ref-wood_mgcv:_2012">
<p>Wood, Simon. 2012. “Mgcv: Mixed GAM Computation Vehicle with GCV/AIC/REML Smoothness Estimation,” October. <a href="https://researchportal.bath.ac.uk/en/publications/mgcv-mixed-gam-computation-vehicle-with-gcvaicreml-smoothness-est">https://researchportal.bath.ac.uk/en/publications/mgcv-mixed-gam-computation-vehicle-with-gcvaicreml-smoothness-est</a>.</p>
</div>
<div id="ref-wood_generalized_2017">
<p>Wood, Simon N. 2017. <em>Generalized Additive Models : An Introduction with R, Second Edition</em>. Chapman; Hall/CRC. <a href="https://doi.org/10.1201/9781315370279">https://doi.org/10.1201/9781315370279</a>.</p>
</div>
<div id="ref-wood_generalized_2015">
<p>Wood, Simon N., Yannig Goude, and Simon Shaw. 2015a. “Generalized Additive Models for Large Data Sets.” <em>Journal of the Royal Statistical Society: Series C (Applied Statistics)</em> 64 (1): 139–55. <a href="https://doi.org/10.1111/rssc.12068">https://doi.org/10.1111/rssc.12068</a>.</p>
</div>
<div id="ref-wood_generalized_2015-1">
<p>———. 2015b. “Generalized Additive Models for Large Data Sets.” <em>Journal of the Royal Statistical Society: Series C (Applied Statistics)</em> 64 (1): 139–55. <a href="https://doi.org/10.1111/rssc.12068">https://doi.org/10.1111/rssc.12068</a>.</p>
</div>
<div id="ref-wood_generalized_2017-1">
<p>Wood, Simon N., Zheyuan Li, Gavin Shaddick, and Nicole H. Augustin. 2017. “Generalized Additive Models for Gigadata: Modeling the U.k. Black Smoke Network Daily Data.” <em>Journal of the American Statistical Association</em> 112 (519): 1199–1210. <a href="https://doi.org/10.1080/01621459.2016.1195744">https://doi.org/10.1080/01621459.2016.1195744</a>.</p>
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>You could use construct the smooth with <span class="pack" style="">mgcv</span> and add it to the model matrix for <span class="pack" style="">lme4</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩</a></p></li>
<li id="fn2" role="doc-endnote"><p>See <a href="https://cran.r-project.org/web/packages/REEMtree/">REEMtree</a>, <a href="https://cran.r-project.org/web/packages/MixRF/">mixRF</a> for example.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩</a></p></li>
<li id="fn3" role="doc-endnote"><p>While I haven’t seen it done, so it may have to serve as a later post, it should be possible to use deep learning tools like Keras or fastai by regularizing only weights associated with the random effects. If one takes an actual deep learning approach, then one can estimate functions of the ‘fixed’ covariates (like the smooth terms in typical GAM) and possibly get at correlations of the clusters themselves (a la spatial random effects).<a href="#fnref3" class="footnote-back" role="doc-backlink">↩</a></p></li>
<li id="fn4" role="doc-endnote"><p>See McCoach reference <span class="citation" data-cites="mccoach2018">(McCoach et al. <a href="#ref-mccoach2018" role="doc-biblioref">2018</a>)</span>. They also look at HLM and Mplus. However, I haven’t in years consulted with anyone across dozens of disciplines that was using HLM for mixed models. With Mplus, the verbosity of the syntax, plus additional data processing required, plus huge lack of post-processing of the model would negate any speed gain one might get from simply running the model. Couple this with the fact that campus-wide licenses are rare for either, neither could be recommended for mixed models. Note also, that one setting of <span class="func" style="">lmer</span> probably would have negated almost all their reported convergence issues.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩</a></p></li>
<li id="fn5" role="doc-endnote"><p>See McCoach reference <span class="citation" data-cites="mccoach2018">(McCoach et al. <a href="#ref-mccoach2018" role="doc-biblioref">2018</a>)</span>. They also look at HLM and Mplus. However, I haven’t in years consulted with anyone across dozens of disciplines that was using HLM for mixed models. With Mplus, the verbosity of the syntax, plus additional data processing required, plus huge lack of post-processing of the model would negate any speed gain one might get from simply running the model. Couple this with the fact that campus-wide licenses are rare for either, neither could be recommended for mixed models. Note also, that one setting of <span class="func" style="">lmer</span> probably would have negated almost all their reported convergence issues.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩</a></p></li>
<li id="fn6" role="doc-endnote"><p>“In general, we expect <span class="pack" style="">glmmTMB</span>‘s advantages over <span class="pack" style="">lme4</span> to be (1) greater flexibility (zero-inflation etc.); (2) greater speed for GLMMs, especially those with large number of ’top-level’ parameters (fixed effects plus random-effects variance-covariance parameters). In contrast, lme4 should be faster for LMMs.”<a href="#fnref6" class="footnote-back" role="doc-backlink">↩</a></p></li>
<li id="fn7" role="doc-endnote"><p>See this R user group thread for a <a href="https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/025938.html">discussion</a>, this <a href="https://stats.stackexchange.com/questions/77313/why-cant-i-match-glmer-family-binomial-output-with-manual-implementation-of-g">stackoverflow exchange</a> involving one of the lme4 contributors, and Bates <a href="https://github.com/dmbates/MixedModelsinJulia/blob/master/nAGQ.ipynb">Julia notebook</a> for more detail.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<div class="article-footer">
  <p class="social_footer">
    <span class="article-sharing">
      Share: &nbsp;
      <a href="https://twitter.com/share?text=Mixed%20Models%20for%20Big%20Data&amp;url=https%3A%2F%2Fm-clark.github.io%2Fposts%2F2019-10-20-big-mixed-models%2F">
        <i class="fab fa-twitter"></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fm-clark.github.io%2Fposts%2F2019-10-20-big-mixed-models%2F&amp;title=Mixed%20Models%20for%20Big%20Data">
        <i class="fab fa-linkedin"></i>
      </a>
      <a href="https://www.facebook.com/sharer/sharer.php?s=100&amp;p[url]=https%3A%2F%2Fm-clark.github.io%2Fposts%2F2019-10-20-big-mixed-models%2F">
        <i class="fab fa-facebook"></i>
      </a>
    </span>
  </p>
</div>
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="updates-and-corrections">Corrections</h3>
  <p>If you see mistakes or want to suggest changes, please <a href="https://github.com//m-clark/m-clark.github.io/issues/new">create an issue</a> on the source repository.</p>
  <h3 id="reuse">Reuse</h3>
  <p>Text and figures are licensed under Creative Commons Attribution <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>. Source code is available at <a href="https://github.com//m-clark/m-clark.github.io">https://github.com//m-clark/m-clark.github.io</a>, unless otherwise noted. The figures that have been reused from other sources don't fall under this license and can be recognized by a note in their caption: "Figure from ...".</p>
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Clark (2019, Oct. 20). Michael Clark: Mixed Models for Big Data. Retrieved from https://m-clark.github.io/posts/2019-10-20-big-mixed-models/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{clark2019mixed,
  author = {Clark, Michael},
  title = {Michael Clark: Mixed Models for Big Data},
  url = {https://m-clark.github.io/posts/2019-10-20-big-mixed-models/},
  year = {2019}
}</pre>
</div>
<script id="distill-bibliography" type="text/bibtex">

@article{beyerlein_alternative_2008,
	title = {Alternative regression models to assess increase in childhood {BMI}},
	volume = {8},
	issn = {1471-2288},
	url = {http://www.biomedcentral.com/1471-2288/8/59},
	doi = {10.1186/1471-2288-8-59},
	number = {1},
	urldate = {2012-05-16},
	journal = {BMC Medical Research Methodology},
	author = {Beyerlein, Andreas and Fahrmeir, Ludwig and Mansmann, Ulrich and Toschke, AndrÃ© M},
	year = {2008},
	pages = {59},
	file = {BMC Medical Research Methodology | Full text | Alternative regression models to assess increase in childhood BMI:/Users/micl/Zotero/storage/KADXBB3S/59.html:text/html}
}

@book{wood_generalized_2006,
	title = {Generalized additive models: an introduction with {R}},
	volume = {66},
	shorttitle = {Generalized additive models},
	publisher = {CRC Press},
	author = {Wood, S. N},
	year = {2006},
	file = {[PDF] from bath.ac.uk:/Users/micl/Zotero/storage/N99I9S57/Wood - 2006 - Generalized additive models an introduction with .pdf:application/pdf;Snapshot:/Users/micl/Zotero/storage/AVVZHAIN/Wood - 2006 - Generalized additive models an introduction with .html:text/html}
}

@book{rasmussen_gaussian_2006,
	address = {Cambridge, Mass.},
	title = {Gaussian processes for machine learning},
	isbn = {0-262-18253-X 978-0-262-18253-9},
	abstract = {"Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics."--Jacket.},
	language = {English},
	publisher = {MIT Press},
	author = {Rasmussen, Carl Edward and Williams, Christopher K. I},
	year = {2006}
}

@book{ruppert_semiparametric_2003,
	title = {Semiparametric {Regression}},
	isbn = {978-0-521-78516-7},
	abstract = {Semiparametric regression is concerned with the flexible incorporation of non-linear functional relationships in regression analyses. Any application area that benefits from regression analysis can also benefit from semiparametric regression. Assuming only a basic familiarity with ordinary parametric regression, this user-friendly book explains the techniques and benefits of semiparametric regression in a concise and modular fashion. The authors make liberal use of graphics and examples plus case studies taken from environmental, financial, and other applications. They include practical advice on implementation and pointers to relevant software. The book is suitable as a textbook for students with little background in regression as well as a reference book for statistically oriented scientists such as biostatisticians, econometricians, quantitative social scientists, epidemiologists, with a good working knowledge of regression and the desire to begin using more flexible semiparametric models. Even experts on semiparametric regression should find something new here.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Ruppert, David and Wand, Matt P. and Carroll, Raymond J.},
	month = jul,
	year = {2003},
	keywords = {Mathematics / Probability \& Statistics / General, Mathematics / General, Regression analysis, Mathematics / Probability \& Statistics / Regression Analysis, Medical / Epidemiology, Nonparametric statistics}
}

@book{fox_nonparametric_2000,
	title = {Nonparametric {Simple} {Regression}: {Smoothing} {Scatterplots}},
	isbn = {978-0-7619-1585-0},
	shorttitle = {Nonparametric {Simple} {Regression}},
	abstract = {John Fox introduces readers to the techniques of kernel estimation, additive nonparametric regression, and the ways nonparametric regression can be employed to select transformations of the data preceding a linear least-squares fit.},
	language = {en},
	publisher = {SAGE},
	author = {Fox, John},
	month = jan,
	year = {2000},
	keywords = {Mathematics / Probability \& Statistics / General, Social Science / Research, Regression analysis, Nonparametric statistics, Medical / General, Social Science / General, Social Science / Statistics, Social sciences}
}

@book{fox_multiple_2000,
	title = {Multiple and {Generalized} {Nonparametric} {Regression}},
	isbn = {978-0-7619-2189-9},
	abstract = {This book builds on John Fox's previous volume in the QASS Series, Non Parametric Simple Regression. In this book, the reader learns how to estimate and plot smooth functions when there are multiple independent variables.},
	language = {en},
	publisher = {SAGE},
	author = {Fox, John},
	month = may,
	year = {2000},
	keywords = {Mathematics / Probability \& Statistics / General, Social Science / Research, Regression analysis, Mathematics / Probability \& Statistics / Regression Analysis, Nonparametric statistics, Social Science / General, Social Science / Statistics, Social sciences, Social Science / Methodology, Social sciences - Statistical methods, Social sciences/ Statistical methods}
}

@book{wasserman_all_2006,
	title = {All of {Nonparametric} {Statistics}},
	isbn = {978-0-387-25145-5},
	abstract = {The goal of this text is to provide the reader with a single book where they can find a brief account of many, modern topics in nonparametric inference. The book is aimed at Master's level or Ph.D. level students in statistics, computer science, and engineering. It is also suitable for researchers who want to get up to speed quickly on modern nonparametric methods. This text covers a wide range of topics including: the bootstrap, the nonparametric delta method, nonparametric regression, density estimation, orthogonal function methods, minimax estimation, nonparametric confidence sets, and wavelets. The book has a mixture of methods and theory. From the reviews: "...The book is excellent." (Short Book Reviews of the ISI, June 2006) "Now we have All of Nonparametric Statistics a?{\textbar} . the writing is excellent and the author is to be congratulated on the clarity achieved. a?{\textbar} the book is excellent." (N.R. Draper, Short Book Reviews, Vol. 26 (1), 2006) "Overall, I enjoyed reading this book very much. I like Wasserman's intuitive explanations and careful insights into why one path or approach is taken over another. Most of all, I am impressed with the wealth of information on the subject of asymptotic nonparametric inferences." (Stergios B. Fotopoulos for Technometrics, Vol. 49, No. 1., February 2007)},
	language = {en},
	publisher = {Springer},
	author = {Wasserman, Larry},
	year = {2006},
	keywords = {statistics, Mathematics / Probability \& Statistics / General, Mathematics / General, Nonparametric statistics, Artificial intelligence, Computers / Intelligence (AI) \& Semantics, Mathematical statistics}
}

@book{venables_modern_2002,
	title = {Modern {Applied} {Statistics} {With} {S}},
	isbn = {978-0-387-95457-8},
	abstract = {S-PLUS is a powerful environment for the statistical and graphical analysis of data. It provides the tools to implement many statistical ideas which have been made possible by the widespread availability of workstations having good graphics and computational capabilities. This book is a guide to using S-PLUS to perform statistical analyses and provides both an introduction to the use of S-PLUS and a course in modern statistical methods. S-PLUS is available for both Windows and UNIX workstations, and both versions are covered in depth.The aim of the book is to show how to use S-PLUS as a powerful and graphical data analysis system. Readers are assumed to have a basic grounding in statistics, and so the book in intended for would-be users of S-PLUS and both students and researchers using statistics. Throughout, the emphasis is on presenting practical problems and full analyses of real data sets. Many of the methods discussed are state-of-the-art approaches to topics such as linear, nonlinear, and smooth regression models, tree-based methods, multivariate analysis and pattern recognition, survival analysis, time series and spatial statistics. Throughout, modern techniques such as robust methods, non-parametric smoothing, and bootstrapping are used where appropriate.This third edition is intended for users of S-PLUS 4.5, 5.0, 2000 or later, although S-PLUS 3.3/4 are also considered. The major change from the second edition is coverage of the current versions of S-PLUS. The material has been extensively rewritten using new examples and the latest computationally intensive methods. The companion volume on S Programming will provide an in-depth guide for those writing software in the S language.The authors have written several software libraries that enhance S-PLUS; these and all the datasets used are available on the Internet in versions for Windows and UNIX. There are extensive on-line complements covering advanced material, user-contributed extensions, further exercises, and new features of S-PLUS as they are introduced.Dr. Venables is now Statistician with CSRIO in Queensland, having been at the Department of Statistics, University of Adelaide, for many years previously. He has given many short courses on S-PLUS in Australia, Europe, and the USA. Professor Ripley holds the Chair of Applied Statistics at the University of Oxford, and is the author of four other books on spatial statistics, simulation, pattern recognition, and neural networks.},
	language = {en},
	publisher = {BirkhÃ¤user},
	author = {Venables, William N. and Ripley, Brian D.},
	month = aug,
	year = {2002},
	keywords = {statistics, Mathematics / Probability \& Statistics / General, Computers / Mathematical \& Statistical Software, Mathematical statistics, Business \& Economics / Statistics, Mathematical statistics - Data processing, Mathematical statistics/ Data processing, S, S (Computer program language), S (Computer system), S-PLUS (Computer program language), Statistics - Data processing, Statistics/ Data processing}
}

@book{hastie_generalized_1990,
	title = {Generalized {Additive} {Models}},
	isbn = {978-0-412-34390-2},
	language = {en},
	publisher = {CRC Press},
	author = {Hastie, T.J. and Tibshirani, R.J.},
	month = jun,
	year = {1990},
	keywords = {Mathematics / Probability \& Statistics / General}
}

@book{hastie_elements_2009,
	edition = {2nd ed. 2009. Corr. 3rd printing 5th Printing.},
	title = {The {Elements} of {Statistical} {Learning}: {Data} {Mining}, {Inference}, and {Prediction}, {Second} {Edition}},
	isbn = {0-387-84857-6},
	shorttitle = {The {Elements} of {Statistical} {Learning}},
	publisher = {Springer},
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
	month = feb,
	year = {2009}
}

@article{breiman_statistical_2001,
	title = {Statistical {Modeling}: {The} {Two} {Cultures} (with comments and a           rejoinder by the author)},
	volume = {16},
	issn = {0883-4237},
	shorttitle = {Statistical {Modeling}},
	url = {http://projecteuclid.org/euclid.ss/1009213726},
	doi = {10.1214/ss/1009213726},
	abstract = {There are two cultures in the use of statistical modeling to reach
             conclusions from data. One assumes that the data are generated by a given
             stochastic data model. The other uses algorithmic models and treats the data
             mechanism as unknown. The statistical community has been committed to the
             almost exclusive use of data models. This commitment has led to irrelevant
             theory, questionable conclusions, and has kept statisticians from working on a
             large range of interesting current problems. Algorithmic modeling, both in
             theory and practice, has developed rapidly in fields outside statistics. It can
             be used both on large complex data sets and as a more accurate and informative
             alternative to data modeling on smaller data sets. If our goal as a field is to
             use data to solve problems, then we need to move away from exclusive dependence
             on data models and adopt a more diverse set of tools.},
	number = {3},
	urldate = {2012-07-22},
	journal = {Statistical Science},
	author = {Breiman, Leo},
	month = aug,
	year = {2001},
	note = {Mathematical Reviews number (MathSciNet): MR1874152},
	pages = {199--231}
}

@article{rigby_generalized_2005,
	title = {Generalized additive models for location, scale and shape},
	volume = {54},
	issn = {1467-9876},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9876.2005.00510.x/abstract},
	doi = {10.1111/j.1467-9876.2005.00510.x},
	abstract = {Summary. A general class of statistical models for a univariate response variable is presented which we call the generalized additive model for location, scale and shape (GAMLSS). The model assumes independent observations of the response variable y given the parameters, the explanatory variables and the values of the random effects. The distribution for the response variable in the GAMLSS can be selected from a very general family of distributions including highly skew or kurtotic continuous and discrete distributions. The systematic part of the model is expanded to allow modelling not only of the mean (or location) but also of the other parameters of the distribution of y, as parametric and/or additive nonparametric (smooth) functions of explanatory variables and/or random-effects terms. Maximum (penalized) likelihood estimation is used to fit the (non)parametric models. A Newtonâ€“Raphson or Fisher scoring algorithm is used to maximize the (penalized) likelihood. The additive terms in the model are fitted by using a backfitting algorithm. Censored data are easily incorporated into the framework. Five data sets from different fields of application are analysed to emphasize the generality of the GAMLSS class of models.},
	language = {en},
	number = {3},
	urldate = {2012-07-13},
	journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
	author = {Rigby, R. A. and Stasinopoulos, D. M.},
	year = {2005},
	keywords = {Betaâ€“binomial distribution, Boxâ€“Cox transformation, Centile estimation, Cubic smoothing splines, Generalized linear mixed model, LMS method, Negative binomial distribution, Non-normality, Nonparametric models, Overdispersion, Penalized likelihood, Random effects, Skewness and kurtosis},
	pages = {507--554},
	file = {Full Text PDF:/Users/micl/Zotero/storage/D6PZADQB/Rigby and Stasinopoulos - 2005 - Generalized additive models for location, scale an.pdf:application/pdf;Snapshot:/Users/micl/Zotero/storage/W752GFV4/full.html:text/html}
}

@book{hardin_generalized_2012,
	edition = {3},
	title = {Generalized {Linear} {Models} and {Extensions}, {Third} {Edition}},
	isbn = {1-59718-105-6},
	publisher = {Stata Press},
	author = {Hardin, James W. and Hilbe, Joseph M.},
	month = jun,
	year = {2012}
}

@article{friedman_projection_1981,
	title = {Projection {Pursuit} {Regression}},
	volume = {76},
	issn = {0162-1459},
	url = {http://www.jstor.org/stable/2287576},
	doi = {10.2307/2287576},
	abstract = {A new method for nonparametric multiple regression is presented. The procedure models the regression surface as a sum of general smooth functions of linear combinations of the predictor variables in an iterative manner. It is more general than standard stepwise and stagewise regression procedures, does not require the definition of a metric in the predictor space, and lends itself to graphical interpretation.},
	number = {376},
	urldate = {2012-06-26},
	journal = {Journal of the American Statistical Association},
	author = {Friedman, Jerome H. and Stuetzle, Werner},
	month = dec,
	year = {1981},
	note = {ArticleType: research-article / Full publication date: Dec., 1981 / Copyright Â© 1981 American Statistical Association},
	pages = {817--823}
}

@book{bybee_pisa_2009,
	title = {Pisa {Science} 2006: {Implications} for {Science} {Teachers} and {Teaching}},
	isbn = {978-1-933531-31-1},
	shorttitle = {Pisa {Science} 2006},
	language = {en},
	publisher = {NSTA Press},
	author = {Bybee, Rodger W. and McCrae, Barry},
	month = may,
	year = {2009},
	keywords = {Education / Testing \& Measurement, Education / General, Education / Student Life \& Student Affairs, Education / Teaching Methods \& Materials / Science \& Technology, Educational tests and measurements, High school students, High school students - Rating of, High school students/ Rating of, Programme for International Student Assessment, Science, Science - Study and teaching - United States, Science - Study and teaching (Secondary), Science / Study \& Teaching, Science/ Study and teaching (Secondary)}
}

@book{hardin_generalized_2007,
	title = {Generalized linear models and extensions},
	publisher = {Stata Corp},
	author = {Hardin, J. W and Hilbe, J.},
	year = {2007},
	file = {Snapshot:/Users/micl/Zotero/storage/9T3DGIWI/Hardin and Hilbe - 2007 - Generalized linear models and extensions.html:text/html}
}

@article{simpson_modelling_2018,
	title = {Modelling {Palaeoecological} {Time} {Series} {Using} {Generalised} {Additive} {Models}},
	volume = {6},
	issn = {2296-701X},
	url = {https://www.frontiersin.org/articles/10.3389/fevo.2018.00149/full},
	doi = {10.3389/fevo.2018.00149},
	abstract = {In the absence of annual laminations, time series generated from lake sediments or other similar stratigraphic sequences are irregularly spaced in time, which complicates formal analysis using classical statistical time series models. In lieu, statistical analyses of trends in palaeoenvironmental time series, if done at all, have typically used simpler linear regressions or (non-) parametric correlations with little regard for the violation of assumptions that almost surely occurs due to temporal dependencies in the data or that correlations do not provide estimates of the magnitude of change, just whether or not there is a linear or monotonic trend. Alternative approaches have used LOESS-estimated trends to justify data interpretations or test hypotheses as to the causal factors without considering the inherent subjectivity of the choice of parameters used to achieve the LOESS fit (e.g. span width, degree of polynomial). Generalized additive models (GAMs) are statistical models that can be used to estimate trends as smooth functions of time. Unlike LOESS, GAMs use automatic smoothness selection methods to objectively determine the complexity of the fitted trend, and as formal statistical models, GAMs, allow for potentially complex, non-linear trends, a proper accounting of model uncertainty, and the identification of periods of significant temporal change. Here, I present a consistent and modern approach to the estimation of trends in palaeoenvironmental time series using GAMs, illustrating features of the methodology with two example time series of contrasting complexity; a 150-year bulk organic matter Î´15N time series from Small Water, UK, and a 3000-year alkenone record from Braya-SÃ¸, Greenland. I discuss the underlying mechanics of GAMs that allow them to learn the shape of the trend from the data themselves and how simultaneous confidence intervals and the first derivatives of the trend are used to properly account for model uncertainty and identify periods of change. It is hoped that by using GAMs greater attention is paid to the statistical estimation of trends in palaeoenvironmental time series leading to more a robust and reproducible palaeoscience.},
	language = {English},
	urldate = {2019-02-10},
	journal = {Frontiers in Ecology and Evolution},
	author = {Simpson, Gavin L.},
	year = {2018},
	keywords = {environmental change, generalized additive models, simultaneous interval, Spline, time series},
	file = {Full Text PDF:/Users/micl/Zotero/storage/8RLFG7ZV/Simpson - 2018 - Modelling Palaeoecological Time Series Using Gener.pdf:application/pdf}
}

@article{friedman_additive_2000,
	title = {Additive logistic regression: a statistical view of boosting ({With} discussion and a rejoinder by the authors)},
	volume = {28},
	issn = {0090-5364, 2168-8966},
	shorttitle = {Additive logistic regression},
	url = {https://projecteuclid.org/euclid.aos/1016218223},
	doi = {10.1214/aos/1016218223},
	abstract = {Boosting is one of the most important recent developments in classification methodology. Boosting works by sequentially applying a classification algorithm to reweighted versions of the training data and then taking a weighted majority vote of the sequence of classifiers thus produced. For many classification algorithms, this simple strategy results in dramatic improvements in performance. We show that this seemingly mysterious phenomenon can be understood in terms of well-known statistical principles, namely additive modeling and maximum likelihood. For the two-class problem, boosting can be viewed as an approximation to additive modeling on the logistic scale using maximum Bernoulli likelihood as a criterion. We develop more direct approximations and show that they exhibit nearly identical results to boosting. Direct multiclass generalizations based on multinomial likelihood are derived that exhibit performance comparable to other recently proposed multiclass generalizations of boosting in most situations, and far superior in some. We suggest a minor modification to boosting that can reduce computation, often by factors of 10 to 50. Finally, we apply these insights to produce an alternative formulation of boosting decision trees. This approach, based on best-first truncated tree induction, often leads to better performance, and can provide interpretable descriptions of the aggregate decision rule. It is also much faster computationally, making it more suitable to large-scale data mining applications.},
	language = {EN},
	number = {2},
	urldate = {2019-02-10},
	journal = {The Annals of Statistics},
	author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
	month = apr,
	year = {2000},
	mrnumber = {MR1790002},
	zmnumber = {1106.62323},
	keywords = {classification, machine learning, nonparametric estimation, stagewise fitting, tree},
	pages = {337--407},
	file = {Full Text PDF:/Users/micl/Zotero/storage/DRP4S38J/Friedman et al. - 2000 - Additive logistic regression a statistical view o.pdf:application/pdf;Snapshot:/Users/micl/Zotero/storage/IU9EH95A/1016218223.html:text/html}
}

@article{wood_mgcv:_2012,
	title = {mgcv: {Mixed} {GAM} {Computation} {Vehicle} with {GCV}/{AIC}/{REML} smoothness estimation},
	shorttitle = {mgcv},
	url = {https://researchportal.bath.ac.uk/en/publications/mgcv-mixed-gam-computation-vehicle-with-gcvaicreml-smoothness-est},
	language = {English},
	urldate = {2019-09-29},
	author = {Wood, Simon},
	month = oct,
	year = {2012},
	file = {Snapshot:/Users/micl/Zotero/storage/V7NYNZR8/mgcv-mixed-gam-computation-vehicle-with-gcvaicreml-smoothness-est.html:text/html}
}

@book{wood_generalized_2017,
	title = {Generalized Additive Models : An Introduction with R, Second Edition},
	isbn = {978-1-315-37027-9},
	shorttitle = {Generalized {Additive} {Models}},
	url = {https://www.taylorfrancis.com/books/9781315370279},
	abstract = {The first edition of this book has established itself as one of the leading references on generalized additive models (GAMs), and the only book on the topic to},
	language = {en},
	urldate = {2019-09-29},
	publisher = {Chapman and Hall/CRC},
	author = {Wood, Simon N.},
	month = may,
	year = {2017},
	doi = {10.1201/9781315370279},
	file = {Full Text PDF:/Users/micl/Zotero/storage/CUH9EAKX/Wood - 2017 - Generalized Additive Models  An Introduction with.pdf:application/pdf;Snapshot:/Users/micl/Zotero/storage/VQ2HCD9B/9781315370279.html:text/html}
}

@article{li_faster_2019,
	title = {Faster model matrix crossproducts for large generalized linear models with discretized covariates},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/s11222-019-09864-2},
	doi = {10.1007/s11222-019-09864-2},
	abstract = {Wood et al. (J Am Stat Assoc 112(519):1199â€“1210, 2017) developed methods for fitting penalized regression spline based generalized additive models, with of the order of 10410410{\textasciicircum}4 coefficients, to up to 10810810{\textasciicircum}8 data. The methods offered two to three orders of magnitude reduction in computational cost relative to the most efficient previous methods. Part of the gain resulted from the development of a set of methods for efficiently computing model matrix products when model covariates each take only a discrete set of values substantially smaller than the sample size [generalizing an idea first appearing in Lang et al. (Stat Comput 24(2):223â€“238, 2014)]. Covariates can always be rounded to achieve such discretization, and it should be noted that the covariate discretization is marginal. That is we do not rely on discretizing covariates jointly, which would typically require the use of very coarse discretization. The most expensive computation in model estimation is the formation of the matrix cross product ð—ð–³ð–ð—XTWX{\textbackslash}mathbf\{X\}{\textasciicircum}\{{\textbackslash}mathsf\{T\}\}\{{\textbackslash}mathbf\{WX\}\} where ð—X{\textbackslash}mathbf\{X\} is a model matrix and ð–W\{{\textbackslash}mathbf\{W\}\} a diagonal or tri-diagonal matrix. The purpose of this paper is to present a simple, novel and substantially more efficient approach to the computation of this cross product. The new method offers, for example, a 30 fold reduction in cross product computation time for the Black Smoke model dataset motivating Wood et al. (2017). Given this reduction in computational cost, the subsequent Cholesky decomposition of ð—ð–³ð–ð—XTWX{\textbackslash}mathbf\{X\}{\textasciicircum}\{{\textbackslash}mathsf\{T\}\}\{{\textbackslash}mathbf\{WX\}\} and follow on computation of (ð—ð–³ð–ð—)âˆ’1(XTWX)âˆ’1({\textbackslash}mathbf\{X\}{\textasciicircum}\{{\textbackslash}mathsf\{T\}\}\{{\textbackslash}mathbf\{WX\}\}){\textasciicircum}\{-1\} become a more significant part of the computational burden, and we also discuss the choice of methods for improving their speed.},
	language = {en},
	urldate = {2019-09-29},
	journal = {Statistics and Computing},
	author = {Li, Zheyuan and Wood, Simon N.},
	month = mar,
	year = {2019},
	keywords = {BLAS, Fast regression, Generalized additive model},
	file = {Springer Full Text PDF:/Users/micl/Zotero/storage/7KC4ZXMP/Li and Wood - 2019 - Faster model matrix crossproducts for large genera.pdf:application/pdf}
}

@article{fasiolo_scalable_2019,
	title = {Scalable Visualization Methods for Modern Generalized Additive Models},
	volume = {0},
	issn = {1061-8600},
	url = {https://doi.org/10.1080/10618600.2019.1629942},
	doi = {10.1080/10618600.2019.1629942},
	abstract = {In the last two decades, the growth of computational resources has made it possible to handle generalized additive models (GAMs) that formerly were too costly for serious applications. However, the growth in model complexity has not been matched by improved visualizations for model development and results presentation. Motivated by an industrial application in electricity load forecasting, we identify the areas where the lack of modern visualization tools for GAMs is particularly severe, and we address the shortcomings of existing methods by proposing a set of visual tools that (a) are fast enough for interactive use, (b) exploit the additive structure of GAMs, (c) scale to large data sets, and (d) can be used in conjunction with a wide range of response distributions. The new visual methods proposed here are implemented by the mgcViz R package, available on the Comprehensive R Archive Network. Supplementary materials for this article are available online.},
	number = {0},
	urldate = {2019-09-29},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Fasiolo, Matteo and Nedellec, RaphaÃ«l and Goude, Yannig and Wood, Simon N.},
	month = jun,
	year = {2019},
	keywords = {Electricity load forecasting, Generalized additive models, Interactive model building, Regression modeling, Residuals checking, Visualization},
	pages = {1--9},
	file = {Snapshot:/Users/micl/Zotero/storage/V6LHAVE7/weblogin.umich.edu.html:text/html;Submitted Version:/Users/micl/Zotero/storage/4K2JDUWT/Fasiolo et al. - 2019 - Scalable Visualization Methods for Modern Generali.pdf:application/pdf}
}

@article{wood_generalized_2015,
	title = {Generalized additive models for large data sets},
	volume = {64},
	copyright = {Â© 2014 The Authors. Journal of the Royal Statistical Society: Series C Applied Statistics Published by John Wiley \& Sons Ltd on behalf of the Royal Statistical Society.},
	issn = {1467-9876},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssc.12068},
	doi = {10.1111/rssc.12068},
	abstract = {We consider an application in electricity grid load prediction, where generalized additive models are appropriate, but where the data set's size can make their use practically intractable with existing methods. We therefore develop practical generalized additive model fitting methods for large data sets in the case in which the smooth terms in the model are represented by using penalized regression splines. The methods use iterative update schemes to obtain factors of the model matrix while requiring only subblocks of the model matrix to be computed at any one time. We show that efficient smoothing parameter estimation can be carried out in a well-justified manner. The grid load prediction problem requires updates of the model fit, as new data become available, and some means for dealing with residual auto-correlation in grid load. Methods are provided for these problems and parallel implementation is covered. The methods allow estimation of generalized additive models for large data sets by using modest computer hardware, and the grid load prediction problem illustrates the utility of reduced rank spline smoothing methods for dealing with complex modelling problems.},
	language = {en},
	number = {1},
	urldate = {2019-09-29},
	journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
	author = {Wood, Simon N. and Goude, Yannig and Shaw, Simon},
	year = {2015},
	keywords = {Correlated additive model, Electricity load prediction, Generalized additive model estimation},
	pages = {139--155},
	file = {Snapshot:/Users/micl/Zotero/storage/8LYQID9I/rssc.html:text/html}
}

@article{wood_generalized_2017-1,
	title = {Generalized Additive Models for Gigadata: Modeling the U.K. Black Smoke Network Daily Data},
	volume = {112},
	issn = {0162-1459},
	shorttitle = {Generalized {Additive} {Models} for {Gigadata}},
	url = {https://amstat.tandfonline.com/doi/full/10.1080/01621459.2016.1195744},
	doi = {10.1080/01621459.2016.1195744},
	abstract = {We develop scalable methods for fitting penalized regression spline based generalized additive models with of the order of 104 coefficients to up to 108 data. Computational feasibility rests on: (i) a new iteration scheme for estimation of model coefficients and smoothing parameters, avoiding poorly scaling matrix operations; (ii) parallelization of the iterationâ€™s pivoted block Cholesky and basic matrix operations; (iii) the marginal discretization of model covariates to reduce memory footprint, with efficient scalable methods for computing required crossproducts directly from the discrete representation. Marginal discretization enables much finer discretization than joint discretization would permit. We were motivated by the need to model four decades worth of daily particulate data from the U.K. Black Smoke and Sulphur Dioxide Monitoring Network. Although reduced in size recently, over 2000 stations have at some time been part of the network, resulting in some 10 million measurements. Modeling at a daily scale is desirable for accurate trend estimation and mapping, and to provide daily exposure estimates for epidemiological cohort studies. Because of the dataset size, previous work has focused on modeling time or space averaged pollution levels, but this is unsatisfactory from a health perspective, since it is often acute exposure locally and on the time scale of days that is of most importance in driving adverse health outcomes. If computed by conventional means our black smoke model would require a half terabyte of storage just for the model matrix, whereas we are able to compute with it on a desktop workstation. The best previously available reduced memory footprint method would have required three orders of magnitude more computing time than our new method. Supplementary materials for this article are available online.},
	number = {519},
	urldate = {2019-09-29},
	journal = {Journal of the American Statistical Association},
	author = {Wood, Simon N. and Li, Zheyuan and Shaddick, Gavin and Augustin, Nicole H.},
	month = jul,
	year = {2017},
	pages = {1199--1210},
	file = {Full Text:/Users/micl/Zotero/storage/2N4Z5LJ3/Wood et al. - 2017 - Generalized Additive Models for Gigadata Modeling.pdf:application/pdf;Snapshot:/Users/micl/Zotero/storage/73X423H7/01621459.2016.html:text/html}
}

@article{wood_generalized_2015-1,
	title = {Generalized additive models for large data sets},
	volume = {64},
	copyright = {Â© 2014 The Authors. Journal of the Royal Statistical Society: Series C Applied Statistics Published by John Wiley \& Sons Ltd on behalf of the Royal Statistical Society.},
	issn = {1467-9876},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssc.12068},
	doi = {10.1111/rssc.12068},
	abstract = {We consider an application in electricity grid load prediction, where generalized additive models are appropriate, but where the data set's size can make their use practically intractable with existing methods. We therefore develop practical generalized additive model fitting methods for large data sets in the case in which the smooth terms in the model are represented by using penalized regression splines. The methods use iterative update schemes to obtain factors of the model matrix while requiring only subblocks of the model matrix to be computed at any one time. We show that efficient smoothing parameter estimation can be carried out in a well-justified manner. The grid load prediction problem requires updates of the model fit, as new data become available, and some means for dealing with residual auto-correlation in grid load. Methods are provided for these problems and parallel implementation is covered. The methods allow estimation of generalized additive models for large data sets by using modest computer hardware, and the grid load prediction problem illustrates the utility of reduced rank spline smoothing methods for dealing with complex modelling problems.},
	language = {en},
	number = {1},
	urldate = {2019-09-29},
	journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
	author = {Wood, Simon N. and Goude, Yannig and Shaw, Simon},
	year = {2015},
	keywords = {Correlated additive model, Electricity load prediction, Generalized additive model estimation},
	pages = {139--155},
	file = {Snapshot:/Users/micl/Zotero/storage/66YDF5ZT/rssc.html:text/html}
}

@article{brooks_glmmtmb_2017,
	title = {glmmTMB Balances Speed and Flexibility Among Packages for Zero-inflated Generalized Linear Mixed Modeling},
	volume = {9},
	issn = {2073-4859},
	url = {https://journal.r-project.org/archive/2017/RJ-2017-066},
	language = {en},
	number = {2},
	urldate = {2019-10-13},
	journal = {The R Journal},
	author = {Brooks, Mollie E. and Kristensen, Kasper and Benthem, Koen J. van and Magnusson, Arni and Berg, Casper W. and Nielsen, Anders and Skaug, Hans J. and MÃ¤chler, Martin and Bolker, Benjamin M.},
	year = {2017},
	pages = {378--400},
	file = {Snapshot:/Users/micl/Zotero/storage/4ZBA8UHP/RJ-2017-066.html:text/html}
}

@article{mccoach2018,
  title={Does the package matter? A comparison of five common multilevel modeling software packages},
  author={McCoach, D Betsy and Rifenbark, Graham G and Newton, Sarah D and Li, Xiaoran and Kooken, Janice and Yomtov, Dani and Gambino, Anthony J and Bellara, Aarti},
  journal={Journal of Educational and Behavioral Statistics},
  url={https://journals.sagepub.com/doi/10.3102/1076998618776348},
  volume={43},
  number={5},
  pages={594--627},
  year={2018},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}
</script>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<div class="distill-site-nav distill-site-footer">
  <div>


Michael Clark â€¢ 2019 â€¢  <a href="https://m-clark.github.io">https://m-clark.github.io/</a>
</div>
</div>
<!--/radix_placeholder_navigation_after_body-->


</body>

</html>
